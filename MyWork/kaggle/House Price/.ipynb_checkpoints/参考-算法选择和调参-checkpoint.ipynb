{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、读取训练集和测试集，确定训练（预测）目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_modified_12-10.csv')\n",
    "#test = pd.read_csv('test_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_data shape is  (1255, 291)\n",
      "df_train_target shape is  (1255,)\n"
     ]
    }
   ],
   "source": [
    "#df_train_target = train['SalePrice']\n",
    "#df_train_data = train.drop(['SalePrice'],axis = 1)\n",
    "#print 'df_train_data shape is ', df_train_data.shape\n",
    "#print 'df_train_target shape is ', df_train_target.shape\n",
    "#print 'df_train_target shape is ', test.shape\n",
    "\n",
    "\n",
    "df_train_target = train['SalePrice'].values\n",
    "df_train_data = train.drop(['SalePrice'],axis = 1).values\n",
    "print 'df_train_data shape is ', df_train_data.shape\n",
    "print 'df_train_target shape is ', df_train_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target='SalePrice'\n",
    "IDcol = 'ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 二、切分训练集，初步尝试各种回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "岭回归\n",
      "train score: 0.945, test score: 0.874\n",
      "\n",
      "train score: 0.945, test score: 0.850\n",
      "\n",
      "train score: 0.943, test score: 0.881\n",
      "\n",
      "GradientBoostingRegressor\n",
      "train score: 0.970, test score: 0.871\n",
      "\n",
      "train score: 0.970, test score: 0.843\n",
      "\n",
      "train score: 0.967, test score: 0.856\n",
      "\n",
      "ExtraTreesRegressor\n",
      "train score: 1.000, test score: 0.825\n",
      "\n",
      "train score: 1.000, test score: 0.773\n",
      "\n",
      "train score: 1.000, test score: 0.772\n",
      "\n",
      "随机森林回归/Random Forest(n_estimators = 100)\n",
      "train score: 0.980, test score: 0.865\n",
      "\n",
      "train score: 0.981, test score: 0.825\n",
      "\n",
      "train score: 0.982, test score: 0.827\n",
      "\n",
      "XGBRegressor\n",
      "train score: 0.966, test score: 0.871\n",
      "\n",
      "train score: 0.967, test score: 0.856\n",
      "\n",
      "train score: 0.964, test score: 0.854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 总得切分一下数据咯（训练集和测试集）\n",
    "cv = cross_validation.ShuffleSplit(len(df_train_data), n_iter=3, test_size=0.2,\n",
    "    random_state=0)\n",
    "\n",
    "# 各种模型来一圈\n",
    "\n",
    "print \"岭回归\"    \n",
    "for train, test in cv:    \n",
    "    svc = linear_model.Ridge().fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        svc.score(df_train_data[train], df_train_target[train]), svc.score(df_train_data[test], df_train_target[test])))\n",
    "    \n",
    "print \"GradientBoostingRegressor\"\n",
    "for train, test in cv:\n",
    "    \n",
    "    svc = GradientBoostingRegressor().fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        svc.score(df_train_data[train], df_train_target[train]), svc.score(df_train_data[test], df_train_target[test])))\n",
    "\n",
    "print \"ExtraTreesRegressor\"\n",
    "for train, test in cv:\n",
    "    \n",
    "    svc = ExtraTreesRegressor().fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        svc.score(df_train_data[train], df_train_target[train]), svc.score(df_train_data[test], df_train_target[test])))\n",
    "        \n",
    "    \n",
    "print \"随机森林回归/Random Forest(n_estimators = 100)\"    \n",
    "for train, test in cv:    \n",
    "    svc = RandomForestRegressor(n_estimators = 100).fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        svc.score(df_train_data[train], df_train_target[train]), svc.score(df_train_data[test], df_train_target[test])))\n",
    "\n",
    "print \"XGBRegressor\"    \n",
    "for train, test in cv:    \n",
    "    svc =  XGBRegressor(max_depth=3, \n",
    "                    learning_rate=0.1, \n",
    "                    n_estimators=100, \n",
    "                    silent=True, \n",
    "                    objective='reg:linear', \n",
    "                    nthread=-1, gamma=0, \n",
    "                    min_child_weight=1, \n",
    "                    max_delta_step=0, \n",
    "                    subsample=1, \n",
    "                    colsample_bytree=1, \n",
    "#                    colsample_bylevel=1, \n",
    "#                    reg_alpha=0, \n",
    "#                    reg_lambda=1, \n",
    "#                    scale_pos_weight=1, \n",
    "                    base_score=0.5, \n",
    "                    seed=0, \n",
    "                    missing=None).fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        svc.score(df_train_data[train], df_train_target[train]), svc.score(df_train_data[test], df_train_target[test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#将多个模型的结果融合，再跑一边xgboost\n",
    "svc0 = linear_model.Ridge().fit(df_train_data, df_train_target)\n",
    "\n",
    "svc1 = GradientBoostingRegressor().fit(df_train_data, df_train_target)\n",
    "\n",
    "svc2 = ExtraTreesRegressor().fit(df_train_data, df_train_target)\n",
    "\n",
    "svc3 = RandomForestRegressor(n_estimators = 100).fit(df_train_data, df_train_target)\n",
    "\n",
    "svc4 =  XGBRegressor(max_depth=3, \n",
    "                    learning_rate=0.1, \n",
    "                    n_estimators=100, \n",
    "                    silent=True, \n",
    "                    objective='reg:linear', \n",
    "                    nthread=-1, gamma=0, \n",
    "                    min_child_weight=1, \n",
    "                    max_delta_step=0, \n",
    "                    subsample=1, \n",
    "                    colsample_bytree=1, \n",
    "#                    colsample_bylevel=1, \n",
    "#                    reg_alpha=0, \n",
    "#                    reg_lambda=1, \n",
    "#                    scale_pos_weight=1, \n",
    "                    base_score=0.5, \n",
    "                    seed=0, \n",
    "                    missing=None).fit(df_train_data, df_train_target)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "trai = pd.read_csv('train_modified.csv')\n",
    "df1 = trai.drop(['SalePrice'],axis = 1)\n",
    "#df1 = pd.read_csv('test_modified.csv')\n",
    "\n",
    "df1_train = pd.DataFrame({\n",
    "                    'svc0':svc0.predict(df1),\n",
    "                    'svc1':svc1.predict(df1),\n",
    "                    'svc2':svc2.predict(df1),\n",
    "                    'svc3':svc3.predict(df1),\n",
    "                    'svc4':svc4.predict(df1),\n",
    "#                    'SalePrice':df_train_target,\n",
    "                   })\n",
    "df1_train = df1_train.values\n",
    "\n",
    "svc_last =  XGBRegressor(max_depth=3, \n",
    "                    learning_rate=0.1, \n",
    "                    n_estimators=100, \n",
    "                    silent=True, \n",
    "                    objective='reg:linear', \n",
    "                    nthread=-1, gamma=0, \n",
    "                    min_child_weight=1, \n",
    "                    max_delta_step=0, \n",
    "                    subsample=1, \n",
    "                    colsample_bytree=1, \n",
    "#                    colsample_bylevel=1, \n",
    "#                    reg_alpha=0, \n",
    "#                    reg_lambda=1, \n",
    "#                    scale_pos_weight=1, \n",
    "                    base_score=0.5, \n",
    "                    seed=0, \n",
    "                    missing=None)\n",
    "svc_last = svc_last.fit(df1_train[train], df_train_target[train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "cv1 = cross_validation.ShuffleSplit(len(df_train_target), n_iter=10, test_size=0.2,\n",
    "    random_state=0)\n",
    "\n",
    "svc_last =  XGBRegressor(max_depth=3, \n",
    "                    learning_rate=0.1, \n",
    "                    n_estimators=100, \n",
    "                    silent=True, \n",
    "                    objective='reg:linear', \n",
    "                    nthread=-1, gamma=0, \n",
    "                    min_child_weight=1, \n",
    "                    max_delta_step=0, \n",
    "                    subsample=1, \n",
    "                    colsample_bytree=1, \n",
    "#                    colsample_bylevel=1, \n",
    "#                    reg_alpha=0, \n",
    "#                    reg_lambda=1, \n",
    "#                    scale_pos_weight=1, \n",
    "                    base_score=0.5, \n",
    "                    seed=0, \n",
    "                    missing=None)\n",
    "\n",
    "for train, test in cv1:    \n",
    "    svc_last = svc_last.fit(df1_train[train], df_train_target[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        svc_last.score(df1_train[train], df_train_target[train]), svc_last.score(df1_train[test], df_train_target[test])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、将各个具有较好默认表现的回归模型，进行更为细致的grid调参和CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_train_data\n",
    "y = df_train_target\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "tuned_parameters = [{\n",
    "        'alpha':[1.0,2.0,3.0,4.0,5.0,6.0], \n",
    "       'tol':[1.0,2.0,3.0,4.0,5.0], \n",
    "#        'max_iter':[3,5,7],\n",
    "\n",
    "#        'n_estimators':[100,200,500,1000,2000], \n",
    "#        'subsample':[1,2,5], \n",
    "#        'colsample_bytree':[1,2,5], \n",
    "                    }]   \n",
    "    \n",
    "scores = ['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2\n",
      "别！喝！咖！啡！了！最佳参数找到了亲！！：\n",
      "\n",
      "Ridge(alpha=5.0, copy_X=True, fit_intercept=False, max_iter=None,\n",
      "   normalize=False, random_state=0, solver='auto', tol=1.0)\n",
      "\n",
      "得分分别是:\n",
      "\n",
      "0.900 (+/-0.006) for {'alpha': 1.0, 'tol': 1.0}\n",
      "\n",
      "0.900 (+/-0.006) for {'alpha': 1.0, 'tol': 2.0}\n",
      "\n",
      "0.900 (+/-0.006) for {'alpha': 1.0, 'tol': 3.0}\n",
      "\n",
      "0.900 (+/-0.006) for {'alpha': 1.0, 'tol': 4.0}\n",
      "\n",
      "0.900 (+/-0.006) for {'alpha': 1.0, 'tol': 5.0}\n",
      "\n",
      "0.903 (+/-0.006) for {'alpha': 2.0, 'tol': 1.0}\n",
      "\n",
      "0.903 (+/-0.006) for {'alpha': 2.0, 'tol': 2.0}\n",
      "\n",
      "0.903 (+/-0.006) for {'alpha': 2.0, 'tol': 3.0}\n",
      "\n",
      "0.903 (+/-0.006) for {'alpha': 2.0, 'tol': 4.0}\n",
      "\n",
      "0.903 (+/-0.006) for {'alpha': 2.0, 'tol': 5.0}\n",
      "\n",
      "0.904 (+/-0.006) for {'alpha': 3.0, 'tol': 1.0}\n",
      "\n",
      "0.904 (+/-0.006) for {'alpha': 3.0, 'tol': 2.0}\n",
      "\n",
      "0.904 (+/-0.006) for {'alpha': 3.0, 'tol': 3.0}\n",
      "\n",
      "0.904 (+/-0.006) for {'alpha': 3.0, 'tol': 4.0}\n",
      "\n",
      "0.904 (+/-0.006) for {'alpha': 3.0, 'tol': 5.0}\n",
      "\n",
      "0.904 (+/-0.006) for {'alpha': 4.0, 'tol': 1.0}\n",
      "\n",
      "0.904 (+/-0.006) for {'alpha': 4.0, 'tol': 2.0}\n",
      "\n",
      "0.904 (+/-0.006) for {'alpha': 4.0, 'tol': 3.0}\n",
      "\n",
      "0.904 (+/-0.006) for {'alpha': 4.0, 'tol': 4.0}\n",
      "\n",
      "0.904 (+/-0.006) for {'alpha': 4.0, 'tol': 5.0}\n",
      "\n",
      "0.905 (+/-0.006) for {'alpha': 5.0, 'tol': 1.0}\n",
      "\n",
      "0.905 (+/-0.006) for {'alpha': 5.0, 'tol': 2.0}\n",
      "\n",
      "0.905 (+/-0.006) for {'alpha': 5.0, 'tol': 3.0}\n",
      "\n",
      "0.905 (+/-0.006) for {'alpha': 5.0, 'tol': 4.0}\n",
      "\n",
      "0.905 (+/-0.006) for {'alpha': 5.0, 'tol': 5.0}\n",
      "\n",
      "0.905 (+/-0.006) for {'alpha': 6.0, 'tol': 1.0}\n",
      "\n",
      "0.905 (+/-0.006) for {'alpha': 6.0, 'tol': 2.0}\n",
      "\n",
      "0.905 (+/-0.006) for {'alpha': 6.0, 'tol': 3.0}\n",
      "\n",
      "0.905 (+/-0.006) for {'alpha': 6.0, 'tol': 4.0}\n",
      "\n",
      "0.905 (+/-0.006) for {'alpha': 6.0, 'tol': 5.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for score in scores:\n",
    "    \n",
    "    print score\n",
    "    \n",
    "    clf = GridSearchCV(linear_model.Ridge( copy_X=True, fit_intercept=False, max_iter=None,\n",
    "      normalize=False,  random_state=0,solver='auto',\n",
    "                                   ), tuned_parameters, cv=5, scoring=score)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"别！喝！咖！啡！了！最佳参数找到了亲！！：\")\n",
    "    print \"\"\n",
    "    #best_estimator_ returns the best estimator chosen by the search\n",
    "    print(clf.best_estimator_)\n",
    "    print \"\"\n",
    "    print(\"得分分别是:\")\n",
    "    print \"\"\n",
    "    #grid_scores_的返回值:\n",
    "    #    * a dict of parameter settings\n",
    "    #    * the mean score over the cross-validation folds \n",
    "    #    * the list of scores for each fold\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() / 2, params))\n",
    "        print \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、通过学习曲线，验证模型是否过拟合或者欠拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "\n",
    "cv = cross_validation.ShuffleSplit(df_train_data.shape[0], n_iter=10,test_size=0.2, random_state=0)\n",
    "#estimator = linear_model.Ridge( copy_X=True, fit_intercept=False, max_iter=None,\n",
    "#      normalize=False, random_state=0, solver='auto',alpha=2.0,tol=1.0)\n",
    "                                  \n",
    "#plot_learning_curve(estimator, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "\n",
    "estimator0 = linear_model.Ridge()\n",
    "estimator1 = GradientBoostingRegressor()\n",
    "estimator2 = ExtraTreesRegressor()\n",
    "estimator3 = RandomForestRegressor()\n",
    "estimator4 = XGBRegressor()\n",
    "\n",
    "\n",
    "title = \"Learning Curves (Ridge)\"\n",
    "plot_learning_curve(estimator0, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "title = \"Learning Curves (GradientBoostingRegressor)\"\n",
    "plot_learning_curve(estimator1, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "title = \"Learning Curves (ExtraTreesRegressor)\"\n",
    "plot_learning_curve(estimator2, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "title = \"Learning Curves (RandomForestRegressor)\"\n",
    "plot_learning_curve(estimator3, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "title = \"Learning Curves (XGBRegressor)\"\n",
    "plot_learning_curve(estimator4, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、用得到的参数，训练测试集，得到结果并保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df2 = pd.read_csv('test_modified.csv')\n",
    "\n",
    "\n",
    "df2_train = pd.DataFrame({\n",
    "                    'svc0':svc0.predict(df2),\n",
    "                    'svc1':svc1.predict(df2),\n",
    "                    'svc2':svc2.predict(df2),\n",
    "                    'svc3':svc3.predict(df2),\n",
    "                    'svc4':svc4.predict(df2),\n",
    "#                    'SalePrice':df_train_target,\n",
    "                   })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df2_train = df2_train.values\n",
    "\n",
    "result_last_var = svc_last.predict(df2_train)\n",
    "\n",
    "\n",
    "result_last = pd.DataFrame({'Id':df2['Id'],'SalePrice':result_last_var})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = linear_model.Ridge( copy_X=True, fit_intercept=False, max_iter=None,\n",
    "      normalize=False, random_state=0, solver='auto',alpha=6.0,tol=1.0\n",
    "                                   ).fit(df_train_data, df_train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('test_modified.csv')\n",
    "aa=aa.predict(df2)\n",
    "result_last = pd.DataFrame({'Id':df2['Id'],'SalePrice':aa})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_last.to_csv('12-10.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1459.000000</td>\n",
       "      <td>1459.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2190.000000</td>\n",
       "      <td>179003.718009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.321334</td>\n",
       "      <td>77928.387039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1461.000000</td>\n",
       "      <td>33157.889167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1825.500000</td>\n",
       "      <td>125400.213041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2190.000000</td>\n",
       "      <td>160161.214955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2554.500000</td>\n",
       "      <td>215151.737643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2919.000000</td>\n",
       "      <td>708106.432624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id      SalePrice\n",
       "count  1459.000000    1459.000000\n",
       "mean   2190.000000  179003.718009\n",
       "std     421.321334   77928.387039\n",
       "min    1461.000000   33157.889167\n",
       "25%    1825.500000  125400.213041\n",
       "50%    2190.000000  160161.214955\n",
       "75%    2554.500000  215151.737643\n",
       "max    2919.000000  708106.432624"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_last.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1459 entries, 0 to 1458\n",
      "Data columns (total 2 columns):\n",
      "Id           1459 non-null int64\n",
      "SalePrice    1459 non-null float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 22.9 KB\n"
     ]
    }
   ],
   "source": [
    "result_last.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  81.,  506.,  444.,  230.,   98.,   52.,   31.,   13.,    3.,\n",
       "           0.,    0.,    1.]),\n",
       " array([  33157.88916671,   89403.60112149,  145649.31307626,\n",
       "         201895.02503103,  258140.73698581,  314386.44894058,\n",
       "         370632.16089535,  426877.87285013,  483123.5848049 ,\n",
       "         539369.29675968,  595615.00871445,  651860.72066922,  708106.432624  ]),\n",
       " <a list of 12 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+4AAAFoCAYAAADJkqFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116635650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(result_last['SalePrice'], bins=12, color=sns.desaturate(\"indianred\", .8), alpha=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ensemble函数\n",
    "class Ensemble(object):\n",
    "    def __init__(self, n_folds, stacker, base_models):\n",
    "        self.n_folds = n_folds\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(KFold(len(y), n_folds=self.n_folds, shuffle=True, random_state=2016))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            S_test_i = np.zeros((T.shape[0], len(folds)))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                # y_holdout = y[test_idx]\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_holdout)[:]\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict(T)[:]\n",
    "\n",
    "            S_test[:, i] = S_test_i.mean(1)\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        y_pred = self.stacker.predict(S_test)[:]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
