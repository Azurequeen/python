{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、读取训练集和测试集，确定训练（预测）目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_modified_Gaoshou.csv')\n",
    "#train = pd.read_csv('train_modified.csv')\n",
    "#test = pd.read_csv('test_modified.csv')\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target='SalePrice'\n",
    "IDcol = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_data shape is  (1456, 403)\n",
      "df_train_target shape is  (1456,)\n"
     ]
    }
   ],
   "source": [
    "#df_train_target = train['SalePrice']\n",
    "#df_train_data = train.drop(['SalePrice'],axis = 1)\n",
    "#print 'df_train_data shape is ', df_train_data.shape\n",
    "#print 'df_train_target shape is ', df_train_target.shape\n",
    "#print 'df_train_target shape is ', test.shape\n",
    "\n",
    "\n",
    "#df_train_target = train['SalePrice'].values\n",
    "df_train_target = train['SalePrice']\n",
    "df_train_data = train.drop(['SalePrice'],axis = 1).values\n",
    "#df_train_target[\"SalePrice\"] = np.log(df_train_target[\"SalePrice\"])\n",
    "\n",
    "\n",
    "\n",
    "print 'df_train_data shape is ', df_train_data.shape\n",
    "print 'df_train_target shape is ', df_train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 二、切分训练集，初步尝试各种回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "('Ridge score on training set: ', 0.10716982346497582)\n",
      "('Ridge score on training set: ', 0.11378590942794356)\n",
      "('Ridge score on training set: ', 0.11120140076858052)\n",
      "Lasso\n",
      "('Lasso score on training set: ', 0.10434714154027118)\n",
      "('Lasso score on training set: ', 0.10825174855650151)\n",
      "('Lasso score on training set: ', 0.10497221995789088)\n",
      "GradientBoostingRegressor\n",
      "('GradientBoostingRegressor score on training set: ', 0.11338879604455837)\n",
      "('GradientBoostingRegressor score on training set: ', 0.12131105644353761)\n",
      "('GradientBoostingRegressor score on training set: ', 0.11745492863954322)\n",
      "ExtraTreesRegressor\n",
      "('ExtraTreesRegressor score on training set: ', 0.12508721687487898)\n",
      "('ExtraTreesRegressor score on training set: ', 0.13440671637669363)\n",
      "('ExtraTreesRegressor score on training set: ', 0.14304816830187878)\n",
      "随机森林回归/Random Forest(n_estimators = 100)\n",
      "('RF score on training set: ', 0.12083888860487142)\n",
      "('RF score on training set: ', 0.13762536759442065)\n",
      "('RF score on training set: ', 0.12862431541566305)\n",
      "XGBRegressor\n",
      "('XGBoost score on training set: ', 0.10628315991015866)\n",
      "('XGBoost score on training set: ', 0.11469744603829321)\n",
      "('XGBoost score on training set: ', 0.10517940806678948)\n",
      "boost\n",
      "('RF score on training set: ', 0.15731384258443337)\n",
      "('RF score on training set: ', 0.15607552541222044)\n",
      "('RF score on training set: ', 0.16274872878989818)\n"
     ]
    }
   ],
   "source": [
    "# 总得切分一下数据咯（训练集和测试集）\n",
    "cv = cross_validation.ShuffleSplit(len(df_train_data), n_iter=3, test_size=0.2,\n",
    "    random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# 各种模型来一圈\n",
    "\n",
    "print \"Ridge\"    \n",
    "z0=list()\n",
    "for train, test in cv:    \n",
    "    svc0 = linear_model.Ridge().fit(df_train_data[train], df_train_target[train])\n",
    "    \n",
    "    print(\"Ridge score on training set: \", rmse(svc0.predict(df_train_data[test]), df_train_target[test]))\n",
    "    z0.append(rmse(svc0.predict(df_train_data[test]), df_train_target[test]))\n",
    "    \n",
    "print \"Lasso\"  \n",
    "z1=list()\n",
    "for train, test in cv:    \n",
    "    svc1 = Lasso(alpha=0.00099, max_iter=50000).fit(df_train_data[train], df_train_target[train])\n",
    "    \n",
    "    print(\"Lasso score on training set: \", rmse(svc1.predict(df_train_data[test]), df_train_target[test]))\n",
    "    z1.append(rmse(svc1.predict(df_train_data[test]), df_train_target[test]))\n",
    "\n",
    "    \n",
    "    \n",
    "print \"GradientBoostingRegressor\"\n",
    "for train, test in cv:\n",
    "    \n",
    "    svc2 = GradientBoostingRegressor().fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"GradientBoostingRegressor score on training set: \", rmse(svc2.predict(df_train_data[test]), df_train_target[test]))\n",
    "\n",
    "print \"ExtraTreesRegressor\"\n",
    "for train, test in cv:\n",
    "    \n",
    "    svc3 = ExtraTreesRegressor().fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"ExtraTreesRegressor score on training set: \", rmse(svc3.predict(df_train_data[test]), df_train_target[test]))\n",
    "        \n",
    "    \n",
    "print \"随机森林回归/Random Forest(n_estimators = 100)\"    \n",
    "for train, test in cv:    \n",
    "    svc4 = RandomForestRegressor(n_estimators = 100).fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"RF score on training set: \", rmse(svc4.predict(df_train_data[test]), df_train_target[test]))\n",
    "\n",
    "print \"XGBRegressor\"    \n",
    "for train, test in cv:  \n",
    "    z5=list()\n",
    "    svc5 =  XGBRegressor(colsample_bytree=0.2,\n",
    "                 gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=4,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=7200,                                                                 \n",
    "#                 reg_alpha=0.9,\n",
    "#                 reg_lambda=0.6,\n",
    "                 subsample=0.2,\n",
    "                 seed=42,\n",
    "                 silent=1).fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"XGBoost score on training set: \", rmse(svc5.predict(df_train_data[test]), df_train_target[test]))\n",
    "    z5.append(rmse(svc5.predict(df_train_data[test]), df_train_target[test]))\n",
    "\n",
    "print \"boost\"    \n",
    "for train, test in cv:    \n",
    "    svc6 = AdaBoostRegressor().fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"RF score on training set: \", rmse(svc6.predict(df_train_data[test]), df_train_target[test]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s015 = rmse((svc0.predict(df_train_data)+svc1.predict(df_train_data)+svc5.predict(df_train_data))/3, df_train_target)\n",
    "s01 = rmse((svc0.predict(df_train_data)+svc1.predict(df_train_data))/2, df_train_target)\n",
    "s05 = rmse((svc0.predict(df_train_data)+svc5.predict(df_train_data))/2, df_train_target)\n",
    "s15 = rmse((svc1.predict(df_train_data)+svc5.predict(df_train_data))/2, df_train_target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print \"s015:%s,s01:%s,s15:%s,s05:%s, \" %(s015,s01,s15,s05)                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将多个模型的结果融合，再跑一边xgboost\n",
    "svc0 = linear_model.Ridge().fit(df_train_data, df_train_target)\n",
    "\n",
    "svc1 = Lasso(alpha=0.00099, max_iter=50000).fit(df_train_data, df_train_target)\n",
    "\n",
    "svc2 = GradientBoostingRegressor().fit(df_train_data, df_train_target)\n",
    "\n",
    "svc3 = ExtraTreesRegressor().fit(df_train_data, df_train_target)\n",
    "\n",
    "svc4 = RandomForestRegressor(n_estimators = 100).fit(df_train_data, df_train_target)\n",
    "\n",
    "svc5 =  XGBRegressor(max_depth=3, \n",
    "                    learning_rate=0.1, \n",
    "                    n_estimators=100, \n",
    "                    silent=True, \n",
    "                    objective='reg:linear', \n",
    "                    nthread=-1, gamma=0, \n",
    "                    min_child_weight=1, \n",
    "                    max_delta_step=0, \n",
    "                    subsample=1, \n",
    "                    colsample_bytree=1, \n",
    "#                    colsample_bylevel=1, \n",
    "#                    reg_alpha=0, \n",
    "#                    reg_lambda=1, \n",
    "#                    scale_pos_weight=1, \n",
    "                    base_score=0.5, \n",
    "                    seed=0, \n",
    "                    missing=None).fit(df_train_data, df_train_target)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trai = pd.read_csv('train_modified_Gaoshou.csv')\n",
    "df1 = trai.drop(['SalePrice'],axis = 1)\n",
    "#df1 = pd.read_csv('test_modified.csv')\n",
    "\n",
    "df1_train = pd.DataFrame({\n",
    "                    'svc0':svc0.predict(df1),\n",
    "#                    'svc1':svc1.predict(df1),\n",
    "#                    'svc2':svc2.predict(df1),\n",
    "#                    'svc3':svc3.predict(df1),\n",
    "#                    'svc4':svc4.predict(df1),\n",
    "                    'svc5':svc5.predict(df1),\n",
    "                   })\n",
    "df1_train = df1_train.values\n",
    "\n",
    "svc_last =  Lasso(alpha=0.00099, max_iter=50000).fit(df1_train[train], df_train_target[train])\n",
    "\n",
    "cv1 = cross_validation.ShuffleSplit(len(df_train_target), n_iter=10, test_size=0.2,\n",
    "    random_state=0)\n",
    "\n",
    "for train, test in cv1:    \n",
    "    svc_last1 =  svc_last\n",
    "    print rmse(svc_last1.predict(df1_train[test]), df_train_target[test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、将各个具有较好默认表现的回归模型，进行更为细致的grid调参和CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_train_data\n",
    "y = df_train_target\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "tuned_parameters = [{\n",
    "        'alpha':[1.0,2.0,3.0,4.0,5.0,6.0], \n",
    "       'tol':[1.0,2.0,3.0,4.0,5.0], \n",
    "#        'max_iter':[3,5,7],\n",
    "\n",
    "#        'n_estimators':[100,200,500,1000,2000], \n",
    "#        'subsample':[1,2,5], \n",
    "#        'colsample_bytree':[1,2,5], \n",
    "                    }]   \n",
    "    \n",
    "scores = ['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: 导入 'GridSearchCV' 和 'make_scorer'\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(df_train_data, df_train_target, test_size=0.3, random_state=0)\n",
    "\n",
    "# TODO：创建你希望调整的参数列表\n",
    "parameters = {'alpha':[1.0,2.0,3.0,4.0,5.0,6.0], \n",
    "       'tol':[1.0,2.0,3.0,4.0,5.0], }\n",
    "\n",
    "# TODO：初始化分类器\n",
    "clf = linear_model.Ridge()\n",
    "\n",
    "# TODO：用'make_scorer'创建一个f1评分函数\n",
    "f1_scorer = make_scorer(mean_squared_error)\n",
    "\n",
    "# TODO：在分类器上使用f1_scorer作为评分函数运行网格搜索\n",
    "grid_obj = GridSearchCV(clf,param_grid=parameters,cv=None,scoring=f1_scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "# TODO：用训练集训练grid search object来寻找最佳参数\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "# 得到预测的结果\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Report the final F1 score for training and testing after parameter tuning\n",
    "# 输出经过调参之后的训练集和测试集的F1值\n",
    "print clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、通过学习曲线，验证模型是否过拟合或者欠拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 10)):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "\n",
    "cv = cross_validation.ShuffleSplit(df_train_data.shape[0], n_iter=10,test_size=0.2, random_state=0)\n",
    "#estimator = linear_model.Ridge( copy_X=True, fit_intercept=False, max_iter=None,\n",
    "#      normalize=False, random_state=0, solver='auto',alpha=2.0,tol=1.0)\n",
    "                                  \n",
    "#plot_learning_curve(estimator, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "\n",
    "estimator0 = linear_model.Ridge()\n",
    "estimator1 = Lasso(alpha=0.00099, max_iter=50000)\n",
    "estimator2 = GradientBoostingRegressor()\n",
    "estimator3 = ExtraTreesRegressor()\n",
    "estimator4 = RandomForestRegressor()\n",
    "estimator5 = XGBRegressor()\n",
    "\n",
    "\n",
    "title = \"Learning Curves (Ridge)\"\n",
    "plot_learning_curve(estimator0, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "title = \"Learning Curves (Lasso)\"\n",
    "plot_learning_curve(estimator1, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "\n",
    "title = \"Learning Curves (XGBRegressor)\"\n",
    "plot_learning_curve(estimator5, title, X, y, (0.0, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、用得到的参数，训练测试集，得到结果并保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "df2 = pd.read_csv('test_modified.csv')\n",
    "\n",
    "\n",
    "df2_train = pd.DataFrame({\n",
    "                    'svc0':svc0.predict(df2),\n",
    "                    'svc1':svc1.predict(df2),\n",
    "                    'svc2':svc2.predict(df2),\n",
    "                    'svc3':svc3.predict(df2),\n",
    "                    'svc4':svc4.predict(df2),\n",
    "#                    'SalePrice':df_train_target,\n",
    "                   })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "df2_train = df2_train.values\n",
    "\n",
    "result_last_var = svc_last.predict(df2_train)\n",
    "\n",
    "\n",
    "result_last = pd.DataFrame({'Id':df2['Id'],'SalePrice':result_last_var})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('test_modified_Gaoshou.csv')\n",
    "\n",
    "pre0 = svc0.predict(df2)\n",
    "pre1 = svc1.predict(df2)\n",
    "pre5 = svc5.predict(df2)\n",
    "\n",
    "predicts = (pre1+pre5)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#加第二层\n",
    "df1_train = pd.DataFrame({\n",
    "                    'svc0':svc0.predict(df2),\n",
    "#                    'svc1':svc1.predict(df2),\n",
    "#                    'svc2':svc2.predict(df1),\n",
    "#                    'svc3':svc3.predict(df1),\n",
    "#                    'svc4':svc4.predict(df1),\n",
    "                    'svc5':svc5.predict(df2),\n",
    "                   })\n",
    "#df1_train = df1_train.values\n",
    "\n",
    "predicts = svc_last.predict(df1_train)\n",
    "#predicts = np.exp(predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "predicts_end = np.exp(predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('test_modified.csv')\n",
    "result_last = pd.DataFrame({'Id':df3['Id'],'SalePrice':predicts_end})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_last.to_csv('12-11.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_last.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_last.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aaaaaaa= pd.read_csv('output.csv')\n",
    "aaaaaaa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.hist(result_last['SalePrice'], bins=12, normed=True, color=\"#FF0000\", alpha=.9)\n",
    "plt.hist(aaaaaaa['SalePrice'], bins=12, normed=True, color=\"#C1F320\", alpha=.9)\n",
    "plt.hist(np.exp(df_train_target), bins=12, normed=True,  alpha=.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ensemble函数\n",
    "class Ensemble(object):\n",
    "    def __init__(self, n_folds, stacker, base_models):\n",
    "        self.n_folds = n_folds\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(KFold(len(y), n_folds=self.n_folds, shuffle=True, random_state=2016))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "            S_test_i = np.zeros((T.shape[0], len(folds)))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                # y_holdout = y[test_idx]\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_holdout)[:]\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict(T)[:]\n",
    "\n",
    "            S_test[:, i] = S_test_i.mean(1)\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        y_pred = self.stacker.predict(S_test)[:]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
