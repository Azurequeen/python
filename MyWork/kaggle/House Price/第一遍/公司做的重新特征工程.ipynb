{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #数据分析\n",
    "import numpy as np #科学计算\n",
    "\n",
    "import visuals as rs\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import cross_validation\n",
    "from IPython.display import display # 使得我们可以对DataFrame使用display()函数\n",
    "from sklearn import cluster\n",
    "from sklearn import decomposition\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、了解目标数据集和学习目标，合并train和test便于清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看数据集大小\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#确定模型要学习的目标，\n",
    "target='SalePrice'\n",
    "IDcol = 'Id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 82)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#添加一列，合成一个总的data，便于清洗\n",
    "train['source']= 'train'\n",
    "test['source'] = 'test'\n",
    "df=pd.concat([train, test],ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#建立一个空DF，逐项处理特征后填入\n",
    "all_df = pd.DataFrame(index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2576    NaN\n",
       "Name: GarageCond, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[df.index == 2576].GarageCond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、处理缺失值<br><br>\n",
    "- 1、查看缺失值及缺失值的分布情况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#通过neighborhood与LotFrontage，新建特征，代替LotFrontage缺失项（此特征重要，且缺失较多，明显故意的嘛）\n",
    "\n",
    "lot_frontage_by_neighborhood = train[\"LotFrontage\"].groupby(train[\"Neighborhood\"])\n",
    "\n",
    "all_df[\"LotFrontage\"] = df[\"LotFrontage\"]   \n",
    "for key, group in lot_frontage_by_neighborhood:\n",
    "    idx = (df[\"Neighborhood\"] == key) & (df[\"LotFrontage\"].isnull())\n",
    "    all_df.loc[idx, \"LotFrontage\"] = group.median() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对于极少出现的特征值，单独给予1个特征表示\n",
    "\n",
    "\n",
    "\n",
    "# IR2 and IR3 don't appear that often, so just make a distinction\n",
    "# between regular and irregular.\n",
    "data[\"IsRegularLotShape\"] = (data[\"LotShape\"] == \"Reg\") * 1\n",
    "\n",
    "# Most properties are level; bin the other possibilities together\n",
    "# as \"not level\".\n",
    "data[\"IsLandLevel\"] = (data[\"LandContour\"] == \"Lvl\") * 1\n",
    "\n",
    "# Most land slopes are gentle; treat the others as \"not gentle\".\n",
    "data[\"IsLandSlopeGentle\"] = (data[\"LandSlope\"] == \"Gtl\") * 1\n",
    "\n",
    "# Most properties use standard circuit breakers.\n",
    "data[\"IsElectricalSBrkr\"] = (data[\"Electrical\"] == \"SBrkr\") * 1\n",
    "\n",
    "# About 2/3rd have an attached garage.\n",
    "data[\"IsGarageDetached\"] = (data[\"GarageType\"] == \"Detchd\") * 1\n",
    "\n",
    "# Most have a paved drive. Treat dirt/gravel and partial pavement\n",
    "# as \"not paved\".\n",
    "data[\"IsPavedDrive\"] = (data[\"PavedDrive\"] == \"Y\") * 1\n",
    "\n",
    "# The only interesting \"misc. feature\" is the presence of a shed.\n",
    "data[\"HasShed\"] = (data[\"MiscFeature\"] == \"Shed\") * 1.  \n",
    "\n",
    "# If YearRemodAdd != YearBuilt, then a remodeling took place at some point.\n",
    "data[\"Remodeled\"] = (data[\"YearRemodAdd\"] != data[\"YearBuilt\"]) * 1\n",
    "\n",
    "# Did a remodeling happen in the year the house was sold?\n",
    "data[\"RecentRemodel\"] = (data[\"YearRemodAdd\"] == data[\"YrSold\"]) * 1\n",
    "\n",
    "# Was this house sold in the year it was built?\n",
    "data[\"VeryNewHouse\"] = (data[\"YearBuilt\"] == data[\"YrSold\"]) * 1\n",
    "\n",
    "data[\"Has2ndataloor\"] = (data[\"2ndatalrSF\"] == 0) * 1\n",
    "data[\"HasMasVnr\"] = (data[\"MasVnrArea\"] == 0) * 1\n",
    "data[\"HasWoodDeck\"] = (data[\"WoodDeckSF\"] == 0) * 1\n",
    "data[\"HasOpenPorch\"] = (data[\"OpenPorchSF\"] == 0) * 1\n",
    "data[\"HasEnclosedPorch\"] = (data[\"EnclosedPorch\"] == 0) * 1\n",
    "data[\"Has3SsnPorch\"] = (data[\"3SsnPorch\"] == 0) * 1\n",
    "data[\"HasScreenPorch\"] = (data[\"ScreenPorch\"] == 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对于有说明的关于质量等的字符型特征，替换成int的数字\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对于标签进行自动编码\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "def factorize(df, factor_df, column, fill_na=None):\n",
    "    factor_df[column] = df[column]\n",
    "    if fill_na is not None:\n",
    "        factor_df[column].fillna(fill_na, inplace=True)\n",
    "    le.fit(factor_df[column].unique())\n",
    "    factor_df[column] = le.transform(factor_df[column])\n",
    "    return factor_df\n",
    "\n",
    "all_df = factorize(df, all_df, \"MSSubClass\")\n",
    "all_df = factorize(df, all_df, \"MSZoning\", \"RL\")\n",
    "all_df = factorize(df, all_df, \"LotConfig\")\n",
    "all_df = factorize(df, all_df, \"Neighborhood\")\n",
    "all_df = factorize(df, all_df, \"Condition1\")\n",
    "all_df = factorize(df, all_df, \"BldgType\")\n",
    "all_df = factorize(df, all_df, \"HouseStyle\")\n",
    "all_df = factorize(df, all_df, \"RoofStyle\")\n",
    "all_df = factorize(df, all_df, \"Exterior1st\", \"Other\")\n",
    "all_df = factorize(df, all_df, \"Exterior2nd\", \"Other\")\n",
    "all_df = factorize(df, all_df, \"MasVnrType\", \"None\")\n",
    "all_df = factorize(df, all_df, \"Foundation\")\n",
    "all_df = factorize(df, all_df, \"SaleType\", \"Oth\")\n",
    "all_df = factorize(df, all_df, \"SaleCondition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#对于极少出现的特征值，单独给予1个特征表示\n",
    "\n",
    "\n",
    "\n",
    "# IR2 and IR3 don't appear that often, so just make a distinction\n",
    "# between regular and irregular.\n",
    "all_df[\"IsRegularLotShape\"] = (df[\"LotShape\"] == \"Reg\") * 1\n",
    "\n",
    "# Most properties are level; bin the other possibilities together\n",
    "# as \"not level\".\n",
    "all_df[\"IsLandLevel\"] = (df[\"LandContour\"] == \"Lvl\") * 1\n",
    "\n",
    "# Most land slopes are gentle; treat the others as \"not gentle\".\n",
    "all_df[\"IsLandSlopeGentle\"] = (df[\"LandSlope\"] == \"Gtl\") * 1\n",
    "\n",
    "# Most properties use standard circuit breakers.\n",
    "all_df[\"IsElectricalSBrkr\"] = (df[\"Electrical\"] == \"SBrkr\") * 1\n",
    "\n",
    "# About 2/3rd have an attached garage.\n",
    "all_df[\"IsGarageDetached\"] = (df[\"GarageType\"] == \"Detchd\") * 1\n",
    "\n",
    "# Most have a paved drive. Treat dirt/gravel and partial pavement\n",
    "# as \"not paved\".\n",
    "all_df[\"IsPavedDrive\"] = (df[\"PavedDrive\"] == \"Y\") * 1\n",
    "\n",
    "# The only interesting \"misc. feature\" is the presence of a shed.\n",
    "all_df[\"HasShed\"] = (df[\"MiscFeature\"] == \"Shed\") * 1.  \n",
    "\n",
    "# If YearRemodAdd != YearBuilt, then a remodeling took place at some point.\n",
    "all_df[\"Remodeled\"] = (all_df[\"YearRemodAdd\"] != all_df[\"YearBuilt\"]) * 1\n",
    "\n",
    "# Did a remodeling happen in the year the house was sold?\n",
    "all_df[\"RecentRemodel\"] = (all_df[\"YearRemodAdd\"] == all_df[\"YrSold\"]) * 1\n",
    "\n",
    "# Was this house sold in the year it was built?\n",
    "all_df[\"VeryNewHouse\"] = (all_df[\"YearBuilt\"] == all_df[\"YrSold\"]) * 1\n",
    "\n",
    "all_df[\"Has2ndFloor\"] = (all_df[\"2ndFlrSF\"] == 0) * 1\n",
    "all_df[\"HasMasVnr\"] = (all_df[\"MasVnrArea\"] == 0) * 1\n",
    "all_df[\"HasWoodDeck\"] = (all_df[\"WoodDeckSF\"] == 0) * 1\n",
    "all_df[\"HasOpenPorch\"] = (all_df[\"OpenPorchSF\"] == 0) * 1\n",
    "all_df[\"HasEnclosedPorch\"] = (all_df[\"EnclosedPorch\"] == 0) * 1\n",
    "all_df[\"Has3SsnPorch\"] = (all_df[\"3SsnPorch\"] == 0) * 1\n",
    "all_df[\"HasScreenPorch\"] = (all_df[\"ScreenPorch\"] == 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加过这些值，但是得分低了些\n",
    "\n",
    "# all_df[\"HasBasement\"] = df[\"BsmtQual\"].isnull() * 1\n",
    "# all_df[\"HasGarage\"] = df[\"GarageQual\"].isnull() * 1\n",
    "# all_df[\"HasFireplace\"] = df[\"FireplaceQu\"].isnull() * 1\n",
    "# all_df[\"HasFence\"] = df[\"Fence\"].isnull() * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将一些int进行离散化\n",
    "\n",
    "# Months with the largest number of deals may be significant.\n",
    "all_df[\"HighSeason\"] = df[\"MoSold\"].replace( \n",
    "{1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0})\n",
    "\n",
    "all_df[\"NewerDwelling\"] = df[\"MSSubClass\"].replace(\n",
    "{20: 1, 30: 0, 40: 0, 45: 0,50: 0, 60: 1, 70: 0, 75: 0, 80: 0, 85: 0,\n",
    " 90: 0, 120: 1, 150: 0, 160: 0, 180: 0, 190: 0})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#新建一些特征\n",
    "all_df.loc[df.Neighborhood == 'NridgHt', \"Neighborhood_Good\"] = 1\n",
    "all_df.loc[df.Neighborhood == 'Crawfor', \"Neighborhood_Good\"] = 1\n",
    "all_df.loc[df.Neighborhood == 'StoneBr', \"Neighborhood_Good\"] = 1\n",
    "all_df.loc[df.Neighborhood == 'Somerst', \"Neighborhood_Good\"] = 1\n",
    "all_df.loc[df.Neighborhood == 'NoRidge', \"Neighborhood_Good\"] = 1\n",
    "all_df[\"Neighborhood_Good\"].fillna(0, inplace=True)\n",
    "\n",
    "all_df[\"SaleCondition_PriceDown\"] = df.SaleCondition.replace(\n",
    "{'Abnorml': 1, 'Alloca': 1, 'AdjLand': 1, 'Family': 1, 'Normal': 0, 'Partial': 0})\n",
    "\n",
    "# House completed before sale or not\n",
    "all_df[\"BoughtOffPlan\"] = df.SaleCondition.replace(\n",
    "{\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1})\n",
    "\n",
    "all_df[\"BadHeating\"] = df.HeatingQC.replace(\n",
    "{'Ex': 0, 'Gd': 0, 'TA': 0, 'Fa': 1, 'Po': 1})\n",
    "\n",
    "area_cols = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    " 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', \n",
    " 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'LowQualFinSF', 'PoolArea' ]\n",
    "all_df[\"TotalArea\"] = all_df[area_cols].sum(axis=1)\n",
    "\n",
    "all_df[\"TotalArea1st2nd\"] = all_df[\"1stFlrSF\"] + all_df[\"2ndFlrSF\"]\n",
    "\n",
    "all_df[\"Age\"] = 2010 - all_df[\"YearBuilt\"]\n",
    "all_df[\"TimeSinceSold\"] = 2010 - all_df[\"YrSold\"]\n",
    "\n",
    "all_df[\"SeasonSold\"] = all_df[\"MoSold\"].map({12:0, 1:0, 2:0, 3:1, 4:1, 5:1, \n",
    "  6:2, 7:2, 8:2, 9:3, 10:3, 11:3}).astype(int)\n",
    "\n",
    "all_df[\"YearsSinceRemodel\"] = all_df[\"YrSold\"] - all_df[\"YearRemodAdd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#简化一些关于质量的特征\n",
    "\n",
    "# Simplifications of existing features into bad/average/good.\n",
    "all_df[\"SimplOverallQual\"] = all_df.OverallQual.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\n",
    "all_df[\"SimplOverallCond\"] = all_df.OverallCond.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\n",
    "all_df[\"SimplPoolQC\"] = all_df.PoolQC.replace(\n",
    "{1 : 1, 2 : 1, 3 : 2, 4 : 2})\n",
    "all_df[\"SimplGarageCond\"] = all_df.GarageCond.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "all_df[\"SimplGarageQual\"] = all_df.GarageQual.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "all_df[\"SimplFireplaceQu\"] = all_df.FireplaceQu.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "all_df[\"SimplFireplaceQu\"] = all_df.FireplaceQu.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "all_df[\"SimplFunctional\"] = all_df.Functional.replace(\n",
    "{1 : 1, 2 : 1, 3 : 2, 4 : 2, 5 : 3, 6 : 3, 7 : 3, 8 : 4})\n",
    "all_df[\"SimplKitchenQual\"] = all_df.KitchenQual.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "all_df[\"SimplHeatingQC\"] = all_df.HeatingQC.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "all_df[\"SimplBsmtFinType1\"] = all_df.BsmtFinType1.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2})\n",
    "all_df[\"SimplBsmtFinType2\"] = all_df.BsmtFinType2.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2})\n",
    "all_df[\"SimplBsmtCond\"] = all_df.BsmtCond.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "all_df[\"SimplBsmtQual\"] = all_df.BsmtQual.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "all_df[\"SimplExterCond\"] = all_df.ExterCond.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})\n",
    "all_df[\"SimplExterQual\"] = all_df.ExterQual.replace(\n",
    "{1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#处理‘neighborhood’特征（有点乱），根据groupby以后的均值来离散化\n",
    "# Bin by neighborhood (a little arbitrarily). Values were computed by: \n",
    "# train_df[\"SalePrice\"].groupby(train_df[\"Neighborhood\"]).median().sort_values()\n",
    "neighborhood_map = {\n",
    "        \"MeadowV\" : 0,  #  88000\n",
    "        \"IDOTRR\" : 1,   # 103000\n",
    "        \"BrDale\" : 1,   # 106000\n",
    "        \"OldTown\" : 1,  # 119000\n",
    "        \"Edwards\" : 1,  # 119500\n",
    "        \"BrkSide\" : 1,  # 124300\n",
    "        \"Sawyer\" : 1,   # 135000\n",
    "        \"Blueste\" : 1,  # 137500\n",
    "        \"SWISU\" : 2,    # 139500\n",
    "        \"NAmes\" : 2,    # 140000\n",
    "        \"NPkVill\" : 2,  # 146000\n",
    "        \"Mitchel\" : 2,  # 153500\n",
    "        \"SawyerW\" : 2,  # 179900\n",
    "        \"Gilbert\" : 2,  # 181000\n",
    "        \"NWAmes\" : 2,   # 182900\n",
    "        \"Blmngtn\" : 2,  # 191000\n",
    "        \"CollgCr\" : 2,  # 197200\n",
    "        \"ClearCr\" : 3,  # 200250\n",
    "        \"Crawfor\" : 3,  # 200624\n",
    "        \"Veenker\" : 3,  # 218000\n",
    "        \"Somerst\" : 3,  # 225500\n",
    "        \"Timber\" : 3,   # 228475\n",
    "        \"StoneBr\" : 4,  # 278000\n",
    "        \"NoRidge\" : 4,  # 290000\n",
    "        \"NridgHt\" : 4,  # 315000\n",
    "    }\n",
    "all_df[\"NeighborhoodBin\"] = df[\"Neighborhood\"].map(neighborhood_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copy NeighborhoodBin into a temporary DataFrame because we want to use the\n",
    "# unscaled version later on (to one-hot encode it). \n",
    "neighborhood_bin_train = pd.DataFrame(index = df.index)\n",
    "neighborhood_bin_train[\"NeighborhoodBin\"] = all_df[\"NeighborhoodBin\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#讲所有int和float，skew一下，使得整齐\n",
    "\n",
    "numeric_features = all_df.dtypes[all_df.dtypes != \"object\"].index\n",
    "\n",
    "# Transform the skewed numeric features by taking log(feature + 1).\n",
    "# This will make the features more normal.\n",
    "from scipy.stats import skew\n",
    "\n",
    "skewed = all_df[numeric_features].apply(lambda x: skew(x.dropna().astype(float)))\n",
    "skewed = skewed[skewed > 0.75]\n",
    "skewed = skewed.index\n",
    "\n",
    "\n",
    "all_df[skewed] = np.log1p(all_df[skewed])\n",
    "\n",
    "\n",
    "# Additional processing: scale the data.   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_df[numeric_features])\n",
    "\n",
    "scaled = scaler.transform(all_df[numeric_features])\n",
    "for i, col in enumerate(numeric_features):\n",
    "    all_df[col] = scaled[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共0个特征有缺失值\n"
     ]
    }
   ],
   "source": [
    "#查看缺省值\n",
    "data_miss = all_df.isnull().apply(lambda x: x.sum(), axis=0)\n",
    "\n",
    "data_miss = pd.DataFrame({'Index':data_miss.index,'Values':data_miss.values})\n",
    "var=list()\n",
    "for i,j in data_miss.iterrows():\n",
    "    if data_miss.iloc[i,1] > 0:\n",
    "        var.append(data_miss.iloc[i,0])\n",
    "\n",
    "print '共%s个特征有缺失值' % len(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#讲所有字符型的进行OneHot（是否太繁琐，可以直接onehot一下）\n",
    "\n",
    "# Convert categorical features using one-hot encoding.\n",
    "def onehot(onehot_df, df, column_name, fill_na, drop_name):\n",
    "    onehot_df[column_name] = df[column_name]\n",
    "    if fill_na is not None:\n",
    "        onehot_df[column_name].fillna(fill_na, inplace=True)\n",
    "\n",
    "    dummies = pd.get_dummies(onehot_df[column_name], prefix=\"_\" + column_name)\n",
    "    \n",
    "    # Dropping one of the columns actually made the results slightly worse.\n",
    "    # if drop_name is not None:\n",
    "    #     dummies.drop([\"_\" + column_name + \"_\" + drop_name], axis=1, inplace=True)\n",
    "\n",
    "    onehot_df = onehot_df.join(dummies)\n",
    "    onehot_df = onehot_df.drop([column_name], axis=1)\n",
    "    return onehot_df\n",
    "\n",
    "def munge_onehot(df):\n",
    "    onehot_df = pd.DataFrame(index = df.index)\n",
    "\n",
    "    onehot_df = onehot(onehot_df, df, \"MSSubClass\", None, \"40\")\n",
    "    onehot_df = onehot(onehot_df, df, \"MSZoning\", \"RL\", \"RH\")\n",
    "    onehot_df = onehot(onehot_df, df, \"LotConfig\", None, \"FR3\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Neighborhood\", None, \"OldTown\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Condition1\", None, \"RRNe\")\n",
    "    onehot_df = onehot(onehot_df, df, \"BldgType\", None, \"2fmCon\")\n",
    "    onehot_df = onehot(onehot_df, df, \"HouseStyle\", None, \"1.5Unf\")\n",
    "    onehot_df = onehot(onehot_df, df, \"RoofStyle\", None, \"Shed\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Exterior1st\", \"VinylSd\", \"CBlock\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Exterior2nd\", \"VinylSd\", \"CBlock\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Foundation\", None, \"Wood\")\n",
    "    onehot_df = onehot(onehot_df, df, \"SaleType\", \"WD\", \"Oth\")\n",
    "    onehot_df = onehot(onehot_df, df, \"SaleCondition\", \"Normal\", \"AdjLand\")\n",
    "\n",
    "    # Fill in missing MasVnrType for rows that do have a MasVnrArea.\n",
    "    temp_df = df[[\"MasVnrType\", \"MasVnrArea\"]].copy()\n",
    "    idx = (df[\"MasVnrArea\"] != 0) & ((df[\"MasVnrType\"] == \"None\") | (df[\"MasVnrType\"].isnull()))\n",
    "    temp_df.loc[idx, \"MasVnrType\"] = \"BrkFace\"\n",
    "    onehot_df = onehot(onehot_df, temp_df, \"MasVnrType\", \"None\", \"BrkCmn\")\n",
    "\n",
    "    # Also add the booleans from calc_df as dummy variables.\n",
    "    onehot_df = onehot(onehot_df, df, \"LotShape\", None, \"IR3\")\n",
    "    onehot_df = onehot(onehot_df, df, \"LandContour\", None, \"Low\")\n",
    "    onehot_df = onehot(onehot_df, df, \"LandSlope\", None, \"Sev\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Electrical\", \"SBrkr\", \"FuseP\")\n",
    "    onehot_df = onehot(onehot_df, df, \"GarageType\", \"None\", \"CarPort\")\n",
    "    onehot_df = onehot(onehot_df, df, \"PavedDrive\", None, \"P\")\n",
    "    onehot_df = onehot(onehot_df, df, \"MiscFeature\", \"None\", \"Othr\")\n",
    "\n",
    "    # Features we can probably ignore (but want to include anyway to see\n",
    "    # if they make any positive difference).\n",
    "    # Definitely ignoring Utilities: all records are \"AllPub\", except for\n",
    "    # one \"NoSeWa\" in the train set and 2 NA in the test set.\n",
    "    onehot_df = onehot(onehot_df, df, \"Street\", None, \"Grvl\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Alley\", \"None\", \"Grvl\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Condition2\", None, \"PosA\")\n",
    "    onehot_df = onehot(onehot_df, df, \"RoofMatl\", None, \"WdShake\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Heating\", None, \"Wall\")\n",
    "\n",
    "    # I have these as numerical variables too.\n",
    "    onehot_df = onehot(onehot_df, df, \"ExterQual\", \"None\", \"Ex\")\n",
    "    onehot_df = onehot(onehot_df, df, \"ExterCond\", \"None\", \"Ex\")\n",
    "    onehot_df = onehot(onehot_df, df, \"BsmtQual\", \"None\", \"Ex\")\n",
    "    onehot_df = onehot(onehot_df, df, \"BsmtCond\", \"None\", \"Ex\")\n",
    "    onehot_df = onehot(onehot_df, df, \"HeatingQC\", \"None\", \"Ex\")\n",
    "    onehot_df = onehot(onehot_df, df, \"KitchenQual\", \"TA\", \"Ex\")\n",
    "    onehot_df = onehot(onehot_df, df, \"FireplaceQu\", \"None\", \"Ex\")\n",
    "    onehot_df = onehot(onehot_df, df, \"GarageQual\", \"None\", \"Ex\")\n",
    "    onehot_df = onehot(onehot_df, df, \"GarageCond\", \"None\", \"Ex\")\n",
    "    onehot_df = onehot(onehot_df, df, \"PoolQC\", \"None\", \"Ex\")\n",
    "    onehot_df = onehot(onehot_df, df, \"BsmtExposure\", \"None\", \"Gd\")\n",
    "    onehot_df = onehot(onehot_df, df, \"BsmtFinType1\", \"None\", \"GLQ\")\n",
    "    onehot_df = onehot(onehot_df, df, \"BsmtFinType2\", \"None\", \"GLQ\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Functional\", \"Typ\", \"Typ\")\n",
    "    onehot_df = onehot(onehot_df, df, \"GarageFinish\", \"None\", \"Fin\")\n",
    "    onehot_df = onehot(onehot_df, df, \"Fence\", \"None\", \"MnPrv\")\n",
    "    onehot_df = onehot(onehot_df, df, \"MoSold\", None, None)\n",
    "    \n",
    "    # Divide up the years between 1871 and 2010 in slices of 20 years.\n",
    "    year_map = pd.concat(pd.Series(\"YearBin\" + str(i+1), index=range(1871+i*20,1891+i*20)) for i in range(0, 7))\n",
    "\n",
    "    yearbin_df = pd.DataFrame(index = df.index)\n",
    "    yearbin_df[\"GarageYrBltBin\"] = df.GarageYrBlt.map(year_map)\n",
    "    yearbin_df[\"GarageYrBltBin\"].fillna(\"NoGarage\", inplace=True)\n",
    "\n",
    "    yearbin_df[\"YearBuiltBin\"] = df.YearBuilt.map(year_map)\n",
    "    yearbin_df[\"YearRemodAddBin\"] = df.YearRemodAdd.map(year_map)\n",
    "    \n",
    "    onehot_df = onehot(onehot_df, yearbin_df, \"GarageYrBltBin\", None, None)\n",
    "    onehot_df = onehot(onehot_df, yearbin_df, \"YearBuiltBin\", None, None)\n",
    "    onehot_df = onehot(onehot_df, yearbin_df, \"YearRemodAddBin\", None, None)\n",
    "\n",
    "    return onehot_df\n",
    "\n",
    "\n",
    "# Add the one-hot encoded categorical features.\n",
    "onehot_df = munge_onehot(df)\n",
    "onehot_df = onehot(onehot_df, neighborhood_bin_train, \"NeighborhoodBin\", None, None)\n",
    "all_df_munged = all_df.join(onehot_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共0个特征有缺失值\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_miss = all_df_munged.isnull().apply(lambda x: x.sum(), axis=0)\n",
    "\n",
    "data_miss = pd.DataFrame({'Index':data_miss.index,'Values':data_miss.values})\n",
    "var=list()\n",
    "for i,j in data_miss.iterrows():\n",
    "    if data_miss.iloc[i,1] > 0:\n",
    "        var.append(data_miss.iloc[i,0])\n",
    "\n",
    "print '共%s个特征有缺失值' % len(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df_munged['source'] = df['source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、清洗完的数据重新分开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set size:', (1460, 425))\n",
      "('Test set size:', (1459, 425))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahui/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#区分训练集和测试集\n",
    "all_df_munged['source'] = df['source']\n",
    "all_df_munged['Id'] = df['Id']\n",
    "\n",
    "train_df_munged = all_df_munged.loc[all_df_munged['source']=='train']\n",
    "test_df_munged = all_df_munged.loc[all_df_munged['source']=='test']\n",
    "\n",
    "train_df_munged.drop(['source'],axis=1,inplace=True)\n",
    "test_df_munged.drop(['source'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "label_df = pd.DataFrame(index = train_df_munged.index, columns=[\"SalePrice\"])\n",
    "label_df[\"SalePrice\"] = np.log(df[\"SalePrice\"])\n",
    "\n",
    "print(\"Training set size:\", train_df_munged.shape)\n",
    "print(\"Test set size:\", test_df_munged.shape)\n",
    "train_df_munged[\"SalePrice\"] = label_df[\"SalePrice\"]\n",
    "\n",
    "train_df_munged.to_csv('train_modified_12-10.csv',index=False)\n",
    "test_df_munged.to_csv('test_modified_12-10.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       12.247694\n",
       "1       12.109011\n",
       "2       12.317167\n",
       "3       11.849398\n",
       "4       12.429216\n",
       "5       11.870600\n",
       "6       12.634603\n",
       "7       12.206073\n",
       "8       11.774520\n",
       "9       11.678440\n",
       "10      11.771436\n",
       "11      12.751300\n",
       "12      11.877569\n",
       "13      12.540758\n",
       "14      11.964001\n",
       "15      11.790557\n",
       "16      11.911702\n",
       "17      11.407565\n",
       "18      11.976659\n",
       "19      11.842229\n",
       "20      12.692503\n",
       "21      11.845103\n",
       "22      12.345835\n",
       "23      11.774520\n",
       "24      11.944708\n",
       "25      12.454104\n",
       "26      11.811547\n",
       "27      12.631340\n",
       "28      12.242887\n",
       "29      11.134589\n",
       "          ...    \n",
       "1430    12.165980\n",
       "1431    11.875831\n",
       "1432    11.074421\n",
       "1433    12.136187\n",
       "1434    11.982929\n",
       "1435    12.066811\n",
       "1436    11.699405\n",
       "1437    12.885671\n",
       "1438    11.916389\n",
       "1439    12.190959\n",
       "1440    12.160029\n",
       "1441    11.913713\n",
       "1442    12.644328\n",
       "1443    11.703546\n",
       "1444    12.098487\n",
       "1445    11.767568\n",
       "1446    11.969717\n",
       "1447    12.388394\n",
       "1448    11.626254\n",
       "1449    11.429544\n",
       "1450    11.820410\n",
       "1451    12.567551\n",
       "1452    11.884489\n",
       "1453    11.344507\n",
       "1454    12.128111\n",
       "1455    12.072541\n",
       "1456    12.254863\n",
       "1457    12.493130\n",
       "1458    11.864462\n",
       "1459    11.901583\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
