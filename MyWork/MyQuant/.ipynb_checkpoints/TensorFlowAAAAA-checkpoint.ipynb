{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/lda.py:6: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/learning_curve.py:23: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/sklearn/qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tushare as ts\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import *\n",
    "import talib\n",
    "import seaborn as sns\n",
    "\n",
    "from solo.getdata import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "\n",
    "\n",
    "from cs231n.classifiers.cnn import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.solver import Solver\n",
    "from cs231n.convnet import *\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、获取数据\n",
    "## 参数说明：\n",
    "- 'name'：名称\n",
    "- 'start'：开始时间\n",
    "- 'data_type'：数据处理方式，'normal'：原始数据, 'carg'：复合增长率, 'grow'：增长速度\n",
    "- 'ktype' ：时间周期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获得原始数据：\t 399300\n",
      "起始时间：\t 2005-04-08\n",
      "结束时间：\t 2017-03-07\n",
      "数据个数：\t 2895\n",
      "\n",
      "      open    close     high     low      volume\n",
      "0   984.66  1003.45  1003.70  979.53  14762500.0\n",
      "1  1003.88   995.42  1008.73  992.77  15936100.0\n",
      "2   993.71   978.70   993.71  978.20  10226200.0\n",
      "3   987.95  1000.90  1006.50  987.95  16071700.0\n",
      "4  1004.64   986.97  1006.42  985.58  12945700.0\n",
      "\n",
      "查看最新数据：\n",
      "\n",
      "                open      high     close       low    volume\n",
      "2005-04-11  0.019519  0.005011 -0.008002  0.013517  0.079499\n",
      "2005-04-12 -0.010131 -0.014890 -0.016797 -0.014676 -0.358300\n",
      "2005-04-13 -0.005796  0.012871  0.022683  0.009967  0.571620\n",
      "2005-04-14  0.016894 -0.000079 -0.013917 -0.002399 -0.194503\n",
      "2005-04-15 -0.021928 -0.023658 -0.013060 -0.013850 -0.195949\n"
     ]
    }
   ],
   "source": [
    "new_data = data_recieve(name='399300',start = '2004-10-01',data_type = 'carg',ktype='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 二、建立特征\n",
    "## 参数说明：\n",
    "- 'data'：数据集\n",
    "- 'time'：多个时间周期\n",
    "- 'normal'：是否对数据进行归一化\n",
    "- 'pattern' ：是否加入k模式识别\n",
    "- 'period' ：预测的天数，默认为1，即用当天的特征预测第二天的值，该值为累加，如设为n，即用n天前的特征预测到今日的累积变化值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_datas = data_indicator(data=new_data,time=[5,10,20,30,60],normal=True,period=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 三、设定X和Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_datas['Price'] = pd.qcut(ml_datas['target'],10) #将target进行10等分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.24, -2.00781], (-2.00781, -1.0489], (-1.0489, -0.554], (-0.554, -0.182], (-0.182, 0.0952], (0.0952, 0.379], (0.379, 0.749], (0.749, 1.33], (1.33, 2.205], (2.205, 9.342]]\n",
      "Categories (10, object): [[-9.24, -2.00781] < (-2.00781, -1.0489] < (-1.0489, -0.554] < (-0.554, -0.182] ... (0.379, 0.749] < (0.749, 1.33] < (1.33, 2.205] < (2.205, 9.342]]\n"
     ]
    }
   ],
   "source": [
    "#y设定为符合增长率求整\n",
    "X_ori = ml_datas.drop(['target','Price'],axis=1).values\n",
    "y_ori = ml_datas['Price'].values\n",
    "#y_ori = y_ori.reshape([y_ori.shape[0],1])\n",
    "y_ori = pd.get_dummies(y_ori)\n",
    "y_columns = y_ori.columns.values\n",
    "print(y_columns)\n",
    "y_ori = y_ori.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2539, 784), (2539, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ori.shape,y_ori.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四、转换格式\n",
    "## 将原2维数组(N,D)转换成（N,D,H,W）的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五、用TensorFlow做个CNN看下效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X_ori, y_ori, test_size=0.33, random_state=42)\n",
    "small_data = {\n",
    "  'X_train': X_train,\n",
    "  'y_train': y_train,\n",
    "  'X_val': X_test,\n",
    "  'y_val': y_test,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "y = tf.matmul(x,W) + b\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "for _ in range(1000):\n",
    "  \n",
    "  train_step.run(feed_dict={x: X_train, y_: y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.131265\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval(feed_dict={x:X_test, y_: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-6).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.101705\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(5000):\n",
    "  \n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "                    x:X_train, y_: y_train, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x:X_train, y_: y_train, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x:X_test, y_: y_test, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
