{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from yahoo_finance import Share\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from bn_class import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Hyperparameters\"\"\"\n",
    "num_filt_1 = 15     #Number of filters in first conv layer\n",
    "num_filt_2 = 8      #Number of filters in second conv layer\n",
    "num_filt_3 = 8      #Number of filters in thirs conv layer\n",
    "num_fc_1 = 1024     #Number of neurons in hully connected layer\n",
    "max_iterations = 8000\n",
    "model_num=7         #Number of model used for voting\n",
    "voting_times=3      #Threshold of voting\n",
    "batch_size = 100\n",
    "dropout = 0.5       #Dropout rate in the fully connected layer\n",
    "plot_row = 5        #How many rows do you want to plot in the visualization\n",
    "regularization = 1e-4\n",
    "learning_rate = 2e-3\n",
    "input_norm = False   # Do you want z-score input normalization?\n",
    "np.set_printoptions(threshold=np.inf)#print full array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = \"2330\"\n",
    "datadir = 'data/'+ dataset\n",
    "data_train = np.loadtxt(datadir+'_train_15',delimiter=',')\n",
    "data_test_val = np.loadtxt(datadir+'_test',delimiter=',')\n",
    "data_test=data_test_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## split training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = data_train[:,1:]\n",
    "X_test = data_test[:,1:]\n",
    "N = X_train.shape[0]\n",
    "Ntest = X_test.shape[0]\n",
    "D = X_train.shape[1]\n",
    "y_train = data_train[:,0]\n",
    "y_test = data_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "base = np.min(y_train)  #Check if data is 0-based\n",
    "if base != 0:\n",
    "    y_train -=base\n",
    "    y_test -= base\n",
    "\n",
    "if input_norm:\n",
    "    mean = np.mean(X_train,axis=0)\n",
    "    variance = np.var(X_train,axis=0)\n",
    "    X_train -= mean\n",
    "    #The 1e-9 avoids dividing by zero\n",
    "    X_train /= np.sqrt(variance)+1e-9\n",
    "    X_test -= mean\n",
    "    X_test /= np.sqrt(variance)+1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with approximately 1467 epochs\n"
     ]
    }
   ],
   "source": [
    "epochs = np.floor(batch_size*max_iterations / N)\n",
    "print('Train with approximately %d epochs' %(epochs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## place for the input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at model 0\n",
      " Training accuracy at 0 out of 8000 is 0.286239\n",
      " Training accuracy at 1000 out of 8000 is 0.954128\n",
      " Training accuracy at 2000 out of 8000 is 0.954128\n",
      " Training accuracy at 3000 out of 8000 is 0.954128\n",
      " Training accuracy at 4000 out of 8000 is 0.961468\n",
      " Training accuracy at 5000 out of 8000 is 0.961468\n",
      " Training accuracy at 6000 out of 8000 is 0.972477\n",
      " Training accuracy at 7000 out of 8000 is 0.974312\n",
      "Training at model 1\n",
      " Training accuracy at 0 out of 8000 is 0.8\n",
      " Training accuracy at 1000 out of 8000 is 0.954128\n",
      " Training accuracy at 2000 out of 8000 is 0.954128\n",
      " Training accuracy at 3000 out of 8000 is 0.954128\n",
      " Training accuracy at 4000 out of 8000 is 0.957798\n",
      " Training accuracy at 5000 out of 8000 is 0.987156\n",
      " Training accuracy at 6000 out of 8000 is 1.0\n",
      " Training accuracy at 7000 out of 8000 is 0.99633\n",
      "Training at model 2\n",
      " Training accuracy at 0 out of 8000 is 0.8\n",
      " Training accuracy at 1000 out of 8000 is 0.952294\n",
      " Training accuracy at 2000 out of 8000 is 0.954128\n",
      " Training accuracy at 3000 out of 8000 is 0.954128\n",
      " Training accuracy at 4000 out of 8000 is 0.955963\n",
      " Training accuracy at 5000 out of 8000 is 0.959633\n",
      " Training accuracy at 6000 out of 8000 is 0.959633\n",
      " Training accuracy at 7000 out of 8000 is 0.961468\n",
      "Training at model 3\n",
      " Training accuracy at 0 out of 8000 is 0.8\n",
      " Training accuracy at 1000 out of 8000 is 0.952294\n",
      " Training accuracy at 2000 out of 8000 is 0.952294\n",
      " Training accuracy at 3000 out of 8000 is 0.961468\n",
      " Training accuracy at 4000 out of 8000 is 0.987156\n",
      " Training accuracy at 5000 out of 8000 is 0.994495\n",
      " Training accuracy at 6000 out of 8000 is 0.985321\n",
      " Training accuracy at 7000 out of 8000 is 0.998165\n",
      "Training at model 4\n",
      " Training accuracy at 0 out of 8000 is 0.2\n",
      " Training accuracy at 1000 out of 8000 is 0.952294\n",
      " Training accuracy at 2000 out of 8000 is 0.955963\n",
      " Training accuracy at 3000 out of 8000 is 0.961468\n",
      " Training accuracy at 4000 out of 8000 is 0.961468\n",
      " Training accuracy at 5000 out of 8000 is 0.974312\n",
      " Training accuracy at 6000 out of 8000 is 0.99633\n",
      " Training accuracy at 7000 out of 8000 is 0.992661\n",
      "Training at model 5\n",
      " Training accuracy at 0 out of 8000 is 0.2\n",
      " Training accuracy at 1000 out of 8000 is 0.954128\n",
      " Training accuracy at 2000 out of 8000 is 0.952294\n",
      " Training accuracy at 3000 out of 8000 is 0.954128\n",
      " Training accuracy at 4000 out of 8000 is 0.961468\n",
      " Training accuracy at 5000 out of 8000 is 0.959633\n",
      " Training accuracy at 6000 out of 8000 is 0.994495\n",
      " Training accuracy at 7000 out of 8000 is 0.99633\n",
      "Training at model 6\n",
      " Training accuracy at 0 out of 8000 is 0.917431\n",
      " Training accuracy at 1000 out of 8000 is 0.954128\n",
      " Training accuracy at 2000 out of 8000 is 0.955963\n",
      " Training accuracy at 3000 out of 8000 is 0.954128\n",
      " Training accuracy at 4000 out of 8000 is 0.959633\n",
      " Training accuracy at 5000 out of 8000 is 0.981651\n",
      " Training accuracy at 6000 out of 8000 is 0.990826\n",
      " Training accuracy at 7000 out of 8000 is 0.988991\n"
     ]
    }
   ],
   "source": [
    "total_rst=np.zeros((model_num,len(y_test)), dtype=np.float)\n",
    "for xx in xrange(0,model_num):\n",
    "  print(\"Training at model \"+str(xx))\n",
    "  x = tf.placeholder(\"float\", shape=[None, D], name = 'Input_data')\n",
    "  y_ = tf.placeholder(tf.int64, shape=[None], name = 'Ground_truth')\n",
    "  keep_prob = tf.placeholder(\"float\")\n",
    "  bn_train = tf.placeholder(tf.bool)          #Boolean value to guide batchnorm\n",
    "\n",
    "  ## w and b and conv function\n",
    "  def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name = name)\n",
    "\n",
    "  def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name = name)\n",
    "\n",
    "  def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "  def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "  with tf.name_scope(\"Reshaping_data\") as scope:\n",
    "    x_image = tf.reshape(x, [-1,D,1,1])\n",
    "\n",
    "  ## Build the graph\n",
    "  # ewma is the decay for which we update the moving average of the \n",
    "  # mean and variance in the batch-norm layers\n",
    "  with tf.name_scope(\"Conv1\") as scope:\n",
    "    W_conv1 = weight_variable([4, 1, 1, num_filt_1], 'Conv_Layer_1')\n",
    "    b_conv1 = bias_variable([num_filt_1], 'bias_for_Conv_Layer_1')\n",
    "    a_conv1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "    \n",
    "  with tf.name_scope('Batch_norm_conv1') as scope:\n",
    "      ewma = tf.train.ExponentialMovingAverage(decay=0.99)                  \n",
    "      bn_conv1 = ConvolutionalBatchNormalizer(num_filt_1, 0.001, ewma, True)           \n",
    "      update_assignments = bn_conv1.get_assigner() \n",
    "      a_conv1 = bn_conv1.normalize(a_conv1, train=bn_train) \n",
    "      h_conv1 = tf.nn.relu(a_conv1)\n",
    "    \n",
    "  with tf.name_scope(\"Conv2\") as scope:\n",
    "    W_conv2 = weight_variable([4, 1, num_filt_1, num_filt_2], 'Conv_Layer_2')\n",
    "    b_conv2 = bias_variable([num_filt_2], 'bias_for_Conv_Layer_2')\n",
    "    a_conv2 = conv2d(h_conv1, W_conv2) + b_conv2\n",
    "    \n",
    "  with tf.name_scope('Batch_norm_conv2') as scope:\n",
    "      bn_conv2 = ConvolutionalBatchNormalizer(num_filt_2, 0.001, ewma, True)           \n",
    "      update_assignments = bn_conv2.get_assigner() \n",
    "      a_conv2 = bn_conv2.normalize(a_conv2, train=bn_train) \n",
    "      h_conv2 = tf.nn.relu(a_conv2)\n",
    "      \n",
    "  with tf.name_scope(\"Conv3\") as scope:\n",
    "    W_conv3 = weight_variable([4, 1, num_filt_2, num_filt_3], 'Conv_Layer_3')\n",
    "    b_conv3 = bias_variable([num_filt_3], 'bias_for_Conv_Layer_3')\n",
    "    a_conv3 = conv2d(h_conv2, W_conv3) + b_conv3\n",
    "    \n",
    "  with tf.name_scope('Batch_norm_conv3') as scope:\n",
    "      bn_conv3 = ConvolutionalBatchNormalizer(num_filt_3, 0.001, ewma, True)           \n",
    "      update_assignments = bn_conv3.get_assigner() \n",
    "      a_conv3 = bn_conv3.normalize(a_conv3, train=bn_train) \n",
    "      h_conv3 = tf.nn.relu(a_conv3)\n",
    "\n",
    "  with tf.name_scope(\"Fully_Connected1\") as scope:\n",
    "    W_fc1 = weight_variable([D*num_filt_3, num_fc_1], 'Fully_Connected_layer_1')\n",
    "    b_fc1 = bias_variable([num_fc_1], 'bias_for_Fully_Connected_Layer_1')\n",
    "    h_conv3_flat = tf.reshape(h_conv3, [-1, D*num_filt_3])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv3_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "  with tf.name_scope(\"Fully_Connected2\") as scope:\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    W_fc2 = tf.Variable(tf.truncated_normal([num_fc_1, num_classes], stddev=0.1),name = 'W_fc2')\n",
    "    b_fc2 = tf.Variable(tf.constant(0.1, shape=[num_classes]),name = 'b_fc2')\n",
    "    h_fc2 = tf.matmul(h_fc1_drop, W_fc2) + b_fc2   \n",
    "  with tf.name_scope(\"SoftMax\") as scope:\n",
    "      regularizers = (tf.nn.l2_loss(W_conv1) + tf.nn.l2_loss(b_conv1) +\n",
    "                    tf.nn.l2_loss(W_conv2) + tf.nn.l2_loss(b_conv2) + \n",
    "                    tf.nn.l2_loss(W_conv3) + tf.nn.l2_loss(b_conv3) +\n",
    "                    tf.nn.l2_loss(W_fc1) + tf.nn.l2_loss(b_fc1) + \n",
    "                    tf.nn.l2_loss(W_fc2) + tf.nn.l2_loss(b_fc2))\n",
    "\n",
    "      loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=h_fc2,labels=y_)\n",
    "      cost = tf.reduce_sum(loss) / batch_size\n",
    "      cost += regularization*regularizers\n",
    " \n",
    "  ## define train optimizer##\n",
    "  with tf.name_scope(\"train\") as scope:\n",
    "      tvars = tf.trainable_variables()\n",
    "      #We clip the gradients to prevent explosion\n",
    "      grads = tf.gradients(cost, tvars)\n",
    "      optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "      gradients = zip(grads, tvars)\n",
    "      train_step = optimizer.apply_gradients(gradients)\n",
    "\n",
    "  with tf.name_scope(\"Evaluating_accuracy\") as scope:\n",
    "      correct_prediction = tf.equal(tf.argmax(h_fc2,1), y_)\n",
    "      accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "  \n",
    "  ## run session and evaluate performance##\n",
    "  perf_collect = np.zeros((3,int(np.floor(max_iterations /100))))\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0      # Step is a counter for filling the numpy array perf_collect\n",
    "    for i in range(max_iterations):#training process\n",
    "      batch_ind = np.random.choice(N,batch_size,replace=False)\n",
    "      \n",
    "      if i==0:\n",
    "          acc_test_before = sess.run(accuracy, feed_dict={ x: X_test, y_: y_test, keep_prob: 1.0, bn_train : False})\n",
    "      if i%1000 == 0:\n",
    "        #Check training performance\n",
    "        result = sess.run(accuracy,feed_dict = { x: X_train, y_: y_train, keep_prob: 1.0, bn_train : False})\n",
    "        print(\" Training accuracy at %s out of %s is %s\" % (i,max_iterations, result))\n",
    "        step +=1\n",
    "      sess.run(train_step,feed_dict={x:X_train[batch_ind], y_: y_train[batch_ind], keep_prob: dropout, bn_train : True})\n",
    "      \n",
    "            #training process done!\n",
    "    predict=sess.run(tf.argmax(h_fc2,1), feed_dict={ x: X_test, y_: y_test, keep_prob: 1.0, bn_train : False})\n",
    "    total_rst[xx]=predict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "history data counts: 287\n",
      "after remove Volume is 0 : 271\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAEHCAYAAADrmJwnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4gXARJY/hwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aa86ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " ## show the graph of voting result\n",
    "rst_arr= np.zeros(len(total_rst[0]), dtype=np.float)\n",
    "for i in xrange(0,len(total_rst[0])):\n",
    "    voting=0\n",
    "    for j in xrange(0,len(total_rst)):\n",
    "        if(total_rst[j,i]==1):\n",
    "            voting+=1\n",
    "    if(voting>voting_times):\n",
    "            rst_arr[i]=1\n",
    "    else:\n",
    "            rst_arr[i]=0\n",
    "print(rst_arr)\n",
    "\n",
    "## get stock price and draw\n",
    "stock = Share('2330.TW') #which stock to evaluate\n",
    "startDay='2015-07-14'\n",
    "endDay='2016-08-19'\n",
    "stock_data = stock.get_historical(startDay,endDay)\n",
    "print 'history data counts:' , len(stock_data)\n",
    "stock_data.reverse() \n",
    "def remove(stock_data):\n",
    "    i = 0\n",
    "    while( i < len(stock_data)):\n",
    "        if (int(stock_data[i].get('Volume')) <= 0):\n",
    "            stock_data.remove(stock_data[i])\n",
    "            i = -1\n",
    "        i += 1\n",
    "    return stock_data\n",
    "\n",
    "stock_data=remove(stock_data)\n",
    "print 'after remove Volume is 0 :', len(stock_data)\n",
    "close_line= np.zeros(len(stock_data), dtype=np.float)\n",
    "for x in xrange(0,len(stock_data)):\n",
    "    close_line[x]=float(stock_data[x].get(\"Close\"))\n",
    "\n",
    "#draw pic\n",
    "plt.figure()\n",
    "new_buy= np.zeros(len(close_line), dtype=np.float)\n",
    "for i in xrange(0,len(rst_arr)):\n",
    "    new_buy[i+9]=rst_arr[i]*close_line[i+9]\n",
    "plt.plot(close_line,label='closePrice',linewidth=5,color=[0,0,1])\n",
    "plt.plot(new_buy, 'ro',label='Buy at',linewidth=1,color=[1,0,0])\n",
    "plt.title(\"When To Buy?(\"+startDay+\"~\"+endDay+\")\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
