{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "% matplotlib inline\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from yahoo_finance import Share\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.image as pimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 使输出的参数完全显示  \n",
    "\n",
    "> 若没有这一句，因为参数太多，中间会以省略号“……”的形式代替 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)#print full array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 每个sample使用多少天的数据\n",
    "\n",
    "> 使用哪一个标的进行计算\n",
    "\n",
    "> 设定today为今日\n",
    "\n",
    "> 设定stock_data为距今1年内的价格\n",
    "\n",
    "> 设定stock_data2为距今2年内的价格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history data counts: 255\n"
     ]
    }
   ],
   "source": [
    "day_len = 15   \n",
    "stock = Share('2330.TW') \n",
    "today = datetime.date.today()       \n",
    "stock_data = stock.get_historical('2015-09-01','2016-08-24')        \n",
    "stock_data2 = stock.get_historical('2014-09-01', '2016-08-24')      \n",
    "print 'history data counts:' , len(stock_data)\n",
    "stock_data.reverse() \n",
    "stock_data2.reverse() \n",
    "create_img='false' #test data existed? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 定义remove函数，逐行检查并去除volume小于等于0的行\n",
    "\n",
    "> 输出去除的行数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after remove Volume is 0 : 240\n"
     ]
    }
   ],
   "source": [
    "# remove empty data\n",
    "def remove(stock_data):\n",
    "    i = 0\n",
    "    while( i < len(stock_data)):\n",
    "        if (int(stock_data[i].get('Volume')) <= 0):\n",
    "            stock_data.remove(stock_data[i])\n",
    "            i = -1\n",
    "        i += 1\n",
    "    return stock_data\n",
    "\n",
    "stock_data=remove(stock_data)\n",
    "print 'after remove Volume is 0 :', len(stock_data)\n",
    "stock_data2=remove(stock_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define each line, prepare to draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 设置年、季、月线\n",
    "\n",
    "> 定义year2011：2年数据比1年数据多多少\n",
    "\n",
    "> 计算年、季、月线值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yearline={}\n",
    "monthline={}\n",
    "seasonline={}\n",
    "\n",
    "#def yearline()\n",
    "year2011=len(stock_data2)-len(stock_data)\n",
    "for i in xrange(0,len(stock_data)):\n",
    "    year=0\n",
    "    season=0\n",
    "    month=0\n",
    "    for j in xrange(0,year2011):\n",
    "        year+=float(stock_data2[i+j].get('Close'))\n",
    "    yearline[i]=float(year/year2011)\n",
    "#def seasonline()\n",
    "    for j in xrange(0,61):\n",
    "        season+=float(stock_data2[year2011-61+i+j].get('Close'))\n",
    "    seasonline[i]=float(season/61)\n",
    "#def monthline()  \n",
    "    for j in xrange(0,13):\n",
    "        month+=float(stock_data2[year2011-13+i+j].get('Close'))\n",
    "    monthline[i]=float(month/13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> my_train: np.zeros([1年数据-时间窗口，时间窗口])\n",
    "\n",
    "> my_img: np.zeros([my_train，64,64])\n",
    "\n",
    "> new_img: np.zeros([my_train，64,64,2])\n",
    "\n",
    "> ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_train = np.zeros((len(stock_data)-day_len, day_len), dtype=np.float)\n",
    "my_img= np.zeros((len(my_train),64,64), dtype=np.float)\n",
    "new_img= np.zeros((len(my_train),64,64,2), dtype=np.float)\n",
    "my_year = np.zeros((len(stock_data)-day_len, day_len), dtype=np.float)\n",
    "year_img= np.zeros((len(my_train),64,64), dtype=np.float)\n",
    "my_season = np.zeros((len(stock_data)-day_len, day_len), dtype=np.float)\n",
    "my_month = np.zeros((len(stock_data)-day_len, day_len), dtype=np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 收益 > earn && 损失 < loss 的，用本身的值表示Label，否则Label = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real label\n",
      "[ 15.   15.5  14.   13.   13.   14.5  14.   14.   13.5  14.5  16.   15.\n",
      "  -7.   14.5  14.5  -8.5  14.5  14.   -7.5  -7.   14.5  -8.5  -8.5  -7.5\n",
      "  14.   14.5  14.5  14.5  -8.   -8.5  -7.5  -8.5  -9.   -8.   14.5  -7.\n",
      "  15.   16.   -7.   14.   -7.5  -8.   -8.   -8.   -8.   -9.5  -7.5  -7.5\n",
      "  -9.5  -9.5  -9.5  -7.5  -8.   -9.5  -7.5  -8.   -8.   -7.5  14.   -8.\n",
      "  -9.5  -9.   -8.5  -9.   -8.5  -9.   -7.5  -8.   -9.   -9.5  -7.5  -8.\n",
      "  14.   15.5  14.5  13.5  14.5  14.5  14.   14.5  14.   14.   14.   13.5\n",
      "  16.   14.5  14.5  14.5  14.5  14.5  15.5  14.5  16.   15.5  15.   18.\n",
      "  17.5  31.   31.   31.   16.   17.5  31.5  16.5  -8.   -9.   -8.   -8.5\n",
      "  -8.   -8.   -9.   -8.5  -8.   -8.5  -8.5  -8.5  -8.5  -9.5 -10.   -8.5\n",
      "  -9.5  -8.5  -8.   -9.   -9.   -8.5  -8.5  -8.5  -9.5  -8.5 -10.   -8.5\n",
      "  -8.5  -8.5  -8.5  -9.5  -8.  -10.   -8.   -9.5  -9.  -10.   -8.   -9.\n",
      "  -9.   15.5  18.   15.   18.   17.5  18.   15.   15.   15.   15.   14.5\n",
      "  15.   15.   15.   17.   28.   31.   27.5  27.   25.5  25.   25.5  23.\n",
      "  23.   21.5  21.   20.  -10.  -20.   16.5  16.5  16.5  16.5  16.5  16.5\n",
      " -10.  -10.5  -8.5  16.   16.5  16.   16.   17.    0.    0.    0.   16.5\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(my_train)):\n",
    "    for j in range(0, day_len):\n",
    "        my_train[i,j] = float(stock_data[i+j].get('Close'))\n",
    "        my_year[i,j] = yearline[i+j]\n",
    "        my_month[i,j] = monthline[i+j]\n",
    "        my_season[i,j] = seasonline[i+j]\n",
    "\n",
    "\n",
    "label_test= np.zeros(len(my_train), dtype=np.float)\n",
    "\n",
    "#set reward\n",
    "earn=10\n",
    "loss=-5\n",
    "for x in xrange(0,len(my_train)):\n",
    "    for y in xrange(0,500):# in the next 500 days reach 10 or-5\n",
    "        if(x+y+1<len(my_train)):\n",
    "\n",
    "            if((my_train[x+y+1][day_len-1]-my_train[x][day_len-1])/my_train[x][day_len-1]*100>earn):\n",
    "                label_test[x]=my_train[x+y+1][day_len-1]-my_train[x][day_len-1]\n",
    "                break\n",
    "            elif((my_train[x+y+1][day_len-1]-my_train[x][day_len-1])/my_train[x][day_len-1]*100<loss):\n",
    "                label_test[x]=my_train[x+y+1][day_len-1]-my_train[x][day_len-1]\n",
    "                break\n",
    "        else:\n",
    "            label_test[x]=0\n",
    "print(\"real label\")            \n",
    "print(label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## draw image and load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 归一化数据，归一化到y轴[-6，6]\n",
    "\n",
    "> 用plt画图\n",
    "\n",
    "> 保存图像，然后再读取图像，reshape成[4，64，64]的彩图\n",
    "\n",
    "> 用img_gray将图像再降维成[64,64]的图/数组\n",
    "\n",
    "> 设定此为训练集\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis y draw min -6, max 6\n"
     ]
    }
   ],
   "source": [
    "def img_gray(my_img):\n",
    "    new_img= np.zeros((64,64), dtype=np.float)\n",
    "    for x in xrange(0,len(my_img)):\n",
    "        for y in xrange(0,len(my_img[x])):\n",
    "            if (my_img[x,y,0]!=1 and my_img[x,y,1]!=1):\n",
    "                new_img[x,y]=0.7\n",
    "            elif (my_img[x,y,0]!=1 and my_img[x,y,2]!=1):\n",
    "                new_img[x,y]=0\n",
    "            elif (my_img[x,y,1]!=1 and my_img[x,y,2]!=1):\n",
    "                new_img[x,y]=0.35\n",
    "            else:\n",
    "                new_img[x,y]=1\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def normalize(li):#a list for create image\n",
    "    mean=sum(li) / float(len(li))\n",
    "    for i in xrange(0,len(li)):\n",
    "        li[i]=li[i]-mean\n",
    "    return li\n",
    "## yearline\n",
    "#if(create_img=='true'):\n",
    "if True:\n",
    "  #normalize\n",
    "  for i in range(0, len(my_train)-1):\n",
    "      my_train[i]=normalize(my_train[i])\n",
    "      my_year[i]=normalize(my_year[i])\t\n",
    "      my_month[i]=normalize(my_month[i])\t\n",
    "      my_season[i]=normalize(my_season[i])\t\n",
    "\n",
    "  min_y=-6\n",
    "  max_y=6\n",
    "  print(\"axis y draw min \"+str(min_y)+\", max \"+str(max_y))\n",
    "  for x in xrange(0,len(my_year)):#save file\n",
    "      #plt.figure()\n",
    "      #print(\"saving pic:\"+str(x))\n",
    "      plt.plot(my_year[x],label='year_close',linewidth=5,color=[0,0,1])\n",
    "      plt.plot(my_month[x],label='month_close',linewidth=5,color=[0,1,0])\n",
    "      plt.plot(my_season[x],label='season_close',linewidth=5,color=[1,0,0])\n",
    "      plt.axis([0, 14, min_y, max_y])\n",
    "      plt.axis('off')\n",
    "      plt.savefig('year_test/'+str(x)+'.png')\n",
    "      plt.close()\n",
    "\n",
    "for x in xrange(0,len(my_train)-day_len-1):#load file\n",
    "    img = pimg.imread('year_test/'+str(x)+'.png')\n",
    "    img2=cv2.resize(img,(64,64)) \n",
    "    my_img[x]=img_gray(img2)\n",
    "    \n",
    "##end yearline\n",
    "my_test=my_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## action and reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TWStock():\n",
    "    def __init__(self, stock_data,label):\n",
    "        self.stock_data = stock_data\n",
    "        self.stock_index = 0\n",
    "        self.label=label\n",
    "    def render(self):\n",
    "        # 尚未實作\n",
    "        return \n",
    "    \n",
    "    def reset(self):\n",
    "        self.stock_index = 0\n",
    "        return self.stock_data[self.stock_index]\n",
    "    \n",
    "    # 0: 觀望, 1: 持有多單, 2: 持有空單\n",
    "    def step(self, action): \n",
    "        self.stock_index += 1\n",
    "\n",
    "        action_reward=self.label[self.stock_index]\n",
    "        if (action == 0):\n",
    "            action_reward = 0\n",
    "\n",
    "        #if (action == 2):\n",
    "        #    action_reward = -1 * action_reward\n",
    "        #print(str(action)+\" \"+str(action_reward))\n",
    "\n",
    "        cv2.imshow('image',self.stock_data[self.stock_index])\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        stock_done = False\n",
    "        if self.stock_index >= len(self.stock_data)-1:\n",
    "            stock_done = True\n",
    "        else:\n",
    "            stock_done = False\n",
    "        return self.stock_data[self.stock_index], action_reward, stock_done, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN network define and agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W,s):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, s,s,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters for DQN\n",
    "GAMMA = 0.9 # discount factor for target Q\n",
    "INITIAL_EPSILON = 0.5 # starting value of epsilon\n",
    "FINAL_EPSILON = 0.01 # final value of epsilon\n",
    "REPLAY_SIZE = 10000 # experience replay buffer size\n",
    "BATCH_SIZE = 32 # size of minibatch\n",
    "\n",
    "class DQN():\n",
    "  # DQN Agent\n",
    "  def __init__(self, env):\n",
    "    # init experience replay\n",
    "    self.replay_buffer = deque()\n",
    "\n",
    "    # init some parameters\n",
    "    self.time_step = 0\n",
    "    self.epsilon = INITIAL_EPSILON\n",
    "    \n",
    "    #self.state_dim = env.observation_space.shape[0]\n",
    "    #self.action_dim = env.action_space.n\n",
    "    \n",
    "    self.state_dim = day_len\n",
    "    self.action_dim = 2\n",
    "\n",
    "\n",
    "    self.create_Q_network()\n",
    "    self.create_training_method()\n",
    "\n",
    "     # saving and loading networks\n",
    "    self.saver = tf.train.Saver()\n",
    "    self.session = tf.InteractiveSession()\n",
    "    self.session.run(tf.global_variables_initializer())\n",
    "    checkpoint = tf.train.get_checkpoint_state(\"saved_year_r\")\n",
    "    if checkpoint and checkpoint.model_checkpoint_path:\n",
    "        self.saver.restore(self.session, checkpoint.model_checkpoint_path)\n",
    "        print \"Successfully loaded:\", checkpoint.model_checkpoint_path\n",
    "    else:\n",
    "        print \"Could not find old network weights\"\n",
    "\n",
    "\n",
    "  def create_Q_network(self):\n",
    "    #-----------------------end cnn   start\n",
    "         \n",
    "        # network weights\n",
    "    W_conv1 = self.weight_variable([8,8,1,32])\n",
    "    b_conv1 = self.bias_variable([32])\n",
    "\n",
    "    W_conv2 = self.weight_variable([4,4,32,64])\n",
    "    b_conv2 = self.bias_variable([64])\n",
    "\n",
    "    W_conv3 = self.weight_variable([3,3,64,64])\n",
    "    b_conv3 = self.bias_variable([64])\n",
    "\n",
    "    W_fc1 = self.weight_variable([1024,512])\n",
    "    b_fc1 = self.bias_variable([512])\n",
    "\n",
    "    W_fc2 = self.weight_variable([512,self.action_dim])\n",
    "    b_fc2 = self.bias_variable([self.action_dim])\n",
    "\n",
    "    # input layer\n",
    "\n",
    "    self.state_input = tf.placeholder(\"float\",[None,64,64])\n",
    "    input1=tf.reshape(self.state_input,[-1,64,64,1])  \n",
    "\n",
    "    # hidden layers\n",
    "    h_conv1 = tf.nn.relu(conv2d(input1,W_conv1,4) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2,2) + b_conv2)\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2,W_conv3,1) + b_conv3)\n",
    "    h_conv3_shape = h_conv3.get_shape().as_list()\n",
    "    print \"dimension:\",h_conv3_shape[1]*h_conv3_shape[2]*h_conv3_shape[3]\n",
    "    h_conv3_flat = tf.reshape(h_conv3,[-1,1024])\n",
    "\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv3_flat,W_fc1) + b_fc1)\n",
    "\n",
    "    # Q Value layer\n",
    "    self.Q_value = tf.matmul(h_fc1,W_fc2) + b_fc2\n",
    "\n",
    "\n",
    "\n",
    "  def create_training_method(self):\n",
    "    self.action_input = tf.placeholder(\"float\",[None,self.action_dim])\n",
    "    # one hot presentation\n",
    "    self.y_input = tf.placeholder(\"float\",[None])\n",
    "    Q_action = tf.reduce_sum(tf.multiply(self.Q_value,self.action_input),reduction_indices = 1)\n",
    "    self.cost = tf.reduce_mean(tf.square(self.y_input - Q_action))\n",
    "    self.optimizer =  tf.train.RMSPropOptimizer(0.00025,0.99,0.0,1e-6).minimize(self.cost)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "  def perceive(self,state,action,reward,next_state,done):\n",
    "    one_hot_action = np.zeros(self.action_dim)\n",
    "    one_hot_action[action] = 1\n",
    "    self.replay_buffer.append((state,one_hot_action,reward,next_state,done))\n",
    "    \n",
    "    if len(self.replay_buffer) > REPLAY_SIZE:\n",
    "      self.replay_buffer.popleft()\n",
    "\n",
    "    if len(self.replay_buffer) > BATCH_SIZE:\n",
    "      self.train_Q_network()\n",
    "\n",
    "  def train_Q_network(self):\n",
    "    self.time_step += 1\n",
    "\n",
    "    # Step 1: obtain random minibatch from replay memory\n",
    "    minibatch = random.sample(self.replay_buffer,BATCH_SIZE)\n",
    "    state_batch = [data[0] for data in minibatch]\n",
    "    action_batch = [data[1] for data in minibatch]\n",
    "    reward_batch = [data[2] for data in minibatch]\n",
    "    #print(reward_batch)\n",
    "    next_state_batch = [data[3] for data in minibatch]\n",
    "    # Step 2: calculate y\n",
    "    y_batch = []\n",
    "    Q_value_batch = self.Q_value.eval(feed_dict={self.state_input:next_state_batch})\n",
    "\n",
    "    for i in range(0,BATCH_SIZE):\n",
    "        done = minibatch[i][4]\n",
    "        if done:\n",
    "            y_batch.append(reward_batch[i])\n",
    "        else :\n",
    "            y_batch.append(reward_batch[i] + GAMMA * np.max(Q_value_batch[i]))\n",
    "    self.optimizer.run(feed_dict={\n",
    "      self.y_input:y_batch,\n",
    "      self.action_input:action_batch,\n",
    "      self.state_input:state_batch\n",
    "      })\n",
    "\n",
    "       \n",
    "  def egreedy_action(self,state):\n",
    "    Q_value = self.Q_value.eval(feed_dict = {\n",
    "      self.state_input:[state]})[0]\n",
    "    if random.random() <= self.epsilon:\n",
    "      return random.randint(0,self.action_dim - 1)\n",
    "    else:\n",
    "      return np.argmax(Q_value)\n",
    "\n",
    "    self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON)/10000\n",
    "\n",
    "\n",
    "  def action(self,state):\n",
    "    return np.argmax(self.Q_value.eval(feed_dict = {\n",
    "      self.state_input:[state]})[0])\n",
    "\n",
    "\n",
    "  def weight_variable(self,shape):\n",
    "    initial = tf.truncated_normal(shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "  def bias_variable(self,shape):\n",
    "    initial = tf.constant(0.01, shape = shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始執行\n",
      "dimension: 1024\n",
      "Could not find old network weights\n",
      "Evaluation Total Reward: 844.0\n",
      "[1.05 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.35 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAEHCAYAAADiczxdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwjk6XGUaywgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b734750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STEP = 10000   # Step limitation in an episode\n",
    "\n",
    "def main():\n",
    "\n",
    " print '開始執行'\n",
    "\n",
    "\n",
    " out=\"test\\n\"     \n",
    " env1=TWStock(my_test,label_test)\n",
    " agent = DQN(env1)\n",
    " total_reward = 0\n",
    " month_reward=0\n",
    " state = env1.reset()\n",
    " p=0\n",
    " n=0\n",
    " month_arr={}\n",
    " buy_rate={}\n",
    " for j in xrange(STEP):\n",
    "\n",
    "   env1.render()\n",
    "   action = agent.action(state)   # direct action for test\n",
    "   state,reward,done,_ = env1.step(action)\n",
    "   out+=str(action)+\" \"+str(reward)+\",\"\n",
    "   if(reward>0):\n",
    "      p+=1\n",
    "   elif(reward<0):\n",
    "      n+=1\n",
    "   total_reward += reward\n",
    "   month_reward += reward\n",
    "   if((j % 20==0 )and( j!=0 )):\n",
    "      #out+=\"\\n\"+\"month_reward,correct,wrong : \"+str(month_reward)+\" \"+str(p)+\" \"+str(n)+\"\\n\\n\"\n",
    "      buy_rate=np.append(buy_rate,(p+n)/20)   \n",
    "      p=0\n",
    "      n=0\n",
    "      month_arr=np.append(month_arr,month_reward)\n",
    " \n",
    "      month_reward=0\n",
    "   if done:\n",
    "     break\n",
    " #print(\"correct,wrong ,rate : \"+str(p)+\" \"+str(n)+\" \"+str(p/(p+n)))\n",
    " print 'Evaluation Total Reward:',total_reward\n",
    "    \n",
    " label_line={}\n",
    " sum_=0\n",
    " for x in xrange(0,len(label_test)):\n",
    "     sum_+=label_test[x]\n",
    "     if(x % 20==0 and x!=0):\n",
    "         label_line=np.append(label_line,sum_)\n",
    "         sum_=0\n",
    " label_line=np.delete(label_line,0)\n",
    " month_arr=np.delete(month_arr,0)\n",
    " buy_rate=np.delete(buy_rate,0)\n",
    " for x in xrange(0,len(month_arr)):\n",
    "        #month_arr[x]=month_arr[x]*buy_rate[x]\n",
    "        label_line[x]=label_line[x]*buy_rate[x]\n",
    " print (buy_rate)\n",
    " plt.figure()\n",
    " plt.plot(label_line, 'ro',label='baseline',linewidth=1,color=[1,0,0])\n",
    " plt.title(\"monthly profit with baseline\")\n",
    " #plt.plot(month_arr,label='predict',linewidth=5,color=[0,1,0])\n",
    " width = 0.6\n",
    " plt.bar([0,0.7,1.7,2.7,3.7,4.7,5.7,6.7,7.7,8.7,9.3],month_arr,width=width,label='predict')\n",
    " #plt.axis([0, 14, min_y, max_y])\n",
    " plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    " plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    " main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
