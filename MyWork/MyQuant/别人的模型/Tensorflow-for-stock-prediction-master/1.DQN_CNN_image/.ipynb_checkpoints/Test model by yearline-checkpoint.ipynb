{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "% matplotlib inline\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from yahoo_finance import Share\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.image as pimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 使输出的参数完全显示  \n",
    "\n",
    "> 若没有这一句，因为参数太多，中间会以省略号“……”的形式代替 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)#print full array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 每个sample使用多少天的数据\n",
    "\n",
    "> 使用哪一个标的进行计算\n",
    "\n",
    "> 设定today为今日\n",
    "\n",
    "> 设定stock_data为距今1年内的价格\n",
    "\n",
    "> 设定stock_data2为距今2年内的价格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history data counts: 255\n"
     ]
    }
   ],
   "source": [
    "day_len = 15   \n",
    "stock = Share('2330.TW') \n",
    "today = datetime.date.today()       \n",
    "stock_data = stock.get_historical('2015-09-01','2016-08-24')        \n",
    "stock_data2 = stock.get_historical('2014-09-01', '2016-08-24')      \n",
    "print 'history data counts:' , len(stock_data)\n",
    "stock_data.reverse() \n",
    "stock_data2.reverse() \n",
    "create_img='false' #test data existed? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 定义remove函数，逐行检查并去除volume小于等于0的行\n",
    "\n",
    "> 输出去除的行数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after remove Volume is 0 : 240\n"
     ]
    }
   ],
   "source": [
    "# remove empty data\n",
    "def remove(stock_data):\n",
    "    i = 0\n",
    "    while( i < len(stock_data)):\n",
    "        if (int(stock_data[i].get('Volume')) <= 0):\n",
    "            stock_data.remove(stock_data[i])\n",
    "            i = -1\n",
    "        i += 1\n",
    "    return stock_data\n",
    "\n",
    "stock_data=remove(stock_data)\n",
    "print 'after remove Volume is 0 :', len(stock_data)\n",
    "stock_data2=remove(stock_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define each line, prepare to draw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 设置年、季、月线\n",
    "\n",
    "> 定义year2011：2年数据比1年数据多多少\n",
    "\n",
    "> 计算年、季、月线值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yearline={}\n",
    "monthline={}\n",
    "seasonline={}\n",
    "\n",
    "#def yearline()\n",
    "year2011=len(stock_data2)-len(stock_data)\n",
    "for i in xrange(0,len(stock_data)):\n",
    "    year=0\n",
    "    season=0\n",
    "    month=0\n",
    "    for j in xrange(0,year2011):\n",
    "        year+=float(stock_data2[i+j].get('Close'))\n",
    "    yearline[i]=float(year/year2011)\n",
    "#def seasonline()\n",
    "    for j in xrange(0,61):\n",
    "        season+=float(stock_data2[year2011-61+i+j].get('Close'))\n",
    "    seasonline[i]=float(season/61)\n",
    "#def monthline()  \n",
    "    for j in xrange(0,13):\n",
    "        month+=float(stock_data2[year2011-13+i+j].get('Close'))\n",
    "    monthline[i]=float(month/13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> my_train: np.zeros([1年数据-时间窗口，时间窗口])\n",
    "\n",
    "> my_img: np.zeros([my_train，64,64])\n",
    "\n",
    "> new_img: np.zeros([my_train，64,64,2])\n",
    "\n",
    "> ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_train = np.zeros((len(stock_data)-day_len, day_len), dtype=np.float)\n",
    "my_img= np.zeros((len(my_train),64,64), dtype=np.float)\n",
    "new_img= np.zeros((len(my_train),64,64,2), dtype=np.float)\n",
    "my_year = np.zeros((len(stock_data)-day_len, day_len), dtype=np.float)\n",
    "year_img= np.zeros((len(my_train),64,64), dtype=np.float)\n",
    "my_season = np.zeros((len(stock_data)-day_len, day_len), dtype=np.float)\n",
    "my_month = np.zeros((len(stock_data)-day_len, day_len), dtype=np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 收益 > earn && 损失 < loss 的，用本身的值表示Label，否则Label = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real label\n",
      "[ 15.   15.5  14.   13.   13.   14.5  14.   14.   13.5  14.5  16.   15.\n",
      "  -7.   14.5  14.5  -8.5  14.5  14.   -7.5  -7.   14.5  -8.5  -8.5  -7.5\n",
      "  14.   14.5  14.5  14.5  -8.   -8.5  -7.5  -8.5  -9.   -8.   14.5  -7.\n",
      "  15.   16.   -7.   14.   -7.5  -8.   -8.   -8.   -8.   -9.5  -7.5  -7.5\n",
      "  -9.5  -9.5  -9.5  -7.5  -8.   -9.5  -7.5  -8.   -8.   -7.5  14.   -8.\n",
      "  -9.5  -9.   -8.5  -9.   -8.5  -9.   -7.5  -8.   -9.   -9.5  -7.5  -8.\n",
      "  14.   15.5  14.5  13.5  14.5  14.5  14.   14.5  14.   14.   14.   13.5\n",
      "  16.   14.5  14.5  14.5  14.5  14.5  15.5  14.5  16.   15.5  15.   18.\n",
      "  17.5  31.   31.   31.   16.   17.5  31.5  16.5  -8.   -9.   -8.   -8.5\n",
      "  -8.   -8.   -9.   -8.5  -8.   -8.5  -8.5  -8.5  -8.5  -9.5 -10.   -8.5\n",
      "  -9.5  -8.5  -8.   -9.   -9.   -8.5  -8.5  -8.5  -9.5  -8.5 -10.   -8.5\n",
      "  -8.5  -8.5  -8.5  -9.5  -8.  -10.   -8.   -9.5  -9.  -10.   -8.   -9.\n",
      "  -9.   15.5  18.   15.   18.   17.5  18.   15.   15.   15.   15.   14.5\n",
      "  15.   15.   15.   17.   28.   31.   27.5  27.   25.5  25.   25.5  23.\n",
      "  23.   21.5  21.   20.  -10.  -20.   16.5  16.5  16.5  16.5  16.5  16.5\n",
      " -10.  -10.5  -8.5  16.   16.5  16.   16.   17.    0.    0.    0.   16.5\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0. ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(my_train)):\n",
    "    for j in range(0, day_len):\n",
    "        my_train[i,j] = float(stock_data[i+j].get('Close'))\n",
    "        my_year[i,j] = yearline[i+j]\n",
    "        my_month[i,j] = monthline[i+j]\n",
    "        my_season[i,j] = seasonline[i+j]\n",
    "\n",
    "\n",
    "label_test= np.zeros(len(my_train), dtype=np.float)\n",
    "\n",
    "#set reward\n",
    "earn=10\n",
    "loss=-5\n",
    "for x in xrange(0,len(my_train)):\n",
    "    for y in xrange(0,500):# in the next 500 days reach 10 or-5\n",
    "        if(x+y+1<len(my_train)):\n",
    "\n",
    "            if((my_train[x+y+1][day_len-1]-my_train[x][day_len-1])/my_train[x][day_len-1]*100>earn):\n",
    "                label_test[x]=my_train[x+y+1][day_len-1]-my_train[x][day_len-1]\n",
    "                break\n",
    "            elif((my_train[x+y+1][day_len-1]-my_train[x][day_len-1])/my_train[x][day_len-1]*100<loss):\n",
    "                label_test[x]=my_train[x+y+1][day_len-1]-my_train[x][day_len-1]\n",
    "                break\n",
    "        else:\n",
    "            label_test[x]=0\n",
    "print(\"real label\")            \n",
    "print(label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## draw image and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 64, 64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x123641b90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11745db10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(my_img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注释：\n",
    "> 归一化数据\n",
    "\n",
    "> 用plt画图\n",
    "\n",
    "> 保存图像，然后再读取图像，reshape成[4，64，64]的彩图\n",
    "\n",
    "> 用img_gray将图像再降维成[64,64]的图/数组\n",
    "\n",
    "> 设定此为训练集\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axis y draw min -6, max 6\n"
     ]
    }
   ],
   "source": [
    "def img_gray(my_img):\n",
    "    new_img= np.zeros((64,64), dtype=np.float)\n",
    "    for x in xrange(0,len(my_img)):\n",
    "        for y in xrange(0,len(my_img[x])):\n",
    "            if (my_img[x,y,0]!=1 and my_img[x,y,1]!=1):\n",
    "                new_img[x,y]=0.7\n",
    "            elif (my_img[x,y,0]!=1 and my_img[x,y,2]!=1):\n",
    "                new_img[x,y]=0\n",
    "            elif (my_img[x,y,1]!=1 and my_img[x,y,2]!=1):\n",
    "                new_img[x,y]=0.35\n",
    "            else:\n",
    "                new_img[x,y]=1\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def normalize(li):#a list for create image\n",
    "    mean=sum(li) / float(len(li))\n",
    "    for i in xrange(0,len(li)):\n",
    "        li[i]=li[i]-mean\n",
    "    return li\n",
    "## yearline\n",
    "#if(create_img=='true'):\n",
    "if True:\n",
    "  #normalize\n",
    "  for i in range(0, len(my_train)-1):\n",
    "      my_train[i]=normalize(my_train[i])\n",
    "      my_year[i]=normalize(my_year[i])\t\n",
    "      my_month[i]=normalize(my_month[i])\t\n",
    "      my_season[i]=normalize(my_season[i])\t\n",
    "\n",
    "  min_y=-6\n",
    "  max_y=6\n",
    "  print(\"axis y draw min \"+str(min_y)+\", max \"+str(max_y))\n",
    "  for x in xrange(0,len(my_year)):#save file\n",
    "      #plt.figure()\n",
    "      #print(\"saving pic:\"+str(x))\n",
    "      plt.plot(my_year[x],label='year_close',linewidth=5,color=[0,0,1])\n",
    "      plt.plot(my_month[x],label='month_close',linewidth=5,color=[0,1,0])\n",
    "      plt.plot(my_season[x],label='season_close',linewidth=5,color=[1,0,0])\n",
    "      plt.axis([0, 14, min_y, max_y])\n",
    "      plt.axis('off')\n",
    "      plt.savefig('year_test/'+str(x)+'.png')\n",
    "      plt.close()\n",
    "\n",
    "for x in xrange(0,len(my_train)-day_len-1):#load file\n",
    "    img = pimg.imread('year_test/'+str(x)+'.png')\n",
    "    img2=cv2.resize(img,(64,64)) \n",
    "    my_img[x]=img_gray(img2)\n",
    "    \n",
    "##end yearline\n",
    "my_test=my_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## action and reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TWStock():\n",
    "    def __init__(self, stock_data,label):\n",
    "        self.stock_data = stock_data\n",
    "        self.stock_index = 0\n",
    "        self.label=label\n",
    "    def render(self):\n",
    "        # 尚未實作\n",
    "        return \n",
    "    \n",
    "    def reset(self):\n",
    "        self.stock_index = 0\n",
    "        return self.stock_data[self.stock_index]\n",
    "    \n",
    "    # 0: 觀望, 1: 持有多單, 2: 持有空單\n",
    "    def step(self, action): \n",
    "        self.stock_index += 1\n",
    "\n",
    "        action_reward=self.label[self.stock_index]\n",
    "        if (action == 0):\n",
    "            action_reward = 0\n",
    "\n",
    "        #if (action == 2):\n",
    "        #    action_reward = -1 * action_reward\n",
    "        #print(str(action)+\" \"+str(action_reward))\n",
    "\n",
    "        cv2.imshow('image',self.stock_data[self.stock_index])\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        stock_done = False\n",
    "        if self.stock_index >= len(self.stock_data)-1:\n",
    "            stock_done = True\n",
    "        else:\n",
    "            stock_done = False\n",
    "        return self.stock_data[self.stock_index], action_reward, stock_done, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN network define and agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W,s):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, s,s,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters for DQN\n",
    "GAMMA = 0.9 # discount factor for target Q\n",
    "INITIAL_EPSILON = 0.5 # starting value of epsilon\n",
    "FINAL_EPSILON = 0.01 # final value of epsilon\n",
    "REPLAY_SIZE = 10000 # experience replay buffer size\n",
    "BATCH_SIZE = 32 # size of minibatch\n",
    "\n",
    "class DQN():\n",
    "  # DQN Agent\n",
    "  def __init__(self, env):\n",
    "    # init experience replay\n",
    "    self.replay_buffer = deque()\n",
    "\n",
    "    # init some parameters\n",
    "    self.time_step = 0\n",
    "    self.epsilon = INITIAL_EPSILON\n",
    "    \n",
    "    #self.state_dim = env.observation_space.shape[0]\n",
    "    #self.action_dim = env.action_space.n\n",
    "    \n",
    "    self.state_dim = day_len\n",
    "    self.action_dim = 2\n",
    "\n",
    "\n",
    "    self.create_Q_network()\n",
    "    self.create_training_method()\n",
    "\n",
    "     # saving and loading networks\n",
    "    self.saver = tf.train.Saver()\n",
    "    self.session = tf.InteractiveSession()\n",
    "    self.session.run(tf.global_variables_initializer())\n",
    "    checkpoint = tf.train.get_checkpoint_state(\"saved_year_r\")\n",
    "    if checkpoint and checkpoint.model_checkpoint_path:\n",
    "        self.saver.restore(self.session, checkpoint.model_checkpoint_path)\n",
    "        print \"Successfully loaded:\", checkpoint.model_checkpoint_path\n",
    "    else:\n",
    "        print \"Could not find old network weights\"\n",
    "\n",
    "\n",
    "  def create_Q_network(self):\n",
    "    #-----------------------end cnn   start\n",
    "         \n",
    "        # network weights\n",
    "    W_conv1 = self.weight_variable([8,8,1,32])\n",
    "    b_conv1 = self.bias_variable([32])\n",
    "\n",
    "    W_conv2 = self.weight_variable([4,4,32,64])\n",
    "    b_conv2 = self.bias_variable([64])\n",
    "\n",
    "    W_conv3 = self.weight_variable([3,3,64,64])\n",
    "    b_conv3 = self.bias_variable([64])\n",
    "\n",
    "    W_fc1 = self.weight_variable([1024,512])\n",
    "    b_fc1 = self.bias_variable([512])\n",
    "\n",
    "    W_fc2 = self.weight_variable([512,self.action_dim])\n",
    "    b_fc2 = self.bias_variable([self.action_dim])\n",
    "\n",
    "    # input layer\n",
    "\n",
    "    self.state_input = tf.placeholder(\"float\",[None,64,64])\n",
    "    input1=tf.reshape(self.state_input,[-1,64,64,1])  \n",
    "\n",
    "    # hidden layers\n",
    "    h_conv1 = tf.nn.relu(conv2d(input1,W_conv1,4) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2,2) + b_conv2)\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_conv2,W_conv3,1) + b_conv3)\n",
    "    h_conv3_shape = h_conv3.get_shape().as_list()\n",
    "    print \"dimension:\",h_conv3_shape[1]*h_conv3_shape[2]*h_conv3_shape[3]\n",
    "    h_conv3_flat = tf.reshape(h_conv3,[-1,1024])\n",
    "\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv3_flat,W_fc1) + b_fc1)\n",
    "\n",
    "    # Q Value layer\n",
    "    self.Q_value = tf.matmul(h_fc1,W_fc2) + b_fc2\n",
    "\n",
    "\n",
    "\n",
    "  def create_training_method(self):\n",
    "    self.action_input = tf.placeholder(\"float\",[None,self.action_dim])\n",
    "    # one hot presentation\n",
    "    self.y_input = tf.placeholder(\"float\",[None])\n",
    "    Q_action = tf.reduce_sum(tf.multiply(self.Q_value,self.action_input),reduction_indices = 1)\n",
    "    self.cost = tf.reduce_mean(tf.square(self.y_input - Q_action))\n",
    "    self.optimizer =  tf.train.RMSPropOptimizer(0.00025,0.99,0.0,1e-6).minimize(self.cost)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "  def perceive(self,state,action,reward,next_state,done):\n",
    "    one_hot_action = np.zeros(self.action_dim)\n",
    "    one_hot_action[action] = 1\n",
    "    self.replay_buffer.append((state,one_hot_action,reward,next_state,done))\n",
    "    \n",
    "    if len(self.replay_buffer) > REPLAY_SIZE:\n",
    "      self.replay_buffer.popleft()\n",
    "\n",
    "    if len(self.replay_buffer) > BATCH_SIZE:\n",
    "      self.train_Q_network()\n",
    "\n",
    "  def train_Q_network(self):\n",
    "    self.time_step += 1\n",
    "\n",
    "    # Step 1: obtain random minibatch from replay memory\n",
    "    minibatch = random.sample(self.replay_buffer,BATCH_SIZE)\n",
    "    state_batch = [data[0] for data in minibatch]\n",
    "    action_batch = [data[1] for data in minibatch]\n",
    "    reward_batch = [data[2] for data in minibatch]\n",
    "    #print(reward_batch)\n",
    "    next_state_batch = [data[3] for data in minibatch]\n",
    "    # Step 2: calculate y\n",
    "    y_batch = []\n",
    "    Q_value_batch = self.Q_value.eval(feed_dict={self.state_input:next_state_batch})\n",
    "\n",
    "    for i in range(0,BATCH_SIZE):\n",
    "        done = minibatch[i][4]\n",
    "        if done:\n",
    "            y_batch.append(reward_batch[i])\n",
    "        else :\n",
    "            y_batch.append(reward_batch[i] + GAMMA * np.max(Q_value_batch[i]))\n",
    "    self.optimizer.run(feed_dict={\n",
    "      self.y_input:y_batch,\n",
    "      self.action_input:action_batch,\n",
    "      self.state_input:state_batch\n",
    "      })\n",
    "\n",
    "       \n",
    "  def egreedy_action(self,state):\n",
    "    Q_value = self.Q_value.eval(feed_dict = {\n",
    "      self.state_input:[state]})[0]\n",
    "    if random.random() <= self.epsilon:\n",
    "      return random.randint(0,self.action_dim - 1)\n",
    "    else:\n",
    "      return np.argmax(Q_value)\n",
    "\n",
    "    self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON)/10000\n",
    "\n",
    "\n",
    "  def action(self,state):\n",
    "    return np.argmax(self.Q_value.eval(feed_dict = {\n",
    "      self.state_input:[state]})[0])\n",
    "\n",
    "\n",
    "  def weight_variable(self,shape):\n",
    "    initial = tf.truncated_normal(shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "  def bias_variable(self,shape):\n",
    "    initial = tf.constant(0.01, shape = shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始執行\n",
      "dimension: 1024\n",
      "Could not find old network weights\n",
      "Evaluation Total Reward: 908.0\n",
      "[1.05 1.0 0.9 0.95 1.0 0.95 0.85 1.0 1.0 0.35 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAEHCAYAAADiczxdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X10VPW97/H3NwSUqKhIBHlIAvKgBrVKtLZFBFGqUtE+\nWLxmFdHDRWttl5ZbyzI9VqmcWhGtBz1yqa2IptojFqVyikd5UBSvivaooPIkScASDQaDGAWSfO8f\ne0eHmACZzJ6ZTD6vtbKyZz9+9wzks3+/vWdvc3dEREQk8bJSXYCIiEimUsiKiIhERCErIiISEYWs\niIhIRBSyIiIiEVHIioiIREQhKwljZiPNbEuTcTeb2cP7WKbMzM6Jvrr9M7NfmNmHZvaZmX3bzOrM\n7Kxw2lwzuzVB29lgZhPC4a+8P2a23MwmtWJ9SX0PY98LM5tgZhuStW2R9iY71QWIpAMzOwK4HTgJ\nWAN0cvdI/n+4+8Ao1psK7j4PmJfqOkTSlVqyHUDY0plpZq+ZWa2Z/S1sdS41sx1m9rKZ9YuZf6yZ\nvRVOW2pmQ5qsa4aZvWpmn5jZf5nZYeHkJUCfsAVYF7Pc0Wb2kJl9ZGYbzWxkMzX2MrNdTeo4w8w+\nMLPOzcxfYGZuZreE66wys1/HTJ9rZo+Y2cJwP0osMNXMys1sWzhPt3CR18Lf/wAq3H1PuP6CsNU5\nAbgx3K8XWqhnt5l1DV9fY2avxkx/xMyui3kPR4at5JuAy8L1xvYCnGpmy8L3+EUz6/PVT3Yv3zGz\n182sJtzWIeG2TjGzdWb2qZltN7MnzSw3nNbVzP4Utt63m9kSM8sPp/U2s8fNrDqs99rmNmpmE81s\necxrN7Nfm9nq8H1/2Mw6xUy/0szeCac9Hft5i2QihWzHMRC4GOhP0Fq7B/gl0Av4AJgCYGYDgT8D\n1wE9gUXA35oE3XHAD4E8oDfwv8Pxo4H33T07/Fkbji8E/gIcA8wF/r1pce5eCTwD/Chm9ETgYXff\ns4/9+gw4HTgb+GmTAC8iaJ0eAdxJEJSXA+eE70dOTC2jw98Hu3vfJrU1ttb+Ldyv4c3UXwZsBYaF\noy4EhphZ47pOA55vssxzwDTgz+F6Y7f7NeBnBJ/BDoLPal96Aj8ABhB8LlPC8RVhLUcQfFZbgdvC\naVMIPpOhwBCCzz3HzLKAvwFvAf2Ai4CbzOyb+6mhUR7B+3k8MCpcHjO7GCgh+LfTC3gH+OMBrlOk\nXVLIdhyz3H2zu38AvAo85u6vunst8N/A4HC+S4FF7r7E3T8jCKeuQOwf2LvdfZO7bweeJQjdfVnm\n7k+5+25gwT7mn0sQgpjZwcB44E/7Wfcd7v6Ru78Vrvu8mGl/cfcX3L0h3JcfAXe5+3p3/xi4kaAV\nmahu4eeAb4StyP7AA8BFZtYd6AH8TyvW9Sd3fyv8fBax//f4j+7+nrt/BPwHcH44vpbgfXwBKAeu\nAAaF0w4hCN8j3f1Dd/+ju79DcEDQA7jF3T919zeA+cAFB1j7b939A3d/H3gppvargOkx+/VvwGgz\n63KA6xVpdxSyHdPngDV53fiHrg/wRbelBze33hKOb2ldrfkj+Tnwle7f0EKgh5mdQdDqXufua1qx\n7m1A931M32vfgM1hLUe3Yhv7shz4BjAGeBp4gqAVVwS86O4Nca63te9xFXBUOPx74LvA9cCxBEHX\n+P9+BvAusDLsPp9jZjlAPkEL9jMz+9zMPgcmEbSW21J7PjA7Zp0VgMe5XpF2QRc+SVPvE3TvAmBm\nBvQNx+9PPXuHd6u4+24ze4SgNduf/bdim+oPvLGP6e8ThEejfsAe4EOCfdyXA9m354DpwHaglKB7\n+M/AuTTpKm7lelurANgUDo8Aprr7SoDg4wy4ezVByxYzO46gi3giwXu4yd2PTXBd7xO0ch9K8HpF\n0pZastLUX4CxZnZueBHPFILznisPYNnNQE8zO9XMeoRdvq01F7gM+BbwyAHMf6KZdTaz84BvE4Rb\nSx4Cfm5mgy24mvi3BOdD6w5gO5uBM83sCDPr3dwM7r4RqCMMVXevJ+iK/zEth+xm4DQzO/oALm7a\nl0Iz6xKG5RS+PEDZCIwM36OTgGsaF7DgK0sXmNmhQDXB51wNvELQip1uZt3N7DAzO8vMRrShPsKa\nfm1mXw9rHWBmV7VxnSJpTSEre3H39cD/Au4iaOGNBS7cz8VHjcuWAXcQdJuuI7i4pbXbX0XQjfiE\nu+84gEXuAj4mOHd8qbtX7GPeeQQh/ixB+NQSXFx0IGYT9Px8QHDOsyXPAc/FBPcCgpbqqhbm/8+w\nlgrgqQOspTkTCLqJlwKPuPtfwvFTCFqzO8J9eDNmma3A7wj26X/C7f8l/KzHEpy7fYegBTodiLe7\nGwB3f4Tgoqs/Enxmy4AT27JOkXRnep6spJOwe3oj8C/uvmwf8xUQdIl2PsCWqIhI0qklK+lmDMHF\nMMtTXIeISJspZCXdTAbmurpYRCQDqLtYREQkImrJioiIRCRtvyfbo0cPLygoSHUZIiLtymuvvbbN\n3XPbsPzR2dnZ9xPcblMNsX1rAFbX1dVNGjZs2IfNzZC2IVtQUMCqVS1960FERJpjZuVtWT47O/v+\nXr16HZ+bm7s9KytL5xP3oaGhwaqqqk6orKy8HxjX3Dw6ShERkVhDc3Nzdyhg9y8rK8tzc3NrCFr9\nzc+TxHpERCT9ZSlgD1z4XrWYpQpZERGRiChkRUQkraxdu7bLoEGDCvc/Z+udfvrpQ55//vkcgP79\n+0eyjVgKWRERid/s2d3p3ftEsrKG0bv3icyeva/HTaaVTZs2teZRmnFRyIqISHxmz+7O9dfns3Vr\nF9xh69YuXH99fiKC9pNPPul03nnnDejfv3/hyJEjB9bU1GRddtll+Xl5eUPz8/OHjhs3rv+ePcFz\nS6666qq+/fr1G9qnT58Tr7766r4AZWVlnc8+++yBgwYNKhw6dOjxK1asyGm6jZycnFMAnnrqqcOG\nDBlywogRIwbl5eUNHTt27ICGhuB5GM8888whp5xyynEDBw4sPOusswZWVlZ2as1+KGRFRCQ+06b1\n4fPP986Rzz/PYtq0tjy2EYD6+nruvvvuLZs2bVrTt2/f3XfeeWfujBkz3q+oqFhdXl6+evv27dlP\nPvlkt5deeqnrihUrDisvL19dUVHx1ne/+92PASZNmpQ3bdq0f65fv37N7Nmzy3/2s5/l7Wt7e/bs\nsQcffLBs06ZNq8vLyw9aunTpITt27MiaOnVq38WLF6/fsGHDmlGjRn1y6623turpYmn7PVmRVikt\nhZISqKiAvDyYPh2Ki1NdlUhmq6zs0qrxrXDEEUfUDxkyZDfAhRdeWPPwww93f+mllz6bNWvW0Vu2\nbDlo27Ztnbdu3dp5+PDhn27btq3zxIkT80aMGPHJ+PHja+rr61m5cmW3H/3oR18807qurs72tb38\n/Pxd/fv33wMwcODAz7ds2dK5vr7e1q1b1/WMM844rnEdRUVFO1uzHwpZaf9KS2HyZKitDV6Xlwev\nQUErEqVevXazdetXA7VXr92J3Mzu3butqqqq81VXXdV/wYIF64cPH147ceLEPHenV69e9W+99daa\nxx577Ignn3zyiHvvvbfnq6+++m52drZv3LhxTVZW6ztsO3Xq5O5uDQ0NnHLKKZ8+//zz6+OtXSEr\naaFg6qK4l33hvuvp2xiwjWprg5atQlYkOjfd9D7XX5+/V5fxwQc3cNNN77d11Xv27LG6ujrMjNLS\n0u4jR47c8cknn3QaPnx47c6dO7M2bNhwcFFR0advvvnmQTt37sy69tprPxo/fvzHgwcPHpqdnc1J\nJ5306a233nr0TTfd9GFdXR1PPfXUYRdffPEnranhjDPOqH333Xe7Ll269JCzzz770+rq6qzXX3+9\n6znnnPPpga5D52Sl3eu9Y1vzEyoqkluISEdz9dXV3HVXOcccsxszOOaY3dx1VzlXX13d1lXX1NR0\nKioqOq6goGBoz54999x6662VQ4YM+axfv34nnnXWWYN37dplAPX19TZ58uSCfv36Df3Wt741ZMaM\nGRUAc+fOLVu+fHm3goKCoQMHDhz697///fDW1nDkkUc2zJs3773rrruu34ABAwpPO+204zdu3HhQ\na9aRto+6Kyoqct27uONoW0v2CvruqPrqhPx8KCuLvyiRdsjMXnP3oniXf+ONN8pOPvnkFo5cpTlv\nvPFGj5NPPrmguWlqyUq7d/uICdRmNzm4zMkJLn4SEUkhhay0ewsLRzH1vGvZ0i0XzIIW7Jw5Oh8r\nIimnC58kIywsHMXCwlGU3TY21aWIiHxBLVkREZGIKGRFJH2VlkJBAWRlBb9LS1NdkUirqLtYRNKT\nbjIiGUAhKyLpqaTky4BtpJuMJF3B1EXDErm+stvGvpbI9e3P2rVru3znO98ZtH79+jXz5s074uWX\nXz7k3nvvbfZmGStXruy6efPmLuPHj69J1PbVXSwi6amlm4noJiMSpwkTJnzcUsACrFq1KmfRokWt\nvmnFvihkRSQ95bXw0JSWxkvGWLt2bZeePXueNGbMmGP79+9feOaZZw6qrq7O6tOnz4lXXnllv8GD\nB58wZcqUY6qrq7Muuuii/oMHDz5h8ODBJzz++OPdADZv3pw9fPjwQQUFBUMvueSSAY3rfeCBB478\n/ve/X9A4z+jRo48tKCgYOmDAgMInn3zysN/85jd9nnjiie79+/cvnDlzZo9E7ItCVkTS0/TpwU1F\nYukmIx1GfX29zZo1a/OmTZvW5OXl7fr973+fC/DNb35z57p1696eOXPm1uuuu67vD3/4w+p169a9\n/fTTT6+/7rrr8gCuueaafhdddNH2srKy1Q8++GBZc+u/+uqr88aMGbOjrKxs9YoVK9Z27969/l//\n9V/fv/jii6s3bdq0ZsqUKQm565XOyYpIemo876pHGHZIRx55ZF3jo+7GjRtX8/DDD3cHGDt27Bc3\n+V++fHm3FStWHParX/2qL0BtbW2n6urqrJUrV3abP39+GUBOTk5Dc+tfuXLlYY8//vgmgD59+tT1\n6dOn7h//+EfXRO+HQlZE0ldxsUJV2L17t3Xt2vUrYdnQ0GAvvvjiu/369auLHb9nzx7Lzs7e7435\nzfb5iNmEUHexiIikncZH3dXV1fHQQw8ddc455+xoOs+IESN23Hzzzcc0NDTQ0NDAX//6124Axx9/\nfO38+fMPB3j55Zdzmi4HMGzYsJ2zZs06CmDbtm2dXnnlla7du3ev37JlSxeAhoZmG8CtppasiIi0\nKNlfuWn00UcfZZ9yyinH19TUdBo9enTNpEmTtt9yyy19Y+e5++67t0yaNClvwIABQwFOPPHET7/3\nve/tuOuuuzZffvnlA0pKSvoWFhbWNrf+2bNnV0ycOLHgnnvu6dW5c2e/4447KsaNG7dj5syZvfr0\n6XPiz3/+862JOC+rR91JWmjLo+5i6d7F0tFlwqPuYr/bmso6DpQedSciIpICcYesmT1sZuvDn8fN\n7BAzO8rMFpvZuvB395j5S8xsrZmtNrPzE1O+iIhkmiFDhuxuL63Y/WlLS3YuMNjdBwG7gEuAGcAC\ndx8MLABuBjCzEcD5wAnAucDdZta5DdsWEZFoNDQ0NER/2W2GCN+rFq+Sijtk3f1Zd3czOwTIBd4B\nRgOPhrM8ClwQDo8GHnP3enffCqwBvh7vtkVEJDKrq6qqDlfQ7l9DQ4NVVVUdDqxuaZ42XV1sZlcC\ndwP/F3gFOMrdawDcvSamu7g38G7MolVAr2bWNxmYDJCnW6eJiCRdXV3dpMrKyvsrKyuHout29qcB\nWF1XVzeppRnaFLLu/iczmwf8CbgcqG8yS5eY4X1Na1zfHGAOBFcXt6U2ERFpvWHDhn0IjEt1HZmi\nzUcp7l4HPAsUATVmdiiAmR0OVIezVRJ0KTfKDceJiIhkrLhC1syONLNzw+HOwMXAKmApMD6c7VJg\nSTi8BLjEzDqZ2THAqQTdyyIiIhkr3u5iA240sz8Ae4C/AfOARUCpmf0SKAOKAdx9uZktBd4m6Db+\nibvvbGPtIiIiaS2ukHX3amBUM5OqgDEtLDMNmBbP9kSk/UrE3bx0Jy9pr3TlmIiISEQUsiIiIhFR\nyIqIiEREISsiIhIRhayIiEhEFLIiIiIRadNtFUWk/UjEV2lAX6cRaQ21ZEVERCKikBUREYmIQlZE\nRCQiClkREZGIKGRFREQiopAVERGJiEJWREQkIgpZERGRiChkRUREIqKQFRERiYhCVkREJCIKWRER\nkYgoZEVERCKikBWRAzJuzTJeuO8KyMqCggIoLU11SSJpT4+6E5H9GrdmGbctvoecul3BiPJymDw5\nGC4uTl1hImmu47VkS0uDo3AdjYscsBuen/dlwDaqrYWSktQUJNJOdKyWbGlpcPRdWxu81tG4yAHp\nvWNb8xMqKpJbiEg707FasiUlXwZsIx2Ni+zXP7v1aH5CXl5yCxFpZzpWyLZ01K2jcZF9un3EBGqz\nD9p7ZE4OTJ+emoJE2omOFbItHXXraFxknxYWjmLqedeypVsumEF+PsyZo9MsIvvRsUJ2+vTg6DuW\njsZFDsjCwlEM//ED0NAAZWUKWJED0LFCtrg4OPrOz9fRuIiIRK5jXV0MQaAqVEVEJAk6VktWREQk\niRSyIiIiEWl1yJrZwWb2rJltNLN1ZnZjOP4oM1scjltsZt1jlikxs7VmttrMzk/kDoiIiKSreFuy\nv3P3Y4GTgPFm9jVgBrDA3QcDC4CbAcxsBHA+cAJwLnC3mXVua+EiIiLprtUh6+6fu/szjcPABqAn\nMBp4NJztUeCCcHg08Ji717v7VmAN8PW2Fi4iIpLu2nRO1sx6AmcALwNHuXsNQPi7sbu4N/BhzGJV\nQK8W1jfZzFaZ2aqqqqq2lCYiIpJycYesmR0MPAaUuPvHQH2TWbrEDO9r2hfcfY67F7l7UW5ubryl\niYiIpIW4QtbMDgLmA39397nh6BozOzScfjhQHY6vBGITMzccJyIiktHiubo4B1gIrHD338ZMWgqM\nD4cvBZaEw0uAS8ysk5kdA5wKvBJ/ySIiIu1DPHd8Oh0YCeSb2RXhuAXAL4BSM/slUAYUA7j7cjNb\nCrxN0G38E3ff2ca696lg6qKErKfstrEJWY+IiHRMrQ5Zd18OHNTC5DEtLDMNmNbabYmIiLRnuuOT\niIhIRBSyIiIiEVHIioiIREQhKyIiEhGFrIiISEQUsiIiIhFRyIqIiEREISsiIhIRhayIiEhEFLIi\nIiIRUciKiIhERCErIiISEYWsiIhIRBSyIiIiEVHIioiIREQhKyIiEhGFrIiISEQUsiIiIhFRyIqI\niEREISsiIhIRhayIiEhEFLIiIiIRUciKiIhERCErIiISEYWsiIhIRBSyIiIiEVHIioiIREQhKyIi\nEhGFrIiISEQUsiIiIhFRyIqIiEREISsiIhKRuEPWzE41szdjXh9lZovNbF34u3vMtBIzW2tmq83s\n/LYWLSIi0h7EFbJmNhN4psnyM4AF7j4YWADcHM47AjgfOAE4F7jbzDq3oWYREZF2Ia6QdfcpwLAm\no0cDj4bDjwIXxIx/zN3r3X0rsAb4ejzbFRERaU8SeU72KHevAQh/N3YX9wY+jJmvCujV3ArMbLKZ\nrTKzVVVVVQksTUREJPkSGbL1TV53OcBpX3D3Oe5e5O5Fubm5CSxNREQk+RIZsjVmdiiAmR0OVIfj\nK4HYxMwNx4mIiGS0RIbsUmB8OHwpsCQcXgJcYmadzOwY4FTglQRuV0REJC1lx7OQmU0DLgaONbNV\nwBTgF0Cpmf0SKAOKAdx9uZktBd4m6Db+ibvvTEDtIiLNKpi6KCHrKbttbELWIx1XXCHr7jcBNzUz\naUwL808DpsWzLRERkfZKd3wSERGJiEJWREQkIgpZERGRiChkRUREIqKQFRERiYhCVkREJCIKWRER\nkYgoZEVERCIS180oJLPpbjkiIomhlqyIiEhEFLIiIiIRUciKiIhERCErIiISEYWsiIhIRBSyIiIi\nEVHIioiIREQhKyIiEhGFrIiISEQUspJw49Ys44X7roCsLCgogNLSVJckIpISuq2iJNS4Ncu4bfE9\n5NTtCkaUl8PkycFwcXHqChMRSQG1ZCWhbnh+3pcB26i2FkpKUlOQiEgKKWQloXrv2Nb8hIqK5BYi\n0gY65SGJopCVhPpntx7NT8jLS24hInFqPOXRd0cVuH95ykNBK3FQyCZDaWlwNNwBjopvHzGB2uyD\n9h6ZkwPTp6emIJFW0ikPSSRd+BS10tLgKLi2Nnid4RcCLSwcBQR/qPp+si1owU6fnpH7KplJpzwk\nkdSSjVpJyZcB2yjDj4oXFo5i+I8fgIYGKCtTwEq7olMekkhqyR6ggqmL4lruvfKK5o9kdFQskpZu\nHzFh76+hgU55SNzUko2YjopF2peFhaOYet61bOmWC2aQnw9z5qhHRuKikI2YLgQSaX90ykMSRSEb\nMR0Vi4h0XDonmwQLC0exsHAUZbeNTXUpIiKSRGrJioiIRCRpIWtmF5jZajNba2Y3Jmu7IiLtQge6\naU1HkpTuYjM7BLgP+DqwDVhmZovd/fVkbF9EJK11sJvWdCTJasmeDrzu7pXuXgfMBy5I0rZFRNJb\nB7xpTUdh7h79RsyKgRHuflX4+jLgm+5+bZP5JgOTAfLy8oaVl5dHXls6i/cGGE3pgquWpeI91ucq\nX5GVFTyMoCmz4GtErWBmr7l7UYIqkzZK5oVP9U1ed2k6g7vPcfcidy/Kzc1NUlkiIinW0s1pdNOa\ndi9ZIVsJxKZmbjhORESmTw9uUhNLN63JCMkK2ZeB08zsaDPLBn4ALEnStkVE0ltxcXCTmvx83bQm\nwyTl6mJ332lm1wLLgM7Aw+7+XDK2LSLSLhQXK1QzUNLu+OTuTwFPJWt7IiIiqaY7PomIiEREISsi\nIhIRhayIiEhEFLIiIiIRUciKiIhERCErIiISEYWsiIhIRBSyIiIiEVHIioiIREQhKyIiEhGFrIiI\nSEQUsiIiIhFRyIqIiEREISsiIhIRhayIiEhEFLIiIiIRUciKiIhERCErIiISEYWsiIhIRBSyIiIi\nEVHIioiIREQhKyIiEhGFrIiISEQUsiJtMG7NMl647wrIyoKCAigtTXVJIpJGslNdgEh7NW7NMm5b\nfA85dbuCEeXlMHlyMFxcnLrCRCRtqCUrEqcbnp/3ZcA2qq2FkpLUFCQiaUchKxKn3ju2NT+hoiK5\nhYhI2lLIisTpn916ND8hLy+5hYhI2lLIisTp9hETqM0+aO+ROTkwfXpqChKRtKOQFYnTwsJRTD3v\nWrZ0ywUzyM+HOXN00ZOIfEFXF4u0wcLCUSwsHEXZbWNTXYqIpCG1ZEVERCISV8iaWRcze8zMftBk\n/JVm9k74c0XM+AFmttLM1pnZI2Z2cFsLFxERSXetDlkzywPeAy5sMr4A+CVQBJwG3GBmR4eT7wdu\ncffBQBlwTdwVi4iItBOtPifr7hVAXzOb22TSKOC/3P1TADNbDIwxs/8EhgL/Hc73KDATuDPeokUS\nRedSRSRKiTwn2xv4MOZ1FdALyAW2u7s3Gf8VZjbZzFaZ2aqqqqoEliYiIpJ8+w1ZMzvdzN4Nf+bv\nZ/b6Jq+77Gf8Xtx9jrsXuXtRbm7u/koTERFJa/vtLnb3V4DjDmBdlU3mywXeImi5HtlkfGUrahQR\nEWmXEtldvAz4jpnlmNmhwPnAMnffDaw1s9HhfJcCSxK4XRERkbTU6gufzKwv8ARQAJxpZt9192J3\nf8/M7gReAwy4w903hYtNAh4ys9nA68AVzaxaREQko8RzdfEWgq/pNDftD8Afmhm/AfhGq6sTERFp\nx3THJxERkYgoZEVERCKikBUREYmIQlZERCQiCtkMNm7NMl647wrIyoKCAigtTXVJIiIdip4nm8ba\ndF/d0lKYdR/U1gavy8th8uRgWA8VFxFJCrVkM1VJyZcB26i2NhgvIiJJoZDNVBUVrRsvIiIJp5DN\nVHl5rRsvIiIJp5DNVNOnQ07O3uNycoLxIiKSFArZTFVcDHPmQH4+mAW/58zRRU8iIkmkq4szWXGx\nQlVEJIXUkhVpZ/T9Z5H2Qy1ZkXZk3Jpl3Lb4HnLqdgUj9P1nkbSmlqxIO3LD8/O+DNhG+v6zSNoy\nd091Dc0ysyqgPMJN9AC2Rbj+dKJ9zRDDYFhL016D15JZS5Jl9OfaRFv3Nd/dcxNVjLRN2oZs1Mxs\nlbs3+/D5TKN9zUza18zUkfa1I1B3sYiISEQUsiIiIhHpyCE7J9UFJJH2NTNpXzNTR9rXjNdhz8mK\niIhErSO3ZEVERCKlkBUREYlIhwtZM7vAzFab2VozuzHV9UTJzA42s2fNbKOZrcv0/QUws1+Y2epU\n1xE1M8sxs3vNbIOZbTazI1NdU1TM7PLw/+w6M5tvZoemuqZEMrNTzezNmNdHmdnicH8Xm1n3VNYn\nbdOhQtbMDgHuA84BCoHzzezU1FYVud+5+7HAScB4M/taqguKipl9C7gs1XUkySzgI2AQkAd8nNpy\nomFmPYFfA99w98HAh8BPU1tV4pjZTOAZ9v5bPANYEO7vAuDmFJQmCdKhQhY4HXjd3SvdvQ6YD1yQ\n4poi4+6fu/szjcPABqBnaquKhpn1AO4Crkp1LVEzs17AGcDNHiPVdUWkC3AI0Nh6rQR2p66cxHL3\nKXz1Ll6jgUfD4UfJ4L9RHUFHC9neBEfCjaqAXimqJanCFsEZwMupriXRzMyAB4Eb2PvzzVRDAQeW\nhqc9SsNemozj7puBO4F3zOx+4DTgP1JbVeSOcvcagPC3uovbsY4WsgD1TV53SUkVSWRmBwOPASXu\nnonditcDK919eaoLSZKjgXXAt4ETgA8IulQzjpkdDlwEfAN4GhgAnJ3SoqLX4f5GZbKOFrKVQOyN\ns3PDcRnLzA4i6Bb/u7vPTXE5UekPTDCzd4ElwCAzW5HimqK0HfjU3Xe5ez3wBHB8imuKyrnAO+7+\njrs/Bvwf4McprilqNY0Xd4UHGdUprkfaoKOF7MvAaWZ2tJllAz8g+KOckcwsB1gIrHD336a6nqi4\n+0/dfYhMkqCkAAAA0ElEQVS7H0dwPmu9u5+Z6roi9CIwwswKwtfnk4GnAULvAWfGXGFbBLybwnqS\nYSkwPhy+lAz+G9URdKiQdfedwLXAMuBt4Bl3fy61VUXqdGAkcIWZvRv+ZGzYdhTuvgP4F+BJM3ub\noPt4Rmqrioa7vw7cA/w/M3uHoHv8ltRWlThmNo3gQPhYM1tlZmcBvyD4JsA64PsE1xpIO6XbKoqI\niESkQ7VkRUREkkkhKyIiEhGFrIiISEQUsiIiIhFRyIqIiEREISsiIhIRhayIiEhE/j+Hc9FwXQqp\n/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123de9590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "STEP = 1000   # Step limitation in an episode\n",
    "\n",
    "def main():\n",
    "\n",
    " print '開始執行'\n",
    "\n",
    "\n",
    " out=\"test\\n\"     \n",
    " env1=TWStock(my_test,label_test)\n",
    " agent = DQN(env1)\n",
    " total_reward = 0\n",
    " month_reward=0\n",
    " state = env1.reset()\n",
    " p=0\n",
    " n=0\n",
    " month_arr={}\n",
    " buy_rate={}\n",
    " for j in xrange(STEP):\n",
    "\n",
    "   env1.render()\n",
    "   action = agent.action(state)   # direct action for test\n",
    "   state,reward,done,_ = env1.step(action)\n",
    "   out+=str(action)+\" \"+str(reward)+\",\"\n",
    "   if(reward>0):\n",
    "      p+=1\n",
    "   elif(reward<0):\n",
    "      n+=1\n",
    "   total_reward += reward\n",
    "   month_reward += reward\n",
    "   if((j % 20==0 )and( j!=0 )):\n",
    "      #out+=\"\\n\"+\"month_reward,correct,wrong : \"+str(month_reward)+\" \"+str(p)+\" \"+str(n)+\"\\n\\n\"\n",
    "      buy_rate=np.append(buy_rate,(p+n)/20)   \n",
    "      p=0\n",
    "      n=0\n",
    "      month_arr=np.append(month_arr,month_reward)\n",
    " \n",
    "      month_reward=0\n",
    "   if done:\n",
    "     break\n",
    " #print(\"correct,wrong ,rate : \"+str(p)+\" \"+str(n)+\" \"+str(p/(p+n)))\n",
    " print 'Evaluation Total Reward:',total_reward\n",
    "    \n",
    " label_line={}\n",
    " sum_=0\n",
    " for x in xrange(0,len(label_test)):\n",
    "     sum_+=label_test[x]\n",
    "     if(x % 20==0 and x!=0):\n",
    "         label_line=np.append(label_line,sum_)\n",
    "         sum_=0\n",
    " label_line=np.delete(label_line,0)\n",
    " month_arr=np.delete(month_arr,0)\n",
    " buy_rate=np.delete(buy_rate,0)\n",
    " for x in xrange(0,len(month_arr)):\n",
    "        #month_arr[x]=month_arr[x]*buy_rate[x]\n",
    "        label_line[x]=label_line[x]*buy_rate[x]\n",
    " print (buy_rate)\n",
    " plt.figure()\n",
    " plt.plot(label_line, 'ro',label='baseline',linewidth=1,color=[1,0,0])\n",
    " plt.title(\"monthly profit with baseline\")\n",
    " #plt.plot(month_arr,label='predict',linewidth=5,color=[0,1,0])\n",
    " width = 0.6\n",
    " plt.bar([0,0.7,1.7,2.7,3.7,4.7,5.7,6.7,7.7,8.7,9.3],month_arr,width=width,label='predict')\n",
    " #plt.axis([0, 14, min_y, max_y])\n",
    " plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    " plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    " main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
