{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: mahui\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train/holdout files.\n",
      "Train count:  49 , holdout count:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:352: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:360: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:368: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:375: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:382: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), activation=\"sigmoid\")`\n",
      "/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:384: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 512, 512, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 512, 512, 1)   4           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 512, 512, 32)  320         batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 512, 512, 32)  9248        conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 256, 256, 32)  0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 256, 256, 32)  128         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 256, 256, 64)  18496       batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 256, 256, 64)  36928       conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 128, 128, 64)  0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 128, 128, 64)  256         max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 128, 128, 96)  55392       batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 128, 128, 96)  83040       conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 64, 64, 96)    0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 64, 64, 96)    384         max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 64, 64, 128)   110720      batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 64, 64, 128)   147584      conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 32, 32, 128)   0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 32, 32, 128)   512         max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 32, 32, 128)   147584      batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv5b (Conv2D)                  (None, 32, 32, 128)   147584      conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)             (None, 16, 16, 128)   0           conv5b[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 16, 16, 128)   512         pool5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 16, 16, 128)   147584      batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv6b (Conv2D)                  (None, 16, 16, 128)   147584      conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up6 (UpSampling2D)               (None, 32, 32, 128)   0           conv6b[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 32, 32, 256)   0           up6[0][0]                        \n",
      "                                                                   conv5b[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 32, 32, 256)   1024        merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 32, 32, 96)    221280      batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 32, 32, 96)    83040       conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)   (None, 64, 64, 96)    0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 64, 64, 224)   0           up_sampling2d_1[0][0]            \n",
      "                                                                   conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 64, 64, 224)   896         merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 64, 64, 64)    129088      batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 64, 64, 64)    36928       conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)   (None, 128, 128, 64)  0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 128, 128, 160) 0           up_sampling2d_2[0][0]            \n",
      "                                                                   conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 128, 128, 160) 640         merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 128, 128, 32)  46112       batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 128, 128, 32)  9248        conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)   (None, 256, 256, 32)  0           conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 256, 256, 96)  0           up_sampling2d_3[0][0]            \n",
      "                                                                   conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 256, 256, 96)  384         merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 256, 256, 32)  27680       batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 256, 256, 32)  9248        conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)   (None, 512, 512, 32)  0           conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 512, 512, 1)   33          up_sampling2d_4[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 1,619,461\n",
      "Trainable params: 1,617,091\n",
      "Non-trainable params: 2,370\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:430: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 49.0, 200, validation_data=<generator..., callbacks=[<keras.ca..., validation_steps=22.0)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/49 [======>.......................] - ETA: 32s - loss: -0.4509 - dice_coef: 0.4509"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f286927dd714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_type_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"masses\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinue_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontinue_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinue_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontinue_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinue_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontinue_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-f286927dd714>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(holdout, model_type, continue_from)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mepoch_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mepoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"masses\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mepoch_div\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholdout_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mepoch_div\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdumper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"workdir/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"_model_h\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_best.hd5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"_model_h\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_best.hd5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1889\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/envs/python36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import settings\n",
    "import helpers\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import ntpath\n",
    "import cv2\n",
    "import numpy\n",
    "from typing import List, Tuple\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, merge, BatchNormalization, SpatialDropout2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import pandas\n",
    "import shutil\n",
    "import h5py\n",
    "\n",
    "MEAN_FRAME_COUNT = 1\n",
    "CHANNEL_COUNT = 1\n",
    "\n",
    "\n",
    "def random_scale_img(img, xy_range, lock_xy=False):\n",
    "    if random.random() > xy_range.chance:\n",
    "        return img\n",
    "\n",
    "    if not isinstance(img, list):\n",
    "        img = [img]\n",
    "\n",
    "    import cv2\n",
    "    scale_x = random.uniform(xy_range.x_min, xy_range.x_max)\n",
    "    scale_y = random.uniform(xy_range.y_min, xy_range.y_max)\n",
    "    if lock_xy:\n",
    "        scale_y = scale_x\n",
    "\n",
    "    org_height, org_width = img[0].shape[:2]\n",
    "    xy_range.last_x = scale_x\n",
    "    xy_range.last_y = scale_y\n",
    "\n",
    "    res = []\n",
    "    for img_inst in img:\n",
    "        scaled_width = int(org_width * scale_x)\n",
    "        scaled_height = int(org_height * scale_y)\n",
    "        scaled_img = cv2.resize(img_inst, (scaled_width, scaled_height), interpolation=cv2.INTER_CUBIC)\n",
    "        if scaled_width < org_width:\n",
    "            extend_left = (org_width - scaled_width) / 2\n",
    "            extend_right = org_width - extend_left - scaled_width\n",
    "            scaled_img = cv2.copyMakeBorder(scaled_img, 0, 0, extend_left, extend_right, borderType=cv2.BORDER_CONSTANT)\n",
    "            scaled_width = org_width\n",
    "\n",
    "        if scaled_height < org_height:\n",
    "            extend_top = (org_height - scaled_height) / 2\n",
    "            extend_bottom = org_height - extend_top - scaled_height\n",
    "            scaled_img = cv2.copyMakeBorder(scaled_img, extend_top, extend_bottom, 0, 0,  borderType=cv2.BORDER_CONSTANT)\n",
    "            scaled_height = org_height\n",
    "\n",
    "        start_x = (scaled_width - org_width) / 2\n",
    "        start_y = (scaled_height - org_height) / 2\n",
    "        tmp = scaled_img[start_y: start_y + org_height, start_x: start_x + org_width]\n",
    "        res.append(tmp)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "class XYRange:\n",
    "    def __init__(self, x_min, x_max, y_min, y_max, chance=1.0):\n",
    "        self.chance = chance\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.y_min = y_min\n",
    "        self.y_max = y_max\n",
    "        self.last_x = 0\n",
    "        self.last_y = 0\n",
    "\n",
    "    def get_last_xy_txt(self):\n",
    "        res = \"x_\" + str(int(self.last_x * 100)).replace(\"-\", \"m\") + \"-\" + \"y_\" + str(int(self.last_y * 100)).replace(\"-\", \"m\")\n",
    "        return res\n",
    "\n",
    "\n",
    "def random_translate_img(img, xy_range, border_mode=\"constant\"):\n",
    "    if random.random() > xy_range.chance:\n",
    "        return img\n",
    "    import cv2\n",
    "    if not isinstance(img, list):\n",
    "        img = [img]\n",
    "\n",
    "    org_height, org_width = img[0].shape[:2]\n",
    "    translate_x = random.randint(xy_range.x_min, xy_range.x_max)\n",
    "    translate_y = random.randint(xy_range.y_min, xy_range.y_max)\n",
    "    trans_matrix = numpy.float32([[1, 0, translate_x], [0, 1, translate_y]])\n",
    "\n",
    "    border_const = cv2.BORDER_CONSTANT\n",
    "    if border_mode == \"reflect\":\n",
    "        border_const = cv2.BORDER_REFLECT\n",
    "\n",
    "    res = []\n",
    "    for img_inst in img:\n",
    "        img_inst = cv2.warpAffine(img_inst, trans_matrix, (org_width, org_height), borderMode=border_const)\n",
    "        res.append(img_inst)\n",
    "    if len(res) == 1:\n",
    "        res = res[0]\n",
    "    xy_range.last_x = translate_x\n",
    "    xy_range.last_y = translate_y\n",
    "    return res\n",
    "\n",
    "\n",
    "def random_rotate_img(img, chance, min_angle, max_angle):\n",
    "    import cv2\n",
    "    if random.random() > chance:\n",
    "        return img\n",
    "    if not isinstance(img, list):\n",
    "        img = [img]\n",
    "\n",
    "    angle = random.randint(min_angle, max_angle)\n",
    "    center = (img[0].shape[0] / 2, img[0].shape[1] / 2)\n",
    "    rot_matrix = cv2.getRotationMatrix2D(center, angle, scale=1.0)\n",
    "\n",
    "    res = []\n",
    "    for img_inst in img:\n",
    "        img_inst = cv2.warpAffine(img_inst, rot_matrix, dsize=img_inst.shape[:2], borderMode=cv2.BORDER_CONSTANT)\n",
    "        res.append(img_inst)\n",
    "    if len(res) == 0:\n",
    "        res = res[0]\n",
    "    return res\n",
    "\n",
    "\n",
    "def random_flip_img(img, horizontal_chance=0, vertical_chance=0):\n",
    "    import cv2\n",
    "    flip_horizontal = False\n",
    "    if random.random() < horizontal_chance:\n",
    "        flip_horizontal = True\n",
    "\n",
    "    flip_vertical = False\n",
    "    if random.random() < vertical_chance:\n",
    "        flip_vertical = True\n",
    "\n",
    "    if not flip_horizontal and not flip_vertical:\n",
    "        return img\n",
    "\n",
    "    flip_val = 1\n",
    "    if flip_vertical:\n",
    "        flip_val = -1 if flip_horizontal else 0\n",
    "\n",
    "    if not isinstance(img, list):\n",
    "        res = cv2.flip(img, flip_val) # 0 = X axis, 1 = Y axis,  -1 = both\n",
    "    else:\n",
    "        res = []\n",
    "        for img_item in img:\n",
    "            img_flip = cv2.flip(img_item, flip_val)\n",
    "            res.append(img_flip)\n",
    "    return res\n",
    "\n",
    "\n",
    "ELASTIC_INDICES = None  # needed to make it faster to fix elastic deformation per epoch.\n",
    "def elastic_transform(image, alpha, sigma, random_state=None):\n",
    "    global ELASTIC_INDICES\n",
    "    shape = image.shape\n",
    "\n",
    "    if ELASTIC_INDICES == None:\n",
    "        if random_state is None:\n",
    "            random_state = numpy.random.RandomState(1301)\n",
    "\n",
    "        dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "        x, y = numpy.meshgrid(numpy.arange(shape[0]), numpy.arange(shape[1]))\n",
    "        ELASTIC_INDICES = numpy.reshape(y + dy, (-1, 1)), numpy.reshape(x + dx, (-1, 1))\n",
    "    return map_coordinates(image, ELASTIC_INDICES, order=1).reshape(shape)\n",
    "\n",
    "\n",
    "def prepare_image_for_net(img):\n",
    "    img = img.astype(numpy.float)\n",
    "    img /= 255.\n",
    "    if len(img.shape) == 3:\n",
    "        img = img.reshape(img.shape[-3], img.shape[-2], img.shape[-1])\n",
    "    else:\n",
    "        img = img.reshape(1, img.shape[-2], img.shape[-1], 1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_train_holdout_files(model_type, holdout, train_percentage=80, frame_count=8):\n",
    "    print(\"Get train/holdout files.\")\n",
    "    file_paths = glob.glob(\"/Volumes/solo/ali/pic/luna16_train_cubes_pos/\" + \"*_1_pos.png\")\n",
    "    file_paths.sort()\n",
    "    train_res = []\n",
    "    holdout_res = []\n",
    "    for index, file_path in enumerate(file_paths):\n",
    "        file_name = ntpath.basename(file_path)\n",
    "        overlay_path = file_path.replace(\"_1.png\", \"_o.png\")\n",
    "        train_set = False\n",
    "        if \"1.3.6.1.4\" in file_name or \"spie\" in file_name or \"TIME\" in file_name:\n",
    "            train_set = True\n",
    "        else:\n",
    "            patient_id = file_name.split(\"_\")[0]\n",
    "            if helpers.get_patient_fold(patient_id) % 3 != holdout:\n",
    "                train_set = True\n",
    "\n",
    "        if train_set:\n",
    "            train_res.append((file_path, overlay_path))\n",
    "        else:\n",
    "            holdout_res.append((file_path, overlay_path))\n",
    "    print(\"Train count: \", len(train_res), \", holdout count: \", len(holdout_res))\n",
    "    return train_res, holdout_res\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 100) / (K.sum(y_true_f) + K.sum(y_pred_f) + 100)\n",
    "\n",
    "\n",
    "def dice_coef_np(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = numpy.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 100) / (numpy.sum(y_true_f) + numpy.sum(y_pred_f) + 100)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "class DumpPredictions(Callback):\n",
    "\n",
    "    def __init__(self, dump_filelist : List[Tuple[str, str]], model_type):\n",
    "        super(DumpPredictions, self).__init__()\n",
    "        self.dump_filelist = dump_filelist\n",
    "        self.batch_count = 0\n",
    "        if not os.path.exists(\"workdir/segmenter/\"):\n",
    "            os.mkdir(\"workdir/segmenter/\")\n",
    "        for file_path in glob.glob(\"workdir/segmenter/*.*\"):\n",
    "            os.remove(file_path)\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model = self.model  # type: Model\n",
    "        generator = image_generator(self.dump_filelist, 1, train_set=False, model_type=self.model_type)\n",
    "        for i in range(0, 10):\n",
    "            x, y = next(generator)\n",
    "            y_pred = model.predict(x, batch_size=1)\n",
    "\n",
    "            x = x.swapaxes(0, 3)\n",
    "            x = x[0]\n",
    "            # print(x.shape, y.shape, y_pred.shape)\n",
    "            x *= 255.\n",
    "            x = x.reshape((x.shape[0], x.shape[0])).astype(numpy.uint8)\n",
    "            y *= 255.\n",
    "            y = y.reshape((y.shape[1], y.shape[2])).astype(numpy.uint8)\n",
    "            y_pred *= 255.\n",
    "            y_pred = y_pred.reshape((y_pred.shape[1], y_pred.shape[2])).astype(numpy.uint8)\n",
    "            # cv2.imwrite(\"workdir/segmenter/img_{0:03d}_{1:02d}_i.png\".format(epoch, i), x)\n",
    "            # cv2.imwrite(\"workdit/segmenter/img_{0:03d}_{1:02d}_o.png\".format(epoch, i), y)\n",
    "            # cv2.imwrite(\"workdit/segmenter/img_{0:03d}_{1:02d}_p.png\".format(epoch, i), y_pred)\n",
    "\n",
    "\n",
    "def image_generator(batch_files, batch_size, train_set, model_type):\n",
    "    global ELASTIC_INDICES\n",
    "    while True:\n",
    "        if train_set:\n",
    "            random.shuffle(batch_files)\n",
    "\n",
    "        img_list = []\n",
    "        overlay_list = []\n",
    "        ELASTIC_INDICES = None\n",
    "        for batch_file_idx, batch_file in enumerate(batch_files):\n",
    "            images = []\n",
    "            img = cv2.imread(batch_file[0], cv2.IMREAD_GRAYSCALE)\n",
    "            images.append(img)\n",
    "            overlay = cv2.imread(batch_file[1], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if train_set:\n",
    "                if random.randint(0, 100) > 50:\n",
    "                    for img_index, img in enumerate(images):\n",
    "                        images[img_index] = elastic_transform(img, 128, 15)\n",
    "                    overlay = elastic_transform(overlay, 128, 15)\n",
    "\n",
    "                if True:\n",
    "                    augmented = images + [overlay]\n",
    "                    augmented = random_rotate_img(augmented, 0.8, -20, 20)\n",
    "                    augmented = random_flip_img(augmented, 0.5, 0.5)\n",
    "\n",
    "                    # processed = helpers_augmentation.random_flip_img(processed, horizontal_chance=0.5, vertical_chance=0)\n",
    "                    # processed = helpers_augmentation.random_scale_img(processed, xy_range=helpers_augmentation.XYRange(x_min=0.8, x_max=1.2, y_min=0.8, y_max=1.2, chance=1.0))\n",
    "                    augmented = random_translate_img(augmented, XYRange(-30, 30, -30, 30, 0.8))\n",
    "                    images = augmented[:-1]\n",
    "                    overlay = augmented[-1]\n",
    "\n",
    "            for index, img in enumerate(images):\n",
    "                # img = img[crop_y: crop_y + settings.TRAIN_IMG_HEIGHT3D, crop_x: crop_x + settings.TRAIN_IMG_WIDTH3D]\n",
    "                img = prepare_image_for_net(img)\n",
    "                images[index] = img\n",
    "\n",
    "            # helpers_augmentation.dump_augmented_image(img, mean_img=None, target_path=\"c:\\\\tmp\\\\\" + batch_file[0])\n",
    "            # overlay = overlay[crop_y: crop_y + settings.TRAIN_IMG_HEIGHT3D, crop_x: crop_x + settings.TRAIN_IMG_WIDTH3D]\n",
    "            overlay = prepare_image_for_net(overlay)\n",
    "            # overlay = overlay.reshape(1, overlay.shape[-3] * overlay.shape[-2])\n",
    "            # overlay *= settings.OVERLAY_MULTIPLIER\n",
    "            images3d = numpy.vstack(images)\n",
    "            images3d = images3d.swapaxes(0, 3)\n",
    "\n",
    "            img_list.append(images3d)\n",
    "            overlay_list.append(overlay)\n",
    "            if len(img_list) >= batch_size:\n",
    "                x = numpy.vstack(img_list)\n",
    "                y = numpy.vstack(overlay_list)\n",
    "                # if len(img_list) >= batch_size:\n",
    "                yield x, y\n",
    "                img_list = []\n",
    "                overlay_list = []\n",
    "\n",
    "\n",
    "def get_unet(learn_rate, load_weights_path=None) -> Model:\n",
    "    inputs = Input((settings.SEGMENTER_IMG_SIZE, settings.SEGMENTER_IMG_SIZE, CHANNEL_COUNT))\n",
    "    filter_size = 32\n",
    "    growth_step = 32\n",
    "    x = BatchNormalization()(inputs)\n",
    "    conv1 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    conv1 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    pool1 = BatchNormalization()(pool1)\n",
    "    filter_size += growth_step\n",
    "    conv2 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = BatchNormalization()(pool2)\n",
    "\n",
    "    filter_size += growth_step\n",
    "    conv3 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "    conv3 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = BatchNormalization()(pool3)\n",
    "\n",
    "    filter_size += growth_step\n",
    "    conv4 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
    "    conv4 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = BatchNormalization()(pool4)\n",
    "\n",
    "    conv5 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "    conv5 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv5b\")(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2), name=\"pool5\")(conv5)\n",
    "    pool5 = BatchNormalization()(pool5)\n",
    "\n",
    "    conv6 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(pool5)\n",
    "    conv6 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\", name=\"conv6b\")(conv6)\n",
    "\n",
    "    up6 = UpSampling2D(size=(2, 2), name=\"up6\")(conv6)\n",
    "    up6 = merge([up6, conv5], mode='concat', concat_axis=3)\n",
    "    up6 = BatchNormalization()(up6)\n",
    "\n",
    "    # up6 = SpatialDropout2D(0.1)(up6)\n",
    "    filter_size -= growth_step\n",
    "    conv66 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(up6)\n",
    "    conv66 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(conv66)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv66), conv4], mode='concat', concat_axis=3)\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    # up7 = SpatialDropout2D(0.1)(up7)\n",
    "\n",
    "    filter_size -= growth_step\n",
    "    conv7 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(up7)\n",
    "    conv7 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv3], mode='concat', concat_axis=3)\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    filter_size -= growth_step\n",
    "    conv8 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(up8)\n",
    "    conv8 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(conv8)\n",
    "\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv2], mode='concat', concat_axis=3)\n",
    "    up9 = BatchNormalization()(up9)\n",
    "    conv9 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(up9)\n",
    "    conv9 = Conv2D(filter_size, (3, 3), activation=\"relu\", padding=\"same\")(conv9)\n",
    "    # conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    up10 = UpSampling2D(size=(2, 2))(conv9)\n",
    "    conv10 = Conv2D(1, (1, 1), activation=\"sigmoid\")(up10)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    # model.load_weights(load_weights_path)\n",
    "    # model.compile(optimizer=Adam(lr=1.0e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    model.compile(optimizer=SGD(lr=learn_rate, momentum=0.9, nesterov=True), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(holdout, model_type, continue_from=None):\n",
    "    batch_size = 4\n",
    "    train_percentage = 80 if model_type == \"masses\" else 90\n",
    "    train_files, holdout_files = get_train_holdout_files( model_type, holdout, train_percentage, frame_count=CHANNEL_COUNT)\n",
    "    # train_files = train_files[:100]\n",
    "    # holdout_files = train_files[:10]\n",
    "\n",
    "    tmp_gen = image_generator(train_files[:2], 2, True, model_type)\n",
    "    for i in range(10):\n",
    "        x = next(tmp_gen)\n",
    "        img = x[0][0].reshape((settings.SEGMENTER_IMG_SIZE, settings.SEGMENTER_IMG_SIZE))\n",
    "        img *= 255\n",
    "        # cv2.imwrite(\"c:/tmp/img_\" + str(i).rjust(3, '0') + \"i.png\", img)\n",
    "        img = x[1][0].reshape((settings.SEGMENTER_IMG_SIZE, settings.SEGMENTER_IMG_SIZE))\n",
    "        img *= 255\n",
    "        # cv2.imwrite(\"c:/tmp/img_\" + str(i).rjust(3, '0') + \"o.png\", img)\n",
    "        # print(x.shape)\n",
    "\n",
    "    train_gen = image_generator(train_files, batch_size, True, model_type)\n",
    "    holdout_gen = image_generator(holdout_files, batch_size, False, model_type)\n",
    "\n",
    "    if continue_from is None:\n",
    "        model = get_unet(0.001)\n",
    "    else:\n",
    "        model = get_unet(0.0001)\n",
    "        model.load_weights(continue_from)\n",
    "\n",
    "    checkpoint1 = ModelCheckpoint(\"workdir/\" + model_type +\"_model_h\" + str(holdout) + \"_{epoch:02d}-{val_loss:.2f}.hd5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    checkpoint2 = ModelCheckpoint(\"workdir/\" + model_type +\"_model_h\" + str(holdout) + \"_best.hd5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    files = []\n",
    "    idx = 0\n",
    "    while (idx < (len(holdout_files))):\n",
    "        files.append(holdout_files[idx])\n",
    "        idx += 5\n",
    "    dumper = DumpPredictions(holdout_files[::10], model_type)\n",
    "    epoch_div = 1\n",
    "    epoch_count = 200 if model_type == \"masses\" else 50\n",
    "    model.fit_generator(train_gen, len(train_files) / epoch_div, epoch_count, validation_data=holdout_gen, nb_val_samples=len(holdout_files) / epoch_div, callbacks=[checkpoint1, checkpoint2, dumper])\n",
    "    shutil.copy(\"workdir/\" + model_type +\"_model_h\" + str(holdout) + \"_best.hd5\", \"models/\" + model_type +\"_model_h\" + str(holdout) + \"_best.hd5\")\n",
    "\n",
    "def predict_patients(patients_dir, model_path, holdout, patient_predictions, model_type):\n",
    "    model = get_unet(0.001)\n",
    "    model.load_weights(model_path)\n",
    "    for item_name in os.listdir(patients_dir):\n",
    "        if not os.path.isdir(patients_dir + item_name):\n",
    "            continue\n",
    "        patient_id = item_name\n",
    "\n",
    "        if holdout >= 0:\n",
    "            patient_fold = helpers.get_patient_fold(patient_id, submission_set_neg=True)\n",
    "            if patient_fold < 0:\n",
    "                if holdout != 0:\n",
    "                    continue\n",
    "            else:\n",
    "                patient_fold %= 3\n",
    "                if patient_fold != holdout:\n",
    "                    continue\n",
    "\n",
    "        # if \"100953483028192176989979435275\" not in patient_id:\n",
    "        #     continue\n",
    "        print(patient_id)\n",
    "        patient_dir = patients_dir + patient_id + \"/\"\n",
    "        mass = 0\n",
    "        img_type = \"_i\" if model_type == \"masses\" else \"_c\"\n",
    "        slices = glob.glob(patient_dir + \"*\" + img_type + \".png\")\n",
    "        if model_type == \"emphysema\":\n",
    "            slices = slices[int(len(slices) / 2):]\n",
    "        for img_path in slices:\n",
    "            src_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            src_img = cv2.resize(src_img, dsize=(settings.SEGMENTER_IMG_SIZE, settings.SEGMENTER_IMG_SIZE))\n",
    "            src_img = prepare_image_for_net(src_img)\n",
    "            p = model.predict(src_img, batch_size=1)\n",
    "            p[p < 0.5] = 0\n",
    "            mass += p.sum()\n",
    "            p = p[0, :, :, 0] * 255\n",
    "            # cv2.imwrite(img_path.replace(\"_i.png\", \"_mass.png\"), p)\n",
    "            src_img = src_img.reshape((settings.SEGMENTER_IMG_SIZE, settings.SEGMENTER_IMG_SIZE))\n",
    "            src_img *= 255\n",
    "            # src_img = cv2.cvtColor(src_img.astype(numpy.uint8), cv2.COLOR_GRAY2BGR)\n",
    "            # p = cv2.cvtColor(p.astype(numpy.uint8), cv2.COLOR_GRAY2BGRA)\n",
    "            src_img = cv2.addWeighted(p.astype(numpy.uint8), 0.2, src_img.astype(numpy.uint8), 1 - 0.2, 0)\n",
    "            cv2.imwrite(img_path.replace(img_type + \".png\", \"_\" + model_type + \"o.png\"), src_img)\n",
    "\n",
    "        if mass > 1:\n",
    "            print(model_type + \": \", mass)\n",
    "        patient_predictions.append((patient_id, mass))\n",
    "        df = pandas.DataFrame(patient_predictions, columns=[\"patient_id\", \"prediction\"])\n",
    "        df.to_csv(settings.BASE_DIR + model_type + \"_predictions.csv\", index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    continue_from = None\n",
    "    if True:\n",
    "        for model_type_name in [\"masses\"]:\n",
    "            train_model(holdout=0, model_type=model_type_name, continue_from=continue_from)\n",
    "            train_model(holdout=1, model_type=model_type_name, continue_from=continue_from)\n",
    "            train_model(holdout=2, model_type=model_type_name, continue_from=continue_from)\n",
    "\n",
    "    if True:\n",
    "        for model_type_name in [\"masses\"]:\n",
    "            patient_predictions_global = []\n",
    "            for holdout_no in [0, 1, 2]:\n",
    "                patient_base_dir = settings.NDSB3_EXTRACTED_IMAGE_DIR\n",
    "                predict_patients(patients_dir=patient_base_dir, model_path=\"models/\" + model_type_name + \"_model_h\" + str(holdout_no) + \"_best.hd5\", holdout=holdout_no, patient_predictions=patient_predictions_global, model_type=model_type_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
