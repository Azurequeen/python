{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, SpatialDropout2D\n",
    "from keras.layers import Input, merge, UpSampling2D, BatchNormalization\n",
    "from keras.optimizers import Adam,rmsprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = '/Volumes/solo/ali/pic/train/'\n",
    "validation_data_dir = '/Volumes/solo/ali/pic/val/'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "width = 32\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19242 images belonging to 2 classes.\n",
      "Found 531 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 7s - loss: 0.7256 - acc: 0.5295 - val_loss: 0.6952 - val_acc: 0.5159\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 5s - loss: 0.6691 - acc: 0.5955 - val_loss: 0.7632 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 5s - loss: 0.6303 - acc: 0.6475 - val_loss: 0.7405 - val_acc: 0.5116\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 5s - loss: 0.5862 - acc: 0.6770 - val_loss: 0.6126 - val_acc: 0.6226\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 5s - loss: 0.5492 - acc: 0.7095 - val_loss: 0.5175 - val_acc: 0.7662\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 5s - loss: 0.5405 - acc: 0.7300 - val_loss: 0.4860 - val_acc: 0.7804\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 5s - loss: 0.5290 - acc: 0.7335 - val_loss: 0.4513 - val_acc: 0.7920\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 5s - loss: 0.5082 - acc: 0.7615 - val_loss: 0.5834 - val_acc: 0.6760\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 5s - loss: 0.5060 - acc: 0.7605 - val_loss: 0.4712 - val_acc: 0.7624\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 6s - loss: 0.4591 - acc: 0.7906 - val_loss: 0.5349 - val_acc: 0.7390\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 5s - loss: 0.4671 - acc: 0.7830 - val_loss: 0.5154 - val_acc: 0.7494\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 5s - loss: 0.4595 - acc: 0.7930 - val_loss: 0.7204 - val_acc: 0.7166\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 5s - loss: 0.4365 - acc: 0.8030 - val_loss: 0.6670 - val_acc: 0.7179\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 5s - loss: 0.4562 - acc: 0.7855 - val_loss: 0.5839 - val_acc: 0.7313\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 5s - loss: 0.4264 - acc: 0.8135 - val_loss: 0.6054 - val_acc: 0.7433\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 5s - loss: 0.4253 - acc: 0.8075 - val_loss: 0.6506 - val_acc: 0.7459\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 5s - loss: 0.4176 - acc: 0.8225 - val_loss: 0.7519 - val_acc: 0.7196\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 5s - loss: 0.4028 - acc: 0.8190 - val_loss: 0.4835 - val_acc: 0.7765\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 5s - loss: 0.4246 - acc: 0.8225 - val_loss: 0.4863 - val_acc: 0.7865\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 5s - loss: 0.4059 - acc: 0.8204 - val_loss: 0.6349 - val_acc: 0.7637\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 5s - loss: 0.4139 - acc: 0.8160 - val_loss: 0.6428 - val_acc: 0.7377\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 5s - loss: 0.4065 - acc: 0.8220 - val_loss: 0.7086 - val_acc: 0.7442\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 5s - loss: 0.4099 - acc: 0.8145 - val_loss: 0.6347 - val_acc: 0.7573\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 6s - loss: 0.4009 - acc: 0.8245 - val_loss: 0.6320 - val_acc: 0.7586\n",
      "Epoch 25/50\n",
      " 39/125 [========>.....................] - ETA: 3s - loss: 0.3660 - acc: 0.8397"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8666a250bd3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     validation_steps=nb_validation_samples // batch_size)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/solo/ali/Data/model/my_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(width, (3, 3), padding=\"same\", activation=\"relu\", input_shape=input_shape))\n",
    "model.add(BatchNormalization(axis = 1))\n",
    "model.add(Convolution2D(width, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(width*2, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization(axis = 1))\n",
    "model.add(Convolution2D(width*2, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(width*4, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization(axis = 1))\n",
    "model.add(Convolution2D(width*4, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(width*8, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization(axis = 1))\n",
    "model.add(Convolution2D(width*8, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(width*16, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization(axis = 1))\n",
    "model.add(Convolution2D(width*16, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "opt1 = Adam(lr=1e-5)\n",
    "opt2 = 'rmsprop'\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt1,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save('/Volumes/solo/ali/Data/model/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fenlei "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature,draw,data\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from scipy import ndimage\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import dicom\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from numba import autojit\n",
    "import zarr\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import scipy.spatial.distance as dist\n",
    "import gc\n",
    "import warnings\n",
    "from solo.unet_utils import *\n",
    "from solo.unet_models import *\n",
    "#from solo.preproc_utils import *\n",
    "#from solo.tianchi import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th') \n",
    "\n",
    "\n",
    "#from inception_unet import *\n",
    "np.random.seed(1337)\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    data_path = src\n",
    "    folders = [x for x in os.listdir(data_path) if 'subset' in x]\n",
    "    os.chdir(data_path)\n",
    "    patients = []\n",
    "    for i in folders:\n",
    "        os.chdir(data_path + i)\n",
    "        #print('Changing folder to: {}'.format(data_path + i))\n",
    "        patient_ids = [x for x in os.listdir(data_path + i) if '.mhd' in x]\n",
    "        for id in patient_ids:\n",
    "            j = '{}/{}'.format(i, id)\n",
    "            patients.append(j)\n",
    "    return patients\n",
    "\n",
    "def get_filename(file_list, case):\n",
    "    for f in file_list:\n",
    "        if case in f:\n",
    "            return(f)\n",
    "        \n",
    "def plot_ct_scan(scan):\n",
    "    f, plots = plt.subplots(int(scan.shape[0] / 20) + 1, 4, figsize=(25, 25))\n",
    "    for i in range(0, scan.shape[0], 5):\n",
    "        plots[int(i / 20), int((i % 20) / 5)].axis('off')\n",
    "        plots[int(i / 20), int((i % 20) / 5)].imshow(scan[i], cmap=plt.cm.bone) \n",
    "         \n",
    "def print_mask(lung_m, nodule_m):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,16))\n",
    "    ax[0].imshow(lung_m, cmap = plt.cm.bone)\n",
    "    ax[1].imshow(nodule_m, cmap = plt.cm.bone)\n",
    "    return\n",
    "\n",
    "def seq(start, stop, step=1):\n",
    "    n = int(round((stop - start)/float(step)))\n",
    "    if n > 1:\n",
    "        return([start + step*i for i in range(n+1)])\n",
    "    else:\n",
    "        return([])\n",
    "    \n",
    "def load_itk(filename):\n",
    "    itkimage = sitk.ReadImage(filename)\n",
    "    numpyImage = sitk.GetArrayFromImage(itkimage)\n",
    "    numpyOrigin = np.array(list(reversed(itkimage.GetOrigin())))\n",
    "    numpySpacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "    return numpyImage, numpyOrigin, numpySpacing\n",
    "\n",
    "def world_2_voxel(world_coordinates, origin, spacing):\n",
    "    stretched_voxel_coordinates = np.absolute(world_coordinates - origin)\n",
    "    voxel_coordinates = stretched_voxel_coordinates / spacing\n",
    "    return voxel_coordinates\n",
    "\n",
    "def voxel_2_world(voxel_coordinates, origin, spacing):\n",
    "    stretched_voxel_coordinates = voxel_coordinates * spacing\n",
    "    world_coordinates = stretched_voxel_coordinates + origin\n",
    "    return world_coordinates\n",
    "\n",
    "def get_pixels_hu(image):\n",
    "    image = image.astype(np.int16)\n",
    "    image[image == threshold_min] = 0\n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "def get_nodule_slices(lung_mask, nodule_mask, lung_raw):\n",
    "    indexes = np.unique(np.nonzero(nodule_mask)[0])\n",
    "    #print('Nodule_present on slices: {}'.format(indexes))\n",
    "    lung_mask_pres = lung_mask[indexes, :, :]\n",
    "    nod_mask_pres = nodule_mask[indexes, :, :]\n",
    "    lung_raw_pres = lung_raw[indexes, :, :]    \n",
    "    return lung_mask_pres, nod_mask_pres, lung_raw_pres\n",
    "\n",
    "def reshape_3d(image_3d):\n",
    "    reshaped_img = image_3d.reshape([image_3d.shape[0], 1, 512, 512])\n",
    "    #print('Reshaped image shape:', reshaped_img.shape)\n",
    "    return reshaped_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_masks_for_patient_watershed(img_file, save = True):\n",
    "    def draw_nodule_mask(node_idx, cur_row):\n",
    "        #print('Working on node: {}, row: {}'.format(node_idx, cur_row), '\\n')\n",
    "        coord_x = cur_row[\"coordX\"]\n",
    "        coord_y = cur_row[\"coordY\"]\n",
    "        coord_z = cur_row[\"coordZ\"]\n",
    "        diam = cur_row[\"diameter_mm\"]\n",
    "        radius = np.ceil(diam/2)\n",
    "        noduleRange = seq(-radius, radius, RESIZE_SPACING[0])\n",
    "        #print('Nodule range:', noduleRange)\n",
    "        world_center = np.array((coord_z,coord_y,coord_x))   # nodule center\n",
    "        voxel_center = world_2_voxel(world_center, origin, new_spacing)\n",
    "        image_mask = np.zeros(lung_img.shape)\n",
    "        for x in noduleRange:\n",
    "            for y in noduleRange:\n",
    "                for z in noduleRange:\n",
    "                    coords = world_2_voxel(np.array((coord_z+z,coord_y+y,coord_x+x)),origin,new_spacing)\n",
    "                    if (np.linalg.norm(voxel_center - coords) * RESIZE_SPACING[0]) < radius:\n",
    "                        image_mask[int(np.round(coords[0])),int(np.round(coords[1])),int(np.round(coords[2]))] = int(1)\n",
    "        #print(np.max(image_mask))    \n",
    "      \n",
    "        return image_mask\n",
    "\n",
    "    print(\"Getting mask for image file {}\".format(img_file))\n",
    "    patient_id = img_file.split('/')[-1][:-4]\n",
    "    mini_df = df_node[df_node[\"file\"] == img_file]\n",
    "    if mini_df.shape[0] > 0: # some files may not have a nodule--skipping those \n",
    "        img, origin, spacing = load_itk(src + img_file)\n",
    "        height, width = img.shape[1], img.shape[2]\n",
    "        #calculate resize factor\n",
    "        RESIZE_SPACING = [1, 1, 1]\n",
    "        resize_factor = spacing / RESIZE_SPACING\n",
    "        new_real_shape = img.shape * resize_factor\n",
    "        new_shape = np.round(new_real_shape)\n",
    "        real_resize = new_shape / img.shape\n",
    "        new_spacing = spacing / real_resize\n",
    "        \n",
    "        \n",
    "        lung_img = scipy.ndimage.interpolation.zoom(img, real_resize)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print('Original image shape: {}'.format(img.shape))\n",
    "        #print('Resized image shape: {}'.format(lung_img.shape))\n",
    "\n",
    "        lung_img = get_pixels_hu(lung_img)\n",
    "        #lung_mask = segment_lung_from_ct_scan(lung_img)\n",
    "        #lung_mask[lung_mask >= threshold_max] = threshold_max\n",
    "        #lung_img[lung_img >= threshold_max] = threshold_max\n",
    "        #lung_img[lung_img == 0] = threshold_min\n",
    "        \n",
    "        \n",
    "        \n",
    "        lung_mask = lung_img.copy()\n",
    "        #lung_mask[lung_mask == 0] = threshold_min\n",
    "        lung_mask[lung_mask >= threshold_max] = threshold_max\n",
    "        lung_img[lung_img >= threshold_max] = threshold_max\n",
    "        \n",
    "        lung_masks_512 = np.zeros([lung_img.shape[0], height_mask, width_mask], dtype = np.float32)\n",
    "        nodule_masks_512 = np.zeros([lung_img.shape[0], height_mask, width_mask], dtype = np.float32)\n",
    "        lung_masks_512[lung_masks_512 == 0] = threshold_min\n",
    "        \n",
    "        i = 0\n",
    "        for node_idx, cur_row in mini_df.iterrows(): \n",
    "            nodule_mask = draw_nodule_mask(node_idx, cur_row)\n",
    "            lung_img_512, lung_mask_512, nodule_mask_512 = np.zeros((lung_img.shape[0], 512, 512)), np.zeros((lung_mask.shape[0], 512, 512)), np.zeros((nodule_mask.shape[0], 512, 512))\n",
    "            lung_mask_512[lung_mask_512 == 0] = threshold_min\n",
    "            lung_img_512[lung_img_512 == 0] = threshold_min\n",
    "            original_shape = lung_img.shape\n",
    "            \n",
    "            for z in range(lung_img.shape[0]):\n",
    "                \n",
    "                offset = (512 - original_shape[1])\n",
    "                upper_offset = int(np.round(offset/2))\n",
    "                lower_offset = int(offset - upper_offset)\n",
    "\n",
    "                new_origin = voxel_2_world([-upper_offset,-lower_offset,0],origin,new_spacing)\n",
    "                \n",
    "                lung_img_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = lung_img[z,:,:]\n",
    "                lung_mask_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = lung_mask[z,:,:]\n",
    "                nodule_mask_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = nodule_mask[z,:,:]\n",
    "            nodule_masks_512 += nodule_mask_512\n",
    "\n",
    "        #print('Offsets shape for node index {} - main: {}, upper: {}, lower: {}'.format(node_idx, offset, upper_offset, lower_offset), '\\n')\n",
    "      \n",
    "       \n",
    "        lung_mask_pres, nod_mask_pres, lung_raw_pres = get_nodule_slices(lung_mask_512, nodule_masks_512, lung_img_512)\n",
    "        #print('Nodules present on slices: ', np.unique(np.nonzero(nodule_masks_512)[0]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        del lung_mask_512, nodule_masks_512, lung_img_512\n",
    "        gc.collect()\n",
    "        \n",
    "        lung_mask_pres = reshape_3d(lung_mask_pres)\n",
    "        nod_mask_pres = reshape_3d(nod_mask_pres)\n",
    "        lung_mask_pres[lung_mask_pres <= threshold_min] = threshold_min\n",
    "        lung_mask_pres[lung_mask_pres >= threshold_max] = threshold_max\n",
    "        \n",
    "        lung_mask_preproc = my_PreProc(lung_mask_pres)\n",
    "        lung_mask_preproc = lung_mask_preproc.astype(np.float32)\n",
    "        nod_mask_pres = (nod_mask_pres > 0.0).astype(np.float32)\n",
    "        nod_mask_pres[nod_mask_pres == 1.0] = 255.\n",
    "\n",
    "        np.save('{}/lung_mask/{}.npy'.format(dst_nodules, patient_id), lung_mask_preproc)\n",
    "        np.save('{}/nodule_mask/{}.npy'.format(dst_nodules, patient_id), nod_mask_pres)\n",
    "        \n",
    "        del lung_mask_pres, lung_mask_preproc, nod_mask_pres\n",
    "        gc.collect()\n",
    "            \n",
    "        #return lung_mask_preproc, nod_mask_pres\n",
    "        return\n",
    "    else: \n",
    "        print('\\n', 'No nodules found for patient: {}'.format(patient_id), '\\n')\n",
    "        return\n",
    "    \n",
    "def predict_on_scan(scan):\n",
    "    model = unet_model()\n",
    "    model.load_weights(luna_path + 'Data/model/Unet_fulldatagen.h5')\n",
    "\n",
    "    num_test = scan.shape[0]\n",
    "    scan = scan.reshape(num_test, 1, 512, 512)\n",
    "    imgs_mask_test = np.ndarray([num_test, 1, 512, 512],dtype=np.float32)\n",
    "    for i in range(num_test):\n",
    "        imgs_mask_test[i] = model.predict([scan[i:i+1]], verbose=0)[0]\n",
    "    return imgs_mask_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "luna_path = '/Volumes/solo/ali/'\n",
    "npy_path = luna_path + 'Data/test_mask/pre_lung_mask/'\n",
    "nodemask = luna_path + 'Data/test_mask/pre_nodule_mask/'\n",
    "\n",
    "pics_path = luna_path + 'pic/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = []\n",
    "subset_path = os.listdir(npy_path)\n",
    "for _ in range(len(subset_path)):\n",
    "    if subset_path[_] != '.DS_Store':\n",
    "        file_list.append(npy_path + subset_path[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_npy = pd.read_csv('/Volumes/solo/ali/csv/test/annotations_pre.csv',index_col=None)\n",
    "df_npy[\"npy_file\"] = df_npy[\"seriesuid\"].map(lambda file_name: get_filename(file_list, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ = []\n",
    "for node_idx, row in tqdm(df_npy.iterrows()):\n",
    "    img = np.load(row['npy_file'])\n",
    "    img = np.squeeze(img)\n",
    "    x = int(row['coordX'])\n",
    "    y = int(row['coordY'])\n",
    "    z = int(row['coordZ'])\n",
    "    d = int(row['diameter_mm'])\n",
    "    \n",
    "    mask = np.zeros([32,32])\n",
    "    rr, cc=draw.circle(y,x,d)\n",
    "    draw.set_color(mask,[rr,cc],[1,])\n",
    "    \n",
    "    \n",
    "    \n",
    "    scipy.misc.imsave(pics_path + str(node_idx) + '.jpg', img[x,y-16:y+16,z-16:z+16])\n",
    "    img1 = load_img(pics_path + str(node_idx) + '.jpg')\n",
    "    x = img_to_array(img1).transpose(1,2,0)\n",
    "    \n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    cc = model.predict(x)\n",
    "    prob_.append(cc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb = pd.read_csv('/Volumes/solo/ali/csv/test/annotations.csv',index_col=None)\n",
    "final_result = pd.DataFrame({'seriesuid':bb['seriesuid'].values,\n",
    "             'coordX':bb['coordX'].values,\n",
    "             'coordY':bb['coordY'].values,\n",
    "             'coordZ':bb['coordZ'].values,\n",
    "             'probability':prob_,\n",
    "                            })\n",
    "final_result = final_result[['seriesuid','coordX','coordY','coordZ','probability']]\n",
    "final_result.to_csv('/Volumes/solo/ali/csv/test/annotations_final.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "subset_path = os.listdir('/Volumes/solo/ali/pic/train/false/')\n",
    "for _ in range(len(subset_path)):\n",
    "    if subset_path[_] != '.DS_Store':\n",
    "        file_list.append('/Volumes/solo/ali/pic/train/false/' + subset_path[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/107 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected conv2d_81_input to have shape (None, 32, 32, 3) but got array with shape (1, 3, 224, 224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-40f0eb766177>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#x = preprocess_input(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mau\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# decode the results into a list of tuples (class, description, probability)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# (one such list for each sample in the batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1553\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    131\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected conv2d_81_input to have shape (None, 32, 32, 3) but got array with shape (1, 3, 224, 224)"
     ]
    }
   ],
   "source": [
    "#model.load_weights('/Volumes/solo/ali/Data/model/prob.h5')\n",
    "#model.load('/Volumes/solo/ali/Data/model/my_model.h5')\n",
    "au = load_model('/Volumes/solo/ali/Data/model/my_model.h5')\n",
    "prob_ = []\n",
    "for _ in tqdm(file_list):\n",
    "\n",
    "    img = load_img(_, target_size=(224, 224))\n",
    "    x = img_to_array(img).transpose(1,2,0)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #x = preprocess_input(x)\n",
    "\n",
    "    preds = au.predict(x)\n",
    "    # decode the results into a list of tuples (class, description, probability)\n",
    "    # (one such list for each sample in the batch)\n",
    "    print('Predicted:', decode_predictions(preds, top=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
