{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "luna_path = '/Volumes/solo/ali/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature,draw,data\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from scipy import ndimage\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import dicom\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from numba import autojit\n",
    "import zarr\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import scipy.spatial.distance as dist\n",
    "import gc\n",
    "import warnings\n",
    "from solo.unet_utils import *\n",
    "from solo.unet_models import *\n",
    "#from solo.preproc_utils import *\n",
    "#from solo.tianchi import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th') \n",
    "\n",
    "\n",
    "#from inception_unet import *\n",
    "np.random.seed(1337)\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    data_path = src\n",
    "    folders = [x for x in os.listdir(data_path) if 'subset' in x]\n",
    "    os.chdir(data_path)\n",
    "    patients = []\n",
    "    for i in folders:\n",
    "        os.chdir(data_path + i)\n",
    "        #print('Changing folder to: {}'.format(data_path + i))\n",
    "        patient_ids = [x for x in os.listdir(data_path + i) if '.mhd' in x]\n",
    "        for id in patient_ids:\n",
    "            j = '{}/{}'.format(i, id)\n",
    "            patients.append(j)\n",
    "    return patients\n",
    "\n",
    "def get_filename(file_list, case):\n",
    "    for f in file_list:\n",
    "        if case in f:\n",
    "            return(f)\n",
    "        \n",
    "def plot_ct_scan(scan):\n",
    "    f, plots = plt.subplots(int(scan.shape[0] / 20) + 1, 4, figsize=(25, 25))\n",
    "    for i in range(0, scan.shape[0], 5):\n",
    "        plots[int(i / 20), int((i % 20) / 5)].axis('off')\n",
    "        plots[int(i / 20), int((i % 20) / 5)].imshow(scan[i], cmap=plt.cm.bone) \n",
    "         \n",
    "def print_mask(lung_m, nodule_m):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,16))\n",
    "    ax[0].imshow(lung_m, cmap = plt.cm.bone)\n",
    "    ax[1].imshow(nodule_m, cmap = plt.cm.bone)\n",
    "    return\n",
    "\n",
    "def seq(start, stop, step=1):\n",
    "    n = int(round((stop - start)/float(step)))\n",
    "    if n > 1:\n",
    "        return([start + step*i for i in range(n+1)])\n",
    "    else:\n",
    "        return([])\n",
    "    \n",
    "def load_itk(filename):\n",
    "    itkimage = sitk.ReadImage(filename)\n",
    "    numpyImage = sitk.GetArrayFromImage(itkimage)\n",
    "    numpyOrigin = np.array(list(reversed(itkimage.GetOrigin())))\n",
    "    numpySpacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "    return numpyImage, numpyOrigin, numpySpacing\n",
    "\n",
    "def world_2_voxel(world_coordinates, origin, spacing):\n",
    "    stretched_voxel_coordinates = np.absolute(world_coordinates - origin)\n",
    "    voxel_coordinates = stretched_voxel_coordinates / spacing\n",
    "    return voxel_coordinates\n",
    "\n",
    "def voxel_2_world(voxel_coordinates, origin, spacing):\n",
    "    stretched_voxel_coordinates = voxel_coordinates * spacing\n",
    "    world_coordinates = stretched_voxel_coordinates + origin\n",
    "    return world_coordinates\n",
    "\n",
    "def get_pixels_hu(image):\n",
    "    image = image.astype(np.int16)\n",
    "    image[image == threshold_min] = 0\n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "def get_nodule_slices(lung_mask, nodule_mask, lung_raw):\n",
    "    indexes = np.unique(np.nonzero(nodule_mask)[0])\n",
    "    #print('Nodule_present on slices: {}'.format(indexes))\n",
    "    lung_mask_pres = lung_mask[indexes, :, :]\n",
    "    nod_mask_pres = nodule_mask[indexes, :, :]\n",
    "    lung_raw_pres = lung_raw[indexes, :, :]    \n",
    "    return lung_mask_pres, nod_mask_pres, lung_raw_pres\n",
    "\n",
    "def reshape_3d(image_3d):\n",
    "    reshaped_img = image_3d.reshape([image_3d.shape[0], 1, 512, 512])\n",
    "    #print('Reshaped image shape:', reshaped_img.shape)\n",
    "    return reshaped_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_masks_for_patient_watershed(img_file, save = True):\n",
    "    def draw_nodule_mask(node_idx, cur_row):\n",
    "        #print('Working on node: {}, row: {}'.format(node_idx, cur_row), '\\n')\n",
    "        coord_x = cur_row[\"coordX\"]\n",
    "        coord_y = cur_row[\"coordY\"]\n",
    "        coord_z = cur_row[\"coordZ\"]\n",
    "        diam = cur_row[\"diameter_mm\"]\n",
    "        radius = np.ceil(diam/2)\n",
    "        noduleRange = seq(-radius, radius, RESIZE_SPACING[0])\n",
    "        #print('Nodule range:', noduleRange)\n",
    "        world_center = np.array((coord_z,coord_y,coord_x))   # nodule center\n",
    "        voxel_center = world_2_voxel(world_center, origin, new_spacing)\n",
    "        image_mask = np.zeros(lung_img.shape)\n",
    "        for x in noduleRange:\n",
    "            for y in noduleRange:\n",
    "                for z in noduleRange:\n",
    "                    coords = world_2_voxel(np.array((coord_z+z,coord_y+y,coord_x+x)),origin,new_spacing)\n",
    "                    if (np.linalg.norm(voxel_center - coords) * RESIZE_SPACING[0]) < radius:\n",
    "                        image_mask[int(np.round(coords[0])),int(np.round(coords[1])),int(np.round(coords[2]))] = int(1)\n",
    "        #print(np.max(image_mask))    \n",
    "      \n",
    "        return image_mask\n",
    "\n",
    "    print(\"Getting mask for image file {}\".format(img_file))\n",
    "    patient_id = img_file.split('/')[-1][:-4]\n",
    "    mini_df = df_node[df_node[\"file\"] == img_file]\n",
    "    if mini_df.shape[0] > 0: # some files may not have a nodule--skipping those \n",
    "        img, origin, spacing = load_itk(src + img_file)\n",
    "        height, width = img.shape[1], img.shape[2]\n",
    "        #calculate resize factor\n",
    "        RESIZE_SPACING = [1, 1, 1]\n",
    "        resize_factor = spacing / RESIZE_SPACING\n",
    "        new_real_shape = img.shape * resize_factor\n",
    "        new_shape = np.round(new_real_shape)\n",
    "        real_resize = new_shape / img.shape\n",
    "        new_spacing = spacing / real_resize\n",
    "        \n",
    "        \n",
    "        lung_img = scipy.ndimage.interpolation.zoom(img, real_resize)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print('Original image shape: {}'.format(img.shape))\n",
    "        #print('Resized image shape: {}'.format(lung_img.shape))\n",
    "\n",
    "        lung_img = get_pixels_hu(lung_img)\n",
    "        #lung_mask = segment_lung_from_ct_scan(lung_img)\n",
    "        #lung_mask[lung_mask >= threshold_max] = threshold_max\n",
    "        #lung_img[lung_img >= threshold_max] = threshold_max\n",
    "        #lung_img[lung_img == 0] = threshold_min\n",
    "        \n",
    "        \n",
    "        \n",
    "        lung_mask = lung_img.copy()\n",
    "        #lung_mask[lung_mask == 0] = threshold_min\n",
    "        lung_mask[lung_mask >= threshold_max] = threshold_max\n",
    "        lung_img[lung_img >= threshold_max] = threshold_max\n",
    "        \n",
    "        lung_masks_512 = np.zeros([lung_img.shape[0], height_mask, width_mask], dtype = np.float32)\n",
    "        nodule_masks_512 = np.zeros([lung_img.shape[0], height_mask, width_mask], dtype = np.float32)\n",
    "        lung_masks_512[lung_masks_512 == 0] = threshold_min\n",
    "        \n",
    "        i = 0\n",
    "        for node_idx, cur_row in mini_df.iterrows(): \n",
    "            nodule_mask = draw_nodule_mask(node_idx, cur_row)\n",
    "            lung_img_512, lung_mask_512, nodule_mask_512 = np.zeros((lung_img.shape[0], 512, 512)), np.zeros((lung_mask.shape[0], 512, 512)), np.zeros((nodule_mask.shape[0], 512, 512))\n",
    "            lung_mask_512[lung_mask_512 == 0] = threshold_min\n",
    "            lung_img_512[lung_img_512 == 0] = threshold_min\n",
    "            original_shape = lung_img.shape\n",
    "            \n",
    "            for z in range(lung_img.shape[0]):\n",
    "                \n",
    "                offset = (512 - original_shape[1])\n",
    "                upper_offset = int(np.round(offset/2))\n",
    "                lower_offset = int(offset - upper_offset)\n",
    "\n",
    "                new_origin = voxel_2_world([-upper_offset,-lower_offset,0],origin,new_spacing)\n",
    "                \n",
    "                lung_img_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = lung_img[z,:,:]\n",
    "                lung_mask_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = lung_mask[z,:,:]\n",
    "                nodule_mask_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = nodule_mask[z,:,:]\n",
    "            nodule_masks_512 += nodule_mask_512\n",
    "\n",
    "        #print('Offsets shape for node index {} - main: {}, upper: {}, lower: {}'.format(node_idx, offset, upper_offset, lower_offset), '\\n')\n",
    "      \n",
    "       \n",
    "        lung_mask_pres, nod_mask_pres, lung_raw_pres = get_nodule_slices(lung_mask_512, nodule_masks_512, lung_img_512)\n",
    "        #print('Nodules present on slices: ', np.unique(np.nonzero(nodule_masks_512)[0]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        del lung_mask_512, nodule_masks_512, lung_img_512\n",
    "        gc.collect()\n",
    "        \n",
    "        lung_mask_pres = reshape_3d(lung_mask_pres)\n",
    "        nod_mask_pres = reshape_3d(nod_mask_pres)\n",
    "        lung_mask_pres[lung_mask_pres <= threshold_min] = threshold_min\n",
    "        lung_mask_pres[lung_mask_pres >= threshold_max] = threshold_max\n",
    "        \n",
    "        lung_mask_preproc = my_PreProc(lung_mask_pres)\n",
    "        lung_mask_preproc = lung_mask_preproc.astype(np.float32)\n",
    "        nod_mask_pres = (nod_mask_pres > 0.0).astype(np.float32)\n",
    "        nod_mask_pres[nod_mask_pres == 1.0] = 255.\n",
    "\n",
    "        np.save('{}/lung_mask/{}.npy'.format(dst_nodules, patient_id), lung_mask_preproc)\n",
    "        np.save('{}/nodule_mask/{}.npy'.format(dst_nodules, patient_id), nod_mask_pres)\n",
    "        \n",
    "        del lung_mask_pres, lung_mask_preproc, nod_mask_pres\n",
    "        gc.collect()\n",
    "            \n",
    "        #return lung_mask_preproc, nod_mask_pres\n",
    "        return\n",
    "    else: \n",
    "        print('\\n', 'No nodules found for patient: {}'.format(patient_id), '\\n')\n",
    "        return\n",
    "    \n",
    "def predict_on_scan(scan):\n",
    "    model = unet_model()\n",
    "    model.load_weights(luna_path + 'Data/model/Unet_fulldatagen.h5')\n",
    "\n",
    "    num_test = scan.shape[0]\n",
    "    scan = scan.reshape(num_test, 1, 512, 512)\n",
    "    imgs_mask_test = np.ndarray([num_test, 1, 512, 512],dtype=np.float32)\n",
    "    for i in range(num_test):\n",
    "        imgs_mask_test[i] = model.predict([scan[i:i+1]], verbose=0)[0]\n",
    "    return imgs_mask_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成完整train的npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotations_path = luna_path + 'csv/train/'\n",
    "src = luna_path + 'Data/train/'\n",
    "dst_nodules = luna_path + 'Data/train_mask/'\n",
    "patients = load_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord_x = []\n",
    "coord_y = []\n",
    "coord_z = []\n",
    "diam = []\n",
    "patient_id = []\n",
    "\n",
    "for img_file in tqdm(patients):\n",
    "    patient_id_ = img_file.split('/')[-1][:-4]\n",
    "    img, origin, spacing = load_itk(src + img_file)   \n",
    "    \n",
    "    RESIZE_SPACING = [1, 1, 1]\n",
    "    resize_factor = spacing / RESIZE_SPACING\n",
    "    new_real_shape = img.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize = new_shape / img.shape\n",
    "    new_spacing = spacing / real_resize\n",
    "    \n",
    "    world_center = np.array((img.shape[2],img.shape[1],img.shape[0]))   # nodule center\n",
    "    voxel_center = world_2_voxel(world_center, origin, new_spacing)\n",
    "    \n",
    "    coord_x.append(img.shape[0]/2)\n",
    "    coord_y.append(img.shape[1]/2)\n",
    "    coord_z.append(img.shape[2]/2)\n",
    "    diam.append(voxel_center[0])\n",
    "    patient_id.append(patient_id_)\n",
    "    \n",
    "df_node = pd.DataFrame({'seriesuid':patient_id,\n",
    "             'coordX':coord_x,\n",
    "             'coordY':coord_y ,\n",
    "             'coordZ':coord_z,\n",
    "             'diameter_mm':diam,\n",
    "             'file':patients})\n",
    "df_node = df_node [['seriesuid','coordX','coordY','coordZ','diameter_mm','file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_node.to_csv('/Volumes/solo/ali/csv/train/temp.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_node = pd.read_csv('/Volumes/solo/ali/csv/train/temp.csv',index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_masks_for_patient_watershed1(img_file, save = True):\n",
    "    \n",
    "\n",
    "    print(\"Getting mask for image file {}\".format(img_file))\n",
    "    patient_id = img_file.split('/')[-1][:-4]\n",
    "    mini_df = df_node[df_node[\"file\"] == img_file]\n",
    "    if mini_df.shape[0] > 0: # some files may not have a nodule--skipping those \n",
    "        img, origin, spacing = load_itk(src + img_file)\n",
    "        height, width = img.shape[1], img.shape[2]\n",
    "        #calculate resize factor\n",
    "        RESIZE_SPACING = [1, 1, 1]\n",
    "        resize_factor = spacing / RESIZE_SPACING\n",
    "        new_real_shape = img.shape * resize_factor\n",
    "        new_shape = np.round(new_real_shape)\n",
    "        real_resize = new_shape / img.shape\n",
    "        new_spacing = spacing / real_resize\n",
    "        \n",
    "        \n",
    "        lung_img = scipy.ndimage.interpolation.zoom(img, real_resize)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print('Original image shape: {}'.format(img.shape))\n",
    "        #print('Resized image shape: {}'.format(lung_img.shape))\n",
    "\n",
    "        lung_img = get_pixels_hu(lung_img)\n",
    "        #lung_mask = segment_lung_from_ct_scan(lung_img)\n",
    "        #lung_mask[lung_mask >= threshold_max] = threshold_max\n",
    "        #lung_img[lung_img >= threshold_max] = threshold_max\n",
    "        #lung_img[lung_img == 0] = threshold_min\n",
    "        \n",
    "        \n",
    "        \n",
    "        lung_mask = lung_img.copy()\n",
    "        #lung_mask[lung_mask == 0] = threshold_min\n",
    "        lung_mask[lung_mask >= threshold_max] = threshold_max\n",
    "        lung_img[lung_img >= threshold_max] = threshold_max\n",
    "        \n",
    "        lung_masks_512 = np.zeros([lung_img.shape[0], height_mask, width_mask], dtype = np.float32)\n",
    "        nodule_masks_512 = np.zeros([lung_img.shape[0], height_mask, width_mask], dtype = np.float32)\n",
    "        lung_masks_512[lung_masks_512 == 0] = threshold_min\n",
    "        \n",
    "        i = 0\n",
    "\n",
    "        nodule_mask = np.ones(lung_img.shape)\n",
    "        #print('nodule_mask shape: {}'.format(nodule_mask.shape))\n",
    "        lung_img_512, lung_mask_512, nodule_mask_512 = np.zeros((lung_img.shape[0], 512, 512)), np.zeros((lung_mask.shape[0], 512, 512)), np.zeros((nodule_mask.shape[0], 512, 512))\n",
    "        lung_mask_512[lung_mask_512 == 0] = threshold_min\n",
    "        lung_img_512[lung_img_512 == 0] = threshold_min\n",
    "        original_shape = lung_img.shape\n",
    "            \n",
    "        for z in range(lung_img.shape[0]):\n",
    "                \n",
    "            offset = (512 - original_shape[1])\n",
    "            upper_offset = int(np.round(offset/2))\n",
    "            lower_offset = int(offset - upper_offset)\n",
    "\n",
    "            new_origin = voxel_2_world([-upper_offset,-lower_offset,0],origin,new_spacing)\n",
    "                \n",
    "            lung_img_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = lung_img[z,:,:]\n",
    "            lung_mask_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = lung_mask[z,:,:]\n",
    "            nodule_mask_512[z, upper_offset:-lower_offset,upper_offset:-lower_offset] = nodule_mask[z,:,:]\n",
    "        nodule_masks_512 += nodule_mask_512\n",
    "        #print('Offsets shape for node index {} - main: {}, upper: {}, lower: {}'.format(node_idx, offset, upper_offset, lower_offset), '\\n')\n",
    "      \n",
    "        #print('nodule_masks_512 shape: {}'.format(nodule_masks_512.shape))\n",
    "        \n",
    "        lung_mask_pres, nod_mask_pres, lung_raw_pres = get_nodule_slices(lung_mask_512, nodule_masks_512, lung_img_512)\n",
    "        #print('Nodules present on slices: ', np.unique(np.nonzero(nodule_masks_512)[0]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        del lung_mask_512, nodule_masks_512, lung_img_512\n",
    "        gc.collect()\n",
    "        \n",
    "        lung_mask_pres = reshape_3d(lung_mask_pres)\n",
    "        nod_mask_pres = reshape_3d(nod_mask_pres)\n",
    "        lung_mask_pres[lung_mask_pres <= threshold_min] = threshold_min\n",
    "        lung_mask_pres[lung_mask_pres >= threshold_max] = threshold_max\n",
    "        \n",
    "        lung_mask_preproc = my_PreProc(lung_mask_pres)\n",
    "        lung_mask_preproc = lung_mask_preproc.astype(np.float32)\n",
    "        nod_mask_pres = (nod_mask_pres > 0.0).astype(np.float32)\n",
    "        nod_mask_pres[nod_mask_pres == 1.0] = 255.\n",
    "\n",
    "        np.save('{}/pre_lung_mask/{}.npy'.format(dst_nodules, patient_id), lung_mask_preproc)\n",
    "        #np.save('{}/nodule_mask/{}.npy'.format(dst_nodules, patient_id), nod_mask_pres)\n",
    "        \n",
    "        del lung_mask_pres, lung_mask_preproc, nod_mask_pres\n",
    "        gc.collect()\n",
    "            \n",
    "        #return lung_mask_preproc, nod_mask_pres\n",
    "        return\n",
    "    else: \n",
    "        print('\\n', 'No nodules found for patient: {}'.format(patient_id), '\\n')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold_min = -2000\n",
    "threshold_max = 400\n",
    "height_mask = 512\n",
    "width_mask = 512\n",
    "\n",
    "Parallel(n_jobs=5)(delayed(create_masks_for_patient_watershed1)(patient) for patient in sorted(patients))\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = luna_path + 'Data/train_mask/pre_lung_mask/'\n",
    "dst_nodules = luna_path + 'Data/train_mask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = []\n",
    "subset_path = os.listdir(src)\n",
    "for _ in range(len(subset_path)):\n",
    "    if subset_path[_] != '.DS_Store':\n",
    "        file_list.append(src+subset_path[_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seriesuid_ = []\n",
    "coordZ_ = []\n",
    "coordX_ = []\n",
    "coordY_ = []\n",
    "diameter_mm_ = []\n",
    "\n",
    "#temp = temp[1:temp.shape[0]-1]\n",
    "for _ in tqdm(file_list):\n",
    "    temp = np.load(_)     \n",
    "    \n",
    "    patient_id = _.split('/')[-1][:-4]\n",
    "\n",
    "    \n",
    "    temp = predict_on_scan(np.squeeze(temp))\n",
    "    temp[temp < 1] = 0\n",
    "    temp = skimage.morphology.binary_opening(np.squeeze(temp),np.ones([5,5,5]))\n",
    "    labels= measure.label(np.squeeze(temp))\n",
    "    props = regionprops(labels)\n",
    "    for i in range(len(props)):             \n",
    "        if props[i]['EquivDiameter'] < 30:\n",
    " \n",
    "            seriesuid_.append(patient_id)\n",
    "            coordZ_.append(props[i]['Centroid'][2])\n",
    "            coordX_.append(props[i]['Centroid'][0])\n",
    "            coordY_.append(props[i]['Centroid'][1])\n",
    "            diameter_mm_.append(props[i]['EquivDiameter'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "aa = pd.DataFrame({'seriesuid':seriesuid_,\n",
    "             'coordX':coordX_,\n",
    "             'coordY':coordY_,\n",
    "             'coordZ':coordZ_,\n",
    "             'diameter_mm':diameter_mm_,})\n",
    "aa = aa[['seriesuid','coordX','coordY','coordZ','diameter_mm']]\n",
    "\n",
    "\n",
    "aa.to_csv('/Volumes/solo/ali/csv/train/annotations_pre3.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、提取质心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = luna_path + 'Data/train/'\n",
    "patients = load_train()\n",
    "df_node = pd.read_csv('/Volumes/solo/ali/csv/train/annotations_pre1.csv',index_col=None)\n",
    "df_node[\"file\"] = df_node[\"seriesuid\"].map(lambda file_name: get_filename(patients, file_name))\n",
    "aa = df_node.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1078it [6:11:05, 23.03s/it]"
     ]
    }
   ],
   "source": [
    "seriesuid_ = []\n",
    "diameter_mm_ = []\n",
    "coordZ_w = []\n",
    "coordX_w = []\n",
    "coordY_w = []\n",
    "\n",
    "origin_ = []\n",
    "new_spacing_ = []\n",
    "offset_ = []\n",
    "\n",
    "for ix, row in tqdm(aa.iterrows()):\n",
    "    img, origin, spacing = load_itk(src + row['file'])\n",
    "    \n",
    "    RESIZE_SPACING = [1, 1, 1]\n",
    "    resize_factor = spacing / RESIZE_SPACING\n",
    "    new_real_shape = img.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize = new_shape / img.shape\n",
    "    new_spacing = spacing / real_resize\n",
    "    \n",
    "    lung_img = scipy.ndimage.interpolation.zoom(img, real_resize)\n",
    "    original_shape = lung_img.shape\n",
    "    offset = (512 - original_shape[1])\n",
    "    upper_offset = int(np.round(offset/2))\n",
    "    lower_offset = int(offset - upper_offset)\n",
    "\n",
    "    new_origin = voxel_2_world([-upper_offset,-lower_offset,0],origin,new_spacing)\n",
    "    \n",
    "    \n",
    "    [a1,a2,a3] = img.shape\n",
    "    [b1,b2,b3] = lung_img.shape\n",
    "    aa = np.array([a1,a2,a3],dtype=np.float32)\n",
    "    bb = np.array([b1,b2,b3],dtype=np.float32)\n",
    "    \n",
    "    offset = int(np.round(offset/2))\n",
    "    \n",
    "    z = row['coordX']\n",
    "    y = row['coordY']-offset\n",
    "    x = row['coordZ']-offset\n",
    "   \n",
    "    \n",
    "    voxel_center = np.array([z,y,x])  \n",
    "    \n",
    "    world_center = voxel_2_world(voxel_center, origin, new_spacing)\n",
    "    \n",
    "    coordZ_w.append(world_center[0])\n",
    "    coordY_w.append(world_center[1])\n",
    "    coordX_w.append(world_center[2])\n",
    "    \n",
    "    origin_.append(origin)\n",
    "    new_spacing_.append(new_spacing)\n",
    "    offset_.append(offset)\n",
    "    seriesuid_.append(row['seriesuid'])\n",
    "    diameter_mm_.append(row['diameter_mm'])\n",
    "    \n",
    "    bb = pd.DataFrame({'seriesuid':seriesuid_,\n",
    "             'coordX':coordX_w,\n",
    "             'coordY':coordY_w,\n",
    "             'coordZ':coordZ_w,\n",
    "             'diameter_mm':diameter_mm_,\n",
    "             'origin':origin_,\n",
    "             'new_spacing':new_spacing_,\n",
    "             'offset':offset_,\n",
    "                  })\n",
    "    bb = bb[['seriesuid','coordX','coordY','coordZ','diameter_mm','origin','new_spacing','offset']]\n",
    "    bb.to_csv('/Volumes/solo/ali/csv/train/annotations_2.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 制表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb = pd.DataFrame({'seriesuid':seriesuid_,\n",
    "             'coordX':coordX_w,\n",
    "             'coordY':coordY_w,\n",
    "             'coordZ':coordZ_w,\n",
    "             'diameter_mm':diameter_mm_,\n",
    "             'origin':origin_,\n",
    "             'new_spacing':new_spacing_,\n",
    "             'offset':offset_,\n",
    "                  })\n",
    "bb = bb[['seriesuid','coordX','coordY','coordZ','diameter_mm','origin','new_spacing','offset']]\n",
    "bb.to_csv('/Volumes/solo/ali/csv/train/annotations_pred_nodule.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
