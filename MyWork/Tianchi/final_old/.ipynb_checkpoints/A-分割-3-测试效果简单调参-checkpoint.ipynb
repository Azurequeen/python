{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef_np(y_true,y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return ((2. * intersection + 1) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1))/255\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def unet_model(dropout_rate,width):\n",
    "    inputs = Input((1, 512, 512))\n",
    "    conv1 = Convolution2D(width, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution2D(width, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Convolution2D(width*2, (3, 3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "    conv2 = BatchNormalization(axis = 1)(conv2)\n",
    "    conv2 = Convolution2D(width*2, (3, 3), padding=\"same\", activation=\"relu\")(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Convolution2D(width*4, (3, 3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "    conv3 = BatchNormalization(axis = 1)(conv3)\n",
    "    conv3 = Convolution2D(width*4, (3, 3), padding=\"same\", activation=\"relu\")(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Convolution2D(width*8, (3, 3), padding=\"same\", activation=\"relu\")(pool3)\n",
    "    conv4 = BatchNormalization(axis = 1)(conv4)\n",
    "    conv4 = Convolution2D(width*8, (3, 3), padding=\"same\", activation=\"relu\")(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Convolution2D(width*16, (3, 3), padding=\"same\", activation=\"relu\")(pool4)\n",
    "    conv5 = BatchNormalization(axis = 1)(conv5)\n",
    "    conv5 = Convolution2D(width*16, (3, 3), padding=\"same\", activation=\"relu\")(conv5)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = SpatialDropout2D(dropout_rate)(up6)\n",
    "    conv6 = Convolution2D(width*8, (3, 3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "    conv6 = Convolution2D(width*8, (3, 3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = SpatialDropout2D(dropout_rate)(up7)\n",
    "    conv7 = Convolution2D(width*4, (3, 3), padding=\"same\", activation=\"relu\")(conv7)\n",
    "    conv7 = Convolution2D(width*4, (3, 3), padding=\"same\", activation=\"relu\")(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = SpatialDropout2D(dropout_rate)(up8)\n",
    "    conv8 = Convolution2D(width*2, (3, 3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "    conv8 = Convolution2D(width*2, (3, 3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = SpatialDropout2D(dropout_rate)(up9)\n",
    "    conv9 = Convolution2D(width, (3, 3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "    conv9 = Convolution2D(width, (3, 3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "    conv10 = Convolution2D(1, (1, 1), activation=\"sigmoid\")(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    #model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9, nesterov=True), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    return model\n",
    "\n",
    "def simule():\n",
    "    mean = 0.0\n",
    "    for scan in tqdm(lung_100):\n",
    "        patient_id = scan.split('/')[-1][:-4]\n",
    "        img = cv2.imread(data_path + 'lung/' + scan,cv2.IMREAD_GRAYSCALE)   \n",
    "        seg_img, overlap = helpers.get_segmented_lungs(img.copy())\n",
    "        mask = cv2.imread(data_path + 'nodule/' + scan[:-5] + 'm.png',cv2.IMREAD_GRAYSCALE).astype(int) \n",
    "        img = np.expand_dims(img,0)\n",
    "        img = np.expand_dims(img,0)   \n",
    "        p = model_fenge.predict(img).astype(int)  \n",
    "        p = np.squeeze(p)\n",
    "\n",
    "        #细节参数调整\n",
    "        \n",
    "        #p = p*overlap\n",
    "        p = skimage.morphology.binary_opening(np.squeeze(p), np.ones([3,3]))       \n",
    "        \n",
    "        mean += dice_coef_np(mask,p)\n",
    "    mean/=len(lung_100)\n",
    "    print(u\"分割的相似度是：%.6f%%\"  %(mean*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path = PATH['annotations_train']\n",
    "model_paths = PATH['model_paths']\n",
    "pred_path = PATH['model_train_pred']\n",
    "data_path = PATH['model_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "model_fenge_path=model_paths + 'final_fenge_170603.h5'\n",
    "model_fenge = unet_model(dropout_rate=0.35,width=64)\n",
    "model_fenge.load_weights(model_fenge_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lungs = [x for x in sorted(os.listdir(data_path + 'lung/')) if x != '.DS_Store']\n",
    "nods = [x for x in sorted(os.listdir(data_path + 'nodule/')) if x != '.DS_Store']\n",
    "lung_100 = sorted(np.random.choice(lungs,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型预测结果与GroundTruth的相似度应越高越好，满值为1\n",
    "### 加上肺部掩模不能提高结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:23<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割的相似度是：0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "simule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
