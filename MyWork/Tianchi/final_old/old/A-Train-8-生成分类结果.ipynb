{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path = PATH['annotations_train']\n",
    "src = PATH['model_train_pred']\n",
    "pred_csv_path = PATH['model_train_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_paths = PATH['model_paths']\n",
    "model_final = PATH['model_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cube_30 = load_model(model_final + 'Fenge_36_36_36.h5')\n",
    "model_20 = load_model(model_final + 'Fenge_06_20_20.h5')\n",
    "model_30 = load_model(model_final + 'Fenge_10_30_30.h5')\n",
    "model_40 = load_model(model_final + 'Fenge_26_40_40.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_1 = pd.read_csv(csv_path + \"annotations_all.csv\")\n",
    "test_pred_2 = pd.read_csv(pred_csv_path + \"2pred_csv_new.csv\")\n",
    "\n",
    "test_pred_1['True'] = int(1)\n",
    "test_pred_2 = test_pred_2.drop(['ratio','dist'],axis=1)\n",
    "\n",
    "test_pred_0 = pd.concat([test_pred_1,test_pred_2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients = [x for x in os.listdir(pred_csv_path) if 'orig' in x]   \n",
    "\n",
    "test_pred_0[\"file\"] = test_pred_0[\"seriesuid\"].map(lambda file_name: get_filename(patients, file_name))\n",
    "test_pred_0 = test_pred_0.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [52:23<00:00,  3.31s/it]  \n"
     ]
    }
   ],
   "source": [
    "probability_30_30_30_cube = []\n",
    "probability_06_20_20 = []\n",
    "probability_10_30_30 = []\n",
    "probability_26_40_40 = []\n",
    "\n",
    "\n",
    "for img_file in tqdm(sorted(patients)):\n",
    "    mini_df_anno = test_pred_0[test_pred_0[\"file\"]==img_file] #get all nodules associate with file\n",
    "    if mini_df_anno.shape[0]>0: # some files may not have a nodule--skipping those \n",
    "        # load the data once        \n",
    "        patient_id = img_file[:-9]\n",
    "        img_array = np.load(src + img_file)\n",
    "        pos_annos = pd.read_csv(src + img_file[:-9] + '_annos_pos.csv')\n",
    "        origin = np.array([pos_annos.loc[0]['origin_x'],pos_annos.loc[0]['origin_y'],pos_annos.loc[0]['origin_z']]) \n",
    "        spacing = np.array([pos_annos.loc[0]['spacing_x'],pos_annos.loc[0]['spacing_y'],pos_annos.loc[0]['spacing_z']])\n",
    "        img_array = normalize(img_array)                \n",
    "        for node_idx1, cur_row1 in mini_df_anno.iterrows():       \n",
    "            node_x = cur_row1[\"coordX\"]\n",
    "            node_y = cur_row1[\"coordY\"]\n",
    "            node_z = cur_row1[\"coordZ\"]\n",
    "            diam = cur_row1[\"diameter_mm\"]\n",
    "            center = np.array([node_x, node_y, node_z])   # nodule center\n",
    "            v_center = np.rint(np.absolute(center-origin)/spacing)            \n",
    "            new_x = int(v_center[0])\n",
    "            new_y = int(v_center[1])\n",
    "            new_z = int(v_center[2])\n",
    "            \n",
    "            if new_z<18 or new_x<18 or new_y<18 or new_x+18>img_array.shape[2] or new_y+18>img_array.shape[1] or new_z+18>img_array.shape[0]:\n",
    "                cls_result_cube_30 = int(0)\n",
    "            else:\n",
    "   \n",
    "                trainX_cube_30 =  img_array[new_z - 18: new_z + 18,\n",
    "                                    new_y - 18 : new_y + 18,\n",
    "                                    new_x - 18 : new_x + 18] \n",
    "            \n",
    "                trainX_cube_30=np.expand_dims(trainX_cube_30,0)\n",
    "                trainX_cube_30=np.expand_dims(trainX_cube_30,0)\n",
    "            \n",
    "                cls_result_cube_30 = model_cube_30.predict(trainX_cube_30)[0][1]\n",
    "            probability_30_30_30_cube.append(cls_result_cube_30)\n",
    "\n",
    "            \n",
    "            if new_z<3 or new_x<10 or new_y<10 or new_x+10>img_array.shape[2] or new_y+10>img_array.shape[1] or new_z+3>img_array.shape[0]:\n",
    "                cls_result20 = int(0)\n",
    "            else:\n",
    "   \n",
    "                trainX_20 =  img_array[new_z - 3: new_z + 3,\n",
    "                                    new_y - 10 : new_y + 10,\n",
    "                                    new_x - 10 : new_x + 10] \n",
    "            \n",
    "                trainX_20=np.expand_dims(trainX_20,0)\n",
    "                trainX_20=np.expand_dims(trainX_20,0)\n",
    "            \n",
    "                cls_result_20 = model_20.predict(trainX_20)[0][1]\n",
    "            probability_06_20_20.append(cls_result_20)\n",
    "            \n",
    "            if new_z<5 or new_x<15 or new_y<15 or new_x+15>img_array.shape[2] or new_y+15>img_array.shape[1] or new_z+5>img_array.shape[0]:\n",
    "                cls_result30 = int(0)\n",
    "            else:\n",
    "   \n",
    "                trainX_30 =  img_array[new_z - 5: new_z + 5,\n",
    "                                    new_y - 15 : new_y + 15,\n",
    "                                    new_x - 15 : new_x + 15] \n",
    "            \n",
    "                trainX_30=np.expand_dims(trainX_30,0)\n",
    "                trainX_30=np.expand_dims(trainX_30,0)\n",
    "            \n",
    "                cls_result_30 = model_30.predict(trainX_30)[0][1]\n",
    "            probability_10_30_30.append(cls_result_30)\n",
    "            \n",
    "            \n",
    "            if new_z<13 or new_x<20 or new_y<20 or new_x+20>img_array.shape[2] or new_y+20>img_array.shape[1] or new_z+13>img_array.shape[0]:\n",
    "                cls_result40 = int(0)\n",
    "            else:\n",
    "   \n",
    "                trainX_40 =  img_array[new_z - 13: new_z + 13,\n",
    "                                    new_y - 20 : new_y + 20,\n",
    "                                    new_x - 20 : new_x + 20] \n",
    "            \n",
    "                trainX_40=np.expand_dims(trainX_40,0)\n",
    "                trainX_40=np.expand_dims(trainX_40,0)\n",
    "            \n",
    "                cls_result_40 = model_40.predict(trainX_40)[0][1]\n",
    "            probability_26_40_40.append(cls_result_40)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probability_30_30_30_cube = np.array(probability_30_30_30_cube)\n",
    "probability_30_30_30_cube = probability_30_30_30_cube.clip(0.005,0.995)\n",
    "probability_30_30_30_cube = probability_30_30_30_cube.round(3)\n",
    "test_pred_0['probability_30_30_30_cube'] = probability_30_30_30_cube\n",
    "\n",
    "\n",
    "probability_06_20_20 = np.array(probability_06_20_20)\n",
    "probability_06_20_20 = probability_06_20_20.clip(0.005,0.995)\n",
    "probability_06_20_20 = probability_06_20_20.round(3)\n",
    "test_pred_0['probability_06_20_20'] = probability_06_20_20\n",
    "\n",
    "probability_10_30_30 = np.array(probability_10_30_30)\n",
    "probability_10_30_30 = probability_10_30_30.clip(0.005,0.995)\n",
    "probability_10_30_30 = probability_10_30_30.round(3)\n",
    "test_pred_0['probability_10_30_30'] = probability_10_30_30\n",
    "\n",
    "probability_26_40_40 = np.array(probability_26_40_40)\n",
    "probability_26_40_40 = probability_26_40_40.clip(0.005,0.995)\n",
    "probability_26_40_40 = probability_26_40_40.round(3)\n",
    "test_pred_0['probability_26_40_40'] = probability_26_40_40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_0.to_csv(csv_path + \"0final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
