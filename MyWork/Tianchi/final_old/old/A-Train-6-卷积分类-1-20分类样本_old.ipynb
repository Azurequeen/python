{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *\n",
    "from utils.preproc_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(output,img_array, patient_id, node_idx, new_x, new_y, new_z, cube_radius, i, rand):\n",
    "    trainX_1 = img_array[new_z - cube_radius: new_z + cube_radius,\n",
    "               new_y - cube_radius: new_y + cube_radius,\n",
    "               new_x - cube_radius: new_x + cube_radius]\n",
    "\n",
    "    if trainX_1.shape == (cube_radius * 2, cube_radius * 2, cube_radius * 2):\n",
    "        trainX_1 = resize(trainX_1, [36, 36, 36])\n",
    "        np.save(\n",
    "            output + str(cube_radius * 2) + ('/') + str(patient_id) + '_' + str(node_idx) + '_' + str(i) + '.npy',\n",
    "            trainX_1)\n",
    "        # cv2.imwrite(output_true+str(cube_radius*2)+('/') + str(patient_id)+'_'+str(node_idx1)+str('_2')+ '.png',trainX_1[17]*255) \n",
    "        np.save(output + str(cube_radius * 2) + ('/') + str(patient_id) + '_' + str(node_idx) + '_' + str(\n",
    "            i + 1) + '.npy', trainX_1[:, :, ::-1])\n",
    "        # cv2.imwrite(output_true+str(cube_radius*2)+('/') + str(patient_id)+'_'+str(node_idx1)+str('_3')+ '.png',trainX_1[:, :, ::-1][17]*255)              \n",
    "    if rand > 0:\n",
    "        for j in range(rand):\n",
    "            new_z1 = new_z + random.choice([ -1, 1])\n",
    "            new_y1 = new_y + random.choice([-2, -1, 1, 2])\n",
    "            new_x1 = new_x + random.choice([-2, -1, 1, 2])\n",
    "            trainX_2 = img_array[new_z1 - cube_radius: new_z1 + cube_radius,\n",
    "                       new_y1 - cube_radius: new_y1 + cube_radius,\n",
    "                       new_x1 - cube_radius: new_x1 + cube_radius]\n",
    "            if trainX_2.shape == (cube_radius * 2, cube_radius * 2, cube_radius * 2):\n",
    "                trainX_2 = resize(trainX_2, [36, 36, 36])\n",
    "                np.save(output + str(cube_radius * 2) + ('/') + str(patient_id) + '_' + str(node_idx) + '_' + str(\n",
    "                    i+2) + '_' + str(j) + '.npy', trainX_2)\n",
    "                # cv2.imwrite(output_true+str(cube_radius*2)+('/') + str(patient_id)+'_'+str(node_idx1)+str('_0')+ '.png',trainX_2[17]*255) \n",
    "                np.save(output + str(cube_radius * 2) + ('/') + str(patient_id) + '_' + str(node_idx) + '_' + str(\n",
    "                    i+3) + '_' + str(j) + '.npy', trainX_2[:, :, ::-1])\n",
    "                # cv2.imwrite(output_true+str(cube_radius*2)+('/') + str(patient_id)+'_'+str(node_idx1)+str('_1')+ '.png',trainX_2[:, :, ::-1][17]*255)                                 \n",
    "\n",
    "\n",
    "def create_cls_sample(df_anno,df_pred,img_file,data_path,output_true,output_false):\n",
    "    mini_df_anno = df_anno[df_anno[\"file\"]==img_file] #get all nodules associate with file\n",
    "    mini_df_pred = df_pred[df_pred[\"file\"]==img_file]\n",
    "    if mini_df_anno.shape[0]>0: # some files may not have a nodule--skipping those \n",
    "        patient_id = img_file[:-9]\n",
    "        img_array = np.load(data_path + img_file)\n",
    "        #img_array = normalize(img_array)\n",
    "        \n",
    "        img_array = img_array.clip(-1000,400)\n",
    "        img_array = np.expand_dims(img_array,1)\n",
    "        img_array = np.squeeze(my_PreProc(img_array))\n",
    "        img_array = img_array/255.\n",
    "        img_array[img_array > 1.] = 1.\n",
    "        img_array[img_array < 0.] = 0.\n",
    "        pos_annos = pd.read_csv(data_path + img_file[:-9] + '_annos_pos.csv')\n",
    "        origin = np.array([pos_annos.loc[0]['origin_x'],pos_annos.loc[0]['origin_y'],pos_annos.loc[0]['origin_z']]) \n",
    "        spacing = np.array([pos_annos.loc[0]['spacing_x'],pos_annos.loc[0]['spacing_y'],pos_annos.loc[0]['spacing_z']]) \n",
    "        \n",
    "        for node_idx1, cur_row1 in mini_df_anno.iterrows():       \n",
    "            node_x = cur_row1[\"coordX\"]\n",
    "            node_y = cur_row1[\"coordY\"]\n",
    "            node_z = cur_row1[\"coordZ\"]\n",
    "            diam = cur_row1[\"diameter_mm\"]\n",
    "            center = np.array([node_x, node_y, node_z])   # nodule center\n",
    "            v_center = np.rint(np.absolute(center-origin)/spacing)  # nodule center in voxel space (still x,y,z ordering)            \n",
    "            new_x = int(v_center[2])\n",
    "            new_y = int(v_center[1])\n",
    "            new_z = int(v_center[0])\n",
    "       \n",
    "\n",
    "            get_image(output_true,img_array,patient_id,node_idx1,new_x,new_y,new_z,6,0,0) \n",
    "            get_image(output_true,img_array,patient_id,node_idx1,new_x,new_y,new_z,9,4,0) \n",
    "            get_image(output_true,img_array,patient_id,node_idx1,new_x,new_y,new_z,12,8,0) \n",
    "                \n",
    "        for node_idx2, cur_row2 in mini_df_pred.iterrows():       \n",
    "            node_x = cur_row2[\"coordX\"]\n",
    "            node_y = cur_row2[\"coordY\"]\n",
    "            node_z = cur_row2[\"coordZ\"]\n",
    "            diam = cur_row2[\"diameter_mm\"]\n",
    "            center = np.array([node_x, node_y, node_z])   # nodule center\n",
    "            v_center = np.rint(np.absolute(center-origin)/spacing)  # nodule center in voxel space (still x,y,z ordering)            \n",
    "            new_x0 = int(v_center[2])\n",
    "            new_y0 = int(v_center[1])\n",
    "            new_z0 = int(v_center[0])         \n",
    "\n",
    "            get_image(output_false,img_array,patient_id,node_idx2,new_x0,new_y0,new_z0,6,0,0) \n",
    "            get_image(output_false,img_array,patient_id,node_idx2,new_x0,new_y0,new_z0,9,4,0) \n",
    "            get_image(output_false,img_array,patient_id,node_idx2,new_x0,new_y0,new_z0,12,8,0) \n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = PATH['annotations_train']\n",
    "output_true = PATH['cls_train_cube_30_true']\n",
    "output_false = PATH['cls_train_cube_30_false']\n",
    "pred_csv_path = PATH['model_train_pred']\n",
    "data_path = PATH['model_train_pred']\n",
    "anno_csv_new = pd.read_csv(csv_path + \"annotations_all.csv\")\n",
    "pred_csv_new = pd.read_csv(pred_csv_path + \"2pred_csv_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_csv_new = pred_csv_new[pred_csv_new.index%4 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients = [x for x in os.listdir(data_path) if 'orig.npy' in x][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anno_csv_new[\"file\"] = anno_csv_new[\"seriesuid\"].map(lambda file_name: get_filename(patients, file_name))\n",
    "anno_csv_new = anno_csv_new.dropna()\n",
    "pred_csv_new[\"file\"] = pred_csv_new[\"seriesuid\"].map(lambda file_name: get_filename(patients, file_name))\n",
    "pred_csv_new = pred_csv_new.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:32<00:00,  1.76s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(create_cls_sample)(anno_csv_new,pred_csv_new,patient,data_path,output_true,output_false) for patient in tqdm(sorted(patients)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = True\n",
    "delete = False\n",
    "\n",
    "if delete:\n",
    "    for i in os.listdir(output_true):\n",
    "        if i != '.DS_Store':\n",
    "            for j in os.listdir(output_true+i):\n",
    "                if j != '.DS_Store':\n",
    "                    os.remove(output_true+i+'/'+j)\n",
    "    for i in os.listdir(output_false):\n",
    "        if i != '.DS_Store':\n",
    "            for j in os.listdir(output_false+i):\n",
    "                if j != '.DS_Store':\n",
    "                    os.remove(output_false+i+'/'+j)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
