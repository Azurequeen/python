{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/Volumes/solo/ali/Data/train_cls_20/train/false/', u'maked')\n",
      "('/Volumes/solo/ali/Data/train_cls_20/train/true/', u'maked')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cls_sample(df_anno,df_pred,img_file,data_path,output_true,output_false):\n",
    "    mini_df_anno = df_anno[df_anno[\"file\"]==img_file] #get all nodules associate with file\n",
    "    if mini_df_anno.shape[0]>0: # some files may not have a nodule--skipping those \n",
    "        # load the data once\n",
    "        patient_id = img_file.split('/')[-1][:-4]\n",
    "        itk_img = SimpleITK.ReadImage(data_path + img_file) \n",
    "        img_array = SimpleITK.GetArrayFromImage(itk_img) # indexes are z,y,x (notice the ordering)\n",
    "        num_z, height, width = img_array.shape        #heightXwidth constitute the transverse plane\n",
    "        origin = np.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "        spacing = np.array(itk_img.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "        # go through all nodes (why just the biggest?)\n",
    "        for node_idx, cur_row in mini_df_anno.iterrows():       \n",
    "            node_x = cur_row[\"coordX\"]\n",
    "            node_y = cur_row[\"coordY\"]\n",
    "            node_z = cur_row[\"coordZ\"]\n",
    "            diam = cur_row[\"diameter_mm\"]\n",
    "            center = np.array([node_x, node_y, node_z])   # nodule center\n",
    "            v_center = np.rint(np.absolute(center-origin)/spacing)  # nodule center in voxel space (still x,y,z ordering)\n",
    "            img_array = normalize(img_array)\n",
    "            \n",
    "            new_x = int(v_center[0])\n",
    "            new_y = int(v_center[1])\n",
    "            new_z = int(v_center[2])\n",
    "            trainX_1 =  img_array[new_x - 3: new_x + 3,\n",
    "                                 new_y - 10 : new_y + 10,\n",
    "                                 new_z - 10 : new_z + 10] \n",
    "            \n",
    "            if trainX_1.shape == (6,20,20):\n",
    "                np.save(output_true + str(patient_id)+'_'+str(node_idx)+'_'+str('_0_')+ '_3d_20_6_i.npy',trainX_1)            \n",
    "               \n",
    "        \n",
    "                \n",
    "    mini_df_pred = df_pred[df_pred[\"file\"]==img_file] #get all nodules associate with file\n",
    "    if mini_df_pred.shape[0]>0: # some files may not have a nodule--skipping those \n",
    "        # load the data once\n",
    "        patient_id = img_file.split('/')[-1][:-4]\n",
    "        itk_img = SimpleITK.ReadImage(data_path + img_file) \n",
    "        img_array = SimpleITK.GetArrayFromImage(itk_img) # indexes are z,y,x (notice the ordering)\n",
    "        num_z, height, width = img_array.shape        #heightXwidth constitute the transverse plane\n",
    "        origin = np.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "        spacing = np.array(itk_img.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "        # go through all nodes (why just the biggest?)\n",
    "        for node_idx, cur_row in mini_df_pred.iterrows():       \n",
    "            node_x = cur_row[\"coordX\"]\n",
    "            node_y = cur_row[\"coordY\"]\n",
    "            node_z = cur_row[\"coordZ\"]\n",
    "            diam = cur_row[\"diameter_mm\"]\n",
    "            center = np.array([node_x, node_y, node_z])   # nodule center\n",
    "            v_center = np.rint(np.absolute(center-origin)/spacing)  # nodule center in voxel space (still x,y,z ordering)\n",
    "            img_array = normalize(img_array)\n",
    "            \n",
    "            new_x = int(v_center[0])\n",
    "            new_y = int(v_center[1])\n",
    "            new_z = int(v_center[2])\n",
    "            \n",
    "            trainX =   img_array[new_x - 3: new_x + 3,\n",
    "                                 new_y - 10: new_y + 10,\n",
    "                                 new_z - 10: new_z + 10] \n",
    "    \n",
    "            if trainX.shape == (6,20,20):\n",
    "                np.save(output_false + str(patient_id)+'_'+str(node_idx)+'_'+str(new_y) + '_3d_20_6_i.npy',trainX)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path = PATH['annotations_train']\n",
    "output_true = PATH['cls_train_20_true']\n",
    "output_false = PATH['cls_train_20_false']\n",
    "pred_csv_path = PATH['model_train_pred']\n",
    "data_path = PATH['src_train']\n",
    "anno_csv_new = pd.read_csv(csv_path + \"annotations_all.csv\")\n",
    "pred_csv_new = pd.read_csv(pred_csv_path + \"anno_false_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_csv_new = pred_csv_new[pred_csv_new.index%12 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients=load_train(data_path)\n",
    "anno_csv_new[\"file\"] = anno_csv_new[\"seriesuid\"].map(lambda file_name: get_filename(patients, file_name))\n",
    "anno_csv_new = anno_csv_new.dropna()\n",
    "pred_csv_new[\"file\"] = pred_csv_new[\"seriesuid\"].map(lambda file_name: get_filename(patients, file_name))\n",
    "pred_csv_new = pred_csv_new.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 494/600 [24:52<04:04,  2.30s/it]  "
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(create_cls_sample)(anno_csv_new,pred_csv_new,patient,data_path,output_true,output_false) for patient in tqdm(sorted(patients)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
