{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/Volumes/solo/ali/Data/train_cls_cube_36/train/true/', u'maked')\n",
      "('/Volumes/solo/ali/Data/train_cls_cube_36/train/false/', u'maked')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cls_sample(df_anno,df_pred,img_file,data_path,output_true,output_false):\n",
    "    mini_df_anno = df_anno[df_anno[\"file\"]==img_file] \n",
    "    mini_df_pred = df_pred[df_pred[\"file\"]==img_file]\n",
    "    if mini_df_anno.shape[0]>0:\n",
    "        patient_id = img_file[:-9]\n",
    "        img_array = np.load(data_path + img_file)\n",
    "        img_array = normalize(img_array)\n",
    "        pos_annos = pd.read_csv(data_path + img_file[:-9] + '_annos_pos.csv')\n",
    "        origin = np.array([pos_annos.loc[0]['origin_x'],pos_annos.loc[0]['origin_y'],pos_annos.loc[0]['origin_z']]) \n",
    "        spacing = np.array([pos_annos.loc[0]['spacing_x'],pos_annos.loc[0]['spacing_y'],pos_annos.loc[0]['spacing_z']]) \n",
    "        \n",
    "        for node_idx1, cur_row1 in mini_df_anno.iterrows():       \n",
    "            node_x = cur_row1[\"coordX\"]\n",
    "            node_y = cur_row1[\"coordY\"]\n",
    "            node_z = cur_row1[\"coordZ\"]\n",
    "            diam = cur_row1[\"diameter_mm\"]\n",
    "            center = np.array([node_x, node_y, node_z])   \n",
    "            v_center = np.rint(np.absolute(center-origin)/spacing) \n",
    "            \n",
    "            new_x = int(v_center[0])\n",
    "            new_y = int(v_center[1])\n",
    "            new_z = int(v_center[2])\n",
    "            trainX_1 =  img_array[new_z - 16 : new_z + 16,\n",
    "                                  new_y - 16 : new_y + 16,\n",
    "                                  new_x - 16 : new_x + 16] \n",
    "            \n",
    "            if trainX_1.shape == (32,32,32):\n",
    "                np.save(output_true + str(patient_id)+'_'+str(node_idx1)+str('_0')+ '.npy',trainX_1)\n",
    "                np.save(output_true + str(patient_id)+'_'+str(node_idx1)+str('_1')+ '.npy',np.fliplr(trainX_1))\n",
    "                #np.save(output_true + str(patient_id)+'_'+str(node_idx1)+str('_2')+ '.npy',np.flipud(trainX_1))\n",
    "            \n",
    "            new_z1 = new_z + random.choice([-3,-2,-1,1,2,3])\n",
    "            new_y1 = new_y + random.choice([-3,-2,-1,1,2,3])\n",
    "            new_x1 = new_x + random.choice([-3,-2,-1,1,2,3])\n",
    "            \n",
    "            trainX_2 =  img_array[new_z1 - 16 : new_z1 + 16,\n",
    "                                  new_y1 - 16 : new_y1 + 16,\n",
    "                                  new_x1 - 16 : new_x1 + 16] \n",
    "            \n",
    "            if trainX_2.shape == (32,32,32):\n",
    "                np.save(output_true + str(patient_id)+'_'+str(node_idx1)+str('_3') + '.npy',trainX_2)\n",
    "                np.save(output_true + str(patient_id)+'_'+str(node_idx1)+str('_4') + '.npy',np.fliplr(trainX_2))\n",
    "#                 np.save(output_true + str(patient_id)+'_'+str(node_idx1)+str('_5') + '.npy',np.flipud(trainX_2))                                         \n",
    "\n",
    "        for node_idx2, cur_row2 in mini_df_pred.iterrows():       \n",
    "            node_x = cur_row2[\"coordX\"]\n",
    "            node_y = cur_row2[\"coordY\"]\n",
    "            node_z = cur_row2[\"coordZ\"]\n",
    "            diam = cur_row2[\"diameter_mm\"]\n",
    "            center = np.array([node_x, node_y, node_z])   \n",
    "            v_center = np.rint(np.absolute(center-origin)/spacing)  \n",
    "            \n",
    "            \n",
    "            new_x = int(v_center[0])\n",
    "            new_y = int(v_center[1])\n",
    "            new_z = int(v_center[2])\n",
    "            \n",
    "            trainXf =   img_array[new_z - 16 : new_z + 16,\n",
    "                                 new_y - 16 : new_y + 16,\n",
    "                                 new_x - 16 : new_x + 16] \n",
    "    \n",
    "            if trainXf.shape == (32,32,32):\n",
    "                np.save(output_false + str(patient_id)+'_'+str(node_idx2)+str('_0') + '.npy',trainXf)\n",
    "                np.save(output_false + str(patient_id)+'_'+str(node_idx1)+str('_1') + '.npy',np.fliplr(trainXf))\n",
    "                #np.save(output_false + str(patient_id)+'_'+str(node_idx1)+str('_2') + '.npy',np.flipud(trainXf))                \n",
    "                \n",
    "#             new_z2 = new_z + random.choice([-3,-2,-1,1,2,3])\n",
    "#             new_y2 = new_y + random.choice([-3,-2,-1,1,2,3])\n",
    "#             new_x2 = new_x + random.choice([-3,-2,-1,1,2,3])\n",
    "            \n",
    "#             trainXf_2 =  img_array[new_z2 - 16 : new_z2 + 16,\n",
    "#                                   new_y2 - 16 : new_y2 + 16,\n",
    "#                                   new_x2 - 16 : new_x2 + 16] \n",
    "            \n",
    "#             if trainXf_2.shape == (32,32,32):\n",
    "#                 np.save(output_false + str(patient_id)+'_'+str(node_idx2)+str('_3') + '.npy',trainXf_2)\n",
    "#                 np.save(output_false + str(patient_id)+'_'+str(node_idx2)+str('_4') + '.npy',np.fliplr(trainXf_2))\n",
    "#                 np.save(output_false + str(patient_id)+'_'+str(node_idx2)+str('_5') + '.npy',np.flipud(trainXf_2))                                         \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path = PATH['annotations_train']\n",
    "output_true = PATH['cls_train_cube_30_true']\n",
    "output_false = PATH['cls_train_cube_30_false']\n",
    "pred_csv_path = PATH['model_train_pred']\n",
    "data_path = PATH['model_train_pred']\n",
    "anno_csv_new = pd.read_csv(pred_csv_path + \"anno_true_final.csv\")\n",
    "pred_csv_new = pd.read_csv(pred_csv_path + \"anno_false_final.csv\")\n",
    "#pred_csv_new = pd.read_csv(pred_csv_path + \"anno_false_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients = [x for x in os.listdir(data_path) if 'orig.npy' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anno_csv_new[\"file\"] = anno_csv_new[\"seriesuid\"].map(lambda file_name: get_filename(patients, file_name))\n",
    "anno_csv_new = anno_csv_new.dropna()\n",
    "pred_csv_new[\"file\"] = pred_csv_new[\"seriesuid\"].map(lambda file_name: get_filename(patients, file_name))\n",
    "pred_csv_new = pred_csv_new.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 176/800 [00:37<01:42,  6.11it/s]"
     ]
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(create_cls_sample)(anno_csv_new,pred_csv_new,patient,data_path,output_true,output_false) for patient in tqdm(sorted(patients)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
