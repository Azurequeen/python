{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *\n",
    "MEAN_FRAME_COUNT = 1\n",
    "CHANNEL_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_scale_img(img, xy_range, lock_xy=False):\n",
    "    if random.random() > xy_range.chance:\n",
    "        return img\n",
    "\n",
    "    if not isinstance(img, list):\n",
    "        img = [img]\n",
    "\n",
    "    import cv2\n",
    "    scale_x = random.uniform(xy_range.x_min, xy_range.x_max)\n",
    "    scale_y = random.uniform(xy_range.y_min, xy_range.y_max)\n",
    "    if lock_xy:\n",
    "        scale_y = scale_x\n",
    "\n",
    "    org_height, org_width = img[0].shape[:2]\n",
    "    xy_range.last_x = scale_x\n",
    "    xy_range.last_y = scale_y\n",
    "\n",
    "    res = []\n",
    "    for img_inst in img:\n",
    "        scaled_width = int(org_width * scale_x)\n",
    "        scaled_height = int(org_height * scale_y)\n",
    "        scaled_img = cv2.resize(img_inst, (scaled_width, scaled_height), interpolation=cv2.INTER_CUBIC)\n",
    "        if scaled_width < org_width:\n",
    "            extend_left = (org_width - scaled_width) / 2\n",
    "            extend_right = org_width - extend_left - scaled_width\n",
    "            scaled_img = cv2.copyMakeBorder(scaled_img, 0, 0, extend_left, extend_right, borderType=cv2.BORDER_CONSTANT)\n",
    "            scaled_width = org_width\n",
    "\n",
    "        if scaled_height < org_height:\n",
    "            extend_top = (org_height - scaled_height) / 2\n",
    "            extend_bottom = org_height - extend_top - scaled_height\n",
    "            scaled_img = cv2.copyMakeBorder(scaled_img, extend_top, extend_bottom, 0, 0,  borderType=cv2.BORDER_CONSTANT)\n",
    "            scaled_height = org_height\n",
    "\n",
    "        start_x = (scaled_width - org_width) / 2\n",
    "        start_y = (scaled_height - org_height) / 2\n",
    "        tmp = scaled_img[start_y: start_y + org_height, start_x: start_x + org_width]\n",
    "        res.append(tmp)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "class XYRange:\n",
    "    def __init__(self, x_min, x_max, y_min, y_max, chance=1.0):\n",
    "        self.chance = chance\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.y_min = y_min\n",
    "        self.y_max = y_max\n",
    "        self.last_x = 0\n",
    "        self.last_y = 0\n",
    "\n",
    "    def get_last_xy_txt(self):\n",
    "        res = \"x_\" + str(int(self.last_x * 100)).replace(\"-\", \"m\") + \"-\" + \"y_\" + str(int(self.last_y * 100)).replace(\"-\", \"m\")\n",
    "        return res\n",
    "\n",
    "\n",
    "def random_translate_img(img, xy_range, border_mode=\"constant\"):\n",
    "    if random.random() > xy_range.chance:\n",
    "        return img\n",
    "    import cv2\n",
    "    if not isinstance(img, list):\n",
    "        img = [img]\n",
    "\n",
    "    org_height, org_width = img[0].shape[:2]\n",
    "    translate_x = random.randint(xy_range.x_min, xy_range.x_max)\n",
    "    translate_y = random.randint(xy_range.y_min, xy_range.y_max)\n",
    "    trans_matrix = numpy.float32([[1, 0, translate_x], [0, 1, translate_y]])\n",
    "\n",
    "    border_const = cv2.BORDER_CONSTANT\n",
    "    if border_mode == \"reflect\":\n",
    "        border_const = cv2.BORDER_REFLECT\n",
    "\n",
    "    res = []\n",
    "    for img_inst in img:\n",
    "        img_inst = cv2.warpAffine(img_inst, trans_matrix, (org_width, org_height), borderMode=border_const)\n",
    "        res.append(img_inst)\n",
    "    if len(res) == 1:\n",
    "        res = res[0]\n",
    "    xy_range.last_x = translate_x\n",
    "    xy_range.last_y = translate_y\n",
    "    return res\n",
    "\n",
    "\n",
    "def random_rotate_img(img, chance, min_angle, max_angle):\n",
    "    import cv2\n",
    "    if random.random() > chance:\n",
    "        return img\n",
    "    if not isinstance(img, list):\n",
    "        img = [img]\n",
    "\n",
    "    angle = random.randint(min_angle, max_angle)\n",
    "    center = (img[0].shape[0] / 2, img[0].shape[1] / 2)\n",
    "    rot_matrix = cv2.getRotationMatrix2D(center, angle, scale=1.0)\n",
    "\n",
    "    res = []\n",
    "    for img_inst in img:\n",
    "        img_inst = cv2.warpAffine(img_inst, rot_matrix, dsize=img_inst.shape[:2], borderMode=cv2.BORDER_CONSTANT)\n",
    "        res.append(img_inst)\n",
    "    if len(res) == 0:\n",
    "        res = res[0]\n",
    "    return res\n",
    "\n",
    "\n",
    "def random_flip_img(img, horizontal_chance=0, vertical_chance=0):\n",
    "    import cv2\n",
    "    flip_horizontal = False\n",
    "    if random.random() < horizontal_chance:\n",
    "        flip_horizontal = True\n",
    "\n",
    "    flip_vertical = False\n",
    "    if random.random() < vertical_chance:\n",
    "        flip_vertical = True\n",
    "\n",
    "    if not flip_horizontal and not flip_vertical:\n",
    "        return img\n",
    "\n",
    "    flip_val = 1\n",
    "    if flip_vertical:\n",
    "        flip_val = -1 if flip_horizontal else 0\n",
    "\n",
    "    if not isinstance(img, list):\n",
    "        res = cv2.flip(img, flip_val) # 0 = X axis, 1 = Y axis,  -1 = both\n",
    "    else:\n",
    "        res = []\n",
    "        for img_item in img:\n",
    "            img_flip = cv2.flip(img_item, flip_val)\n",
    "            res.append(img_flip)\n",
    "    return res\n",
    "\n",
    "\n",
    "ELASTIC_INDICES = None  # needed to make it faster to fix elastic deformation per epoch.\n",
    "def elastic_transform(image, alpha, sigma, random_state=None):\n",
    "    global ELASTIC_INDICES\n",
    "    shape = image.shape\n",
    "\n",
    "    if ELASTIC_INDICES == None:\n",
    "        if random_state is None:\n",
    "            random_state = numpy.random.RandomState(1301)\n",
    "\n",
    "        dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "        dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "        x, y = numpy.meshgrid(numpy.arange(shape[0]), numpy.arange(shape[1]))\n",
    "        ELASTIC_INDICES = numpy.reshape(y + dy, (-1, 1)), numpy.reshape(x + dx, (-1, 1))\n",
    "    return map_coordinates(image, ELASTIC_INDICES, order=1).reshape(shape)\n",
    "\n",
    "\n",
    "def prepare_image_for_net(img):\n",
    "    img = img.astype(numpy.float)\n",
    "    img /= 255.\n",
    "    if len(img.shape) == 3:\n",
    "        img = img.reshape(img.shape[-3], img.shape[-2], img.shape[-1])\n",
    "    else:\n",
    "        img = img.reshape(1, img.shape[-2], img.shape[-1], 1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_train_holdout_files(model_type, generated_path, csv_path,holdout, train_percentage=80, frame_count=8):\n",
    "    print(\"Get train/holdout files.\")\n",
    "    file_paths = glob.glob(generated_path + \"*_i.png\")\n",
    "    file_paths.sort()\n",
    "    train_res = []\n",
    "    holdout_res = []\n",
    "    for index, file_path in enumerate(file_paths):\n",
    "        file_name = ntpath.basename(file_path)\n",
    "        overlay_path = file_path.replace(\"_i.png\", \"_o.png\")\n",
    "        train_set = False\n",
    "        if \"1.3.6.1.4\" in file_name or \"spie\" in file_name or \"TIME\" in file_name:\n",
    "            train_set = True\n",
    "        else:\n",
    "            patient_id = file_name.split(\"_\")[0]\n",
    "            if helpers.get_patient_fold(csv_path,patient_id) % 3 != holdout:\n",
    "                train_set = True\n",
    "\n",
    "        if train_set:\n",
    "            train_res.append((file_path, overlay_path))\n",
    "        else:\n",
    "            holdout_res.append((file_path, overlay_path))\n",
    "    print(\"Train count: \", len(train_res), \", holdout count: \", len(holdout_res))\n",
    "    return train_res, holdout_res\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "\n",
    "\n",
    "def dice_coef_np(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = numpy.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (numpy.sum(y_true_f) + numpy.sum(y_pred_f) + 1)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "class DumpPredictions(Callback):\n",
    "\n",
    "    def __init__(self, dump_filelist, model_type):\n",
    "        super(DumpPredictions, self).__init__()\n",
    "        self.dump_filelist = dump_filelist\n",
    "        self.batch_count = 0\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model = self.model  # type: Model\n",
    "        generator = image_generator(self.dump_filelist, 1, train_set=False, model_type=self.model_type)\n",
    "        for i in range(0, 10):\n",
    "            x, y = next(generator)\n",
    "            y_pred = model.predict(x, batch_size=1)\n",
    "\n",
    "            x = x.swapaxes(0, 3)\n",
    "            x = x[0]\n",
    "            # print(x.shape, y.shape, y_pred.shape)\n",
    "            x *= 255.\n",
    "            x = x.reshape((x.shape[0], x.shape[0])).astype(numpy.uint8)\n",
    "            y *= 255.\n",
    "            y = y.reshape((y.shape[1], y.shape[2])).astype(numpy.uint8)\n",
    "            y_pred *= 255.\n",
    "            y_pred = y_pred.reshape((y_pred.shape[1], y_pred.shape[2])).astype(numpy.uint8)\n",
    "            # cv2.imwrite(\"workdir/segmenter/img_{0:03d}_{1:02d}_i.png\".format(epoch, i), x)\n",
    "            # cv2.imwrite(\"workdit/segmenter/img_{0:03d}_{1:02d}_o.png\".format(epoch, i), y)\n",
    "            # cv2.imwrite(\"workdit/segmenter/img_{0:03d}_{1:02d}_p.png\".format(epoch, i), y_pred)\n",
    "\n",
    "\n",
    "def image_generator(batch_files, batch_size, train_set, model_type):\n",
    "    global ELASTIC_INDICES\n",
    "    while True:\n",
    "        if train_set:\n",
    "            random.shuffle(batch_files)\n",
    "\n",
    "        img_list = []\n",
    "        overlay_list = []\n",
    "        ELASTIC_INDICES = None\n",
    "        for batch_file_idx, batch_file in enumerate(batch_files):\n",
    "            images = []\n",
    "            img = cv2.imread(batch_file[0], cv2.IMREAD_GRAYSCALE)\n",
    "            images.append(img)\n",
    "            overlay = cv2.imread(batch_file[1], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if train_set:\n",
    "                if random.randint(0, 100) > 50:\n",
    "                    for img_index, img in enumerate(images):\n",
    "                        images[img_index] = elastic_transform(img, 128, 15)\n",
    "                    overlay = elastic_transform(overlay, 128, 15)\n",
    "\n",
    "                if True:\n",
    "                    augmented = images + [overlay]\n",
    "                    augmented = random_rotate_img(augmented, 0.8, -20, 20)\n",
    "                    augmented = random_flip_img(augmented, 0.5, 0.5)\n",
    "\n",
    "                    # processed = helpers_augmentation.random_flip_img(processed, horizontal_chance=0.5, vertical_chance=0)\n",
    "                    # processed = helpers_augmentation.random_scale_img(processed, xy_range=helpers_augmentation.XYRange(x_min=0.8, x_max=1.2, y_min=0.8, y_max=1.2, chance=1.0))\n",
    "                    augmented = random_translate_img(augmented, XYRange(-30, 30, -30, 30, 0.8))\n",
    "                    images = augmented[:-1]\n",
    "                    overlay = augmented[-1]\n",
    "\n",
    "            for index, img in enumerate(images):\n",
    "                # img = img[crop_y: crop_y + settings.TRAIN_IMG_HEIGHT3D, crop_x: crop_x + settings.TRAIN_IMG_WIDTH3D]\n",
    "                img = prepare_image_for_net(img)\n",
    "                images[index] = img\n",
    "\n",
    "            # helpers_augmentation.dump_augmented_image(img, mean_img=None, target_path=\"c:\\\\tmp\\\\\" + batch_file[0])\n",
    "            # overlay = overlay[crop_y: crop_y + settings.TRAIN_IMG_HEIGHT3D, crop_x: crop_x + settings.TRAIN_IMG_WIDTH3D]\n",
    "            overlay = prepare_image_for_net(overlay)\n",
    "            # overlay = overlay.reshape(1, overlay.shape[-3] * overlay.shape[-2])\n",
    "            # overlay *= settings.OVERLAY_MULTIPLIER\n",
    "            images3d = numpy.vstack(images)\n",
    "            images3d = images3d.swapaxes(0, 3)\n",
    "\n",
    "            img_list.append(images3d)\n",
    "            overlay_list.append(overlay)\n",
    "            if len(img_list) >= batch_size:\n",
    "                x = numpy.vstack(img_list)\n",
    "                y = numpy.vstack(overlay_list)\n",
    "                # if len(img_list) >= batch_size:\n",
    "                yield x, y\n",
    "                img_list = []\n",
    "                overlay_list = []\n",
    "\n",
    "\n",
    "def get_unet(learn_rate, load_weights_path=None):\n",
    "    inputs = Input((SEGMENTER_IMG_SIZE, SEGMENTER_IMG_SIZE, CHANNEL_COUNT))\n",
    "    filter_size = 32\n",
    "    growth_step = 32\n",
    "    x = BatchNormalization()(inputs)\n",
    "    conv1 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    conv1 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    pool1 = BatchNormalization()(pool1)\n",
    "    filter_size += growth_step\n",
    "    conv2 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = BatchNormalization()(pool2)\n",
    "\n",
    "    filter_size += growth_step\n",
    "    conv3 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = BatchNormalization()(pool3)\n",
    "\n",
    "    filter_size += growth_step\n",
    "    conv4 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = BatchNormalization()(pool4)\n",
    "\n",
    "    conv5 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same', name=\"conv5b\")(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2), name=\"pool5\")(conv5)\n",
    "    pool5 = BatchNormalization()(pool5)\n",
    "\n",
    "    conv6 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(pool5)\n",
    "    conv6 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same', name=\"conv6b\")(conv6)\n",
    "\n",
    "    up6 = UpSampling2D(size=(2, 2), name=\"up6\")(conv6)\n",
    "    up6 = merge([up6, conv5], mode='concat', concat_axis=3)\n",
    "    up6 = BatchNormalization()(up6)\n",
    "\n",
    "    # up6 = SpatialDropout2D(0.1)(up6)\n",
    "    filter_size -= growth_step\n",
    "    conv66 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv66 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv66)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv66), conv4], mode='concat', concat_axis=3)\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    # up7 = SpatialDropout2D(0.1)(up7)\n",
    "\n",
    "    filter_size -= growth_step\n",
    "    conv7 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv3], mode='concat', concat_axis=3)\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    filter_size -= growth_step\n",
    "    conv8 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv2], mode='concat', concat_axis=3)\n",
    "    up9 = BatchNormalization()(up9)\n",
    "    conv9 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "    # conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    up10 = UpSampling2D(size=(2, 2))(conv9)\n",
    "    conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(up10)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    # model.load_weights(load_weights_path)\n",
    "    # model.compile(optimizer=Adam(lr=1.0e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    model.compile(optimizer=SGD(lr=learn_rate, momentum=0.9, nesterov=True), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model_paths, model_paths_temp, holdout, model_type, continue_from=None):\n",
    "    batch_size = 4\n",
    "    train_percentage = 80 if model_type == \"masses\" else 90\n",
    "    train_files, holdout_files = get_train_holdout_files( model_type,generated_path, csv_path, holdout, train_percentage, frame_count=CHANNEL_COUNT)\n",
    "    # train_files = train_files[:100]\n",
    "    # holdout_files = train_files[:10]\n",
    "\n",
    "    tmp_gen = image_generator(train_files[:2], 2, True, model_type)\n",
    "    for i in range(10):\n",
    "        x = next(tmp_gen)\n",
    "        img = x[0][0].reshape((SEGMENTER_IMG_SIZE, SEGMENTER_IMG_SIZE))\n",
    "        img *= 255\n",
    "        # cv2.imwrite(\"c:/tmp/img_\" + str(i).rjust(3, '0') + \"i.png\", img)\n",
    "        img = x[1][0].reshape((SEGMENTER_IMG_SIZE, SEGMENTER_IMG_SIZE))\n",
    "        img *= 255\n",
    "        # cv2.imwrite(\"c:/tmp/img_\" + str(i).rjust(3, '0') + \"o.png\", img)\n",
    "        # print(x.shape)\n",
    "\n",
    "    train_gen = image_generator(train_files, batch_size, True, model_type)\n",
    "    holdout_gen = image_generator(holdout_files, batch_size, False, model_type)\n",
    "\n",
    "    if continue_from is None:\n",
    "        model = get_unet(0.001)\n",
    "    else:\n",
    "        model = get_unet(0.0001)\n",
    "        model.load_weights(continue_from)\n",
    "\n",
    "    checkpoint1 = ModelCheckpoint(model_paths_temp +\"_model\" + \"_{epoch:02d}-{val_loss:.2f}.hd5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    checkpoint2 = ModelCheckpoint(model_paths_temp +\"_model\" + \"_best.hd5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    files = []\n",
    "    idx = 0\n",
    "    while (idx < (len(holdout_files))):\n",
    "        files.append(holdout_files[idx])\n",
    "        idx += 5\n",
    "    dumper = DumpPredictions(holdout_files[::10], model_type)\n",
    "    epoch_div = 1\n",
    "    epoch_count = 50 \n",
    "    model.fit_generator(train_gen, len(train_files) / epoch_div, epoch_count, validation_data=holdout_gen, nb_val_samples=len(holdout_files) / epoch_div, callbacks=[checkpoint1, checkpoint2, dumper])\n",
    "    shutil.copy(model_paths_temp +\"_model\" + \"_best.hd5\", model_paths +\"_model\" + \"_best.hd5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path = PATH['annotations_train']\n",
    "generated_path = PATH['pic_train']\n",
    "model_paths = PATH['model_paths']\n",
    "model_paths_temp = PATH['model_paths_temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train/holdout files.\n",
      "('Train count: ', 1965, ', holdout count: ', 948)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_1/MaxPool' (op: 'MaxPool') with input shapes: [?,512,1,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-64c7d959c729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     train_model(model_paths, model_paths_temp, holdout=0, \n\u001b[0;32m----> 8\u001b[0;31m             model_type=\"masses\", continue_from=None)  \n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-af43b3a39383>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_paths, model_paths_temp, holdout, model_type, continue_from)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontinue_from\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-af43b3a39383>\u001b[0m in \u001b[0;36mget_unet\u001b[0;34m(learn_rate, load_weights_path)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    215\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[1;32m    216\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                           pool_mode='max')\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   3010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3012\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3013\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1819\u001b[0m                                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m                                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   1822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36m_max_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1636\u001b[0m   result = _op_def_lib.apply_op(\"MaxPool\", input=input, ksize=ksize,\n\u001b[1;32m   1637\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   1639\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    766\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    767\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2336\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1717\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_1/MaxPool' (op: 'MaxPool') with input shapes: [?,512,1,32]."
     ]
    }
   ],
   "source": [
    "continue_from_model = False\n",
    "\n",
    "if continue_from_model:\n",
    "    train_model(model_paths, model_paths_temp, holdout=0, \n",
    "            model_type=\"masses\", continue_from=model_paths+'model_best.hd5')     \n",
    "else:\n",
    "    train_model(model_paths, model_paths_temp, holdout=0, \n",
    "            model_type=\"masses\", continue_from=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
