{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_net(input_shape, load_weight_path=None, features=False, mal=False):\n",
    "    width = 64\n",
    "    inputs = Input(shape=(1, 32, 32, 32), name=\"input_1\")\n",
    "    x = inputs\n",
    "    x = AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode=\"same\")(x)\n",
    "    x = Convolution3D(width, 3, 3, 3, activation='relu', border_mode='same', name='conv1', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1')(x)\n",
    "\n",
    "    # 2nd layer group\n",
    "    x = Convolution3D(width*2, 3, 3, 3, activation='relu', border_mode='same', name='conv2', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2')(x)\n",
    "    x = Dropout(p=0.3)(x)\n",
    "\n",
    "    # 3rd layer group\n",
    "    x = Convolution3D(width*4, 3, 3, 3, activation='relu', border_mode='same', name='conv3a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(width*4, 3, 3, 3, activation='relu', border_mode='same', name='conv3b', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3')(x)\n",
    "    x = Dropout(p=0.4)(x)\n",
    "\n",
    "    # 4th layer group\n",
    "    x = Convolution3D(width*8, 3, 3, 3, activation='relu', border_mode='same', name='conv4a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(width*8, 3, 3, 3, activation='relu', border_mode='same', name='conv4b', subsample=(1, 1, 1),)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4')(x)\n",
    "    x = Dropout(p=0.5)(x)\n",
    "       \n",
    "    last64 = Convolution3D(64, 2, 2, 2, activation=\"relu\", name=\"last_64\")(x)\n",
    "    out_class = Convolution3D(1, 1, 1, 1, activation=\"softmax\", name=\"out_class_last\")(last64)\n",
    "    out_class = Flatten(name=\"out_class\")(x)\n",
    "    \n",
    "    out_class = Dense(2)(out_class) \n",
    "    out_class = Activation('softmax')(out_class)\n",
    "    \n",
    "    model = Model(input=inputs, output=out_class)\n",
    "    model.compile(optimizer=SGD(lr=1e-3, momentum=0.9, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = PATH['cls_train_cube_30']\n",
    "output_true = PATH['cls_train_cube_30_true']\n",
    "output_false = PATH['cls_train_cube_30_false']\n",
    "model_paths = PATH['model_paths']\n",
    "model_final = PATH['model_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dirfiles(dir):\n",
    "    file_list = []\n",
    "    subset_path = os.listdir(dir)\n",
    "    for _ in range(len(subset_path)):\n",
    "        if subset_path[_] != '.DS_Store':\n",
    "            file_list.append(dir + subset_path[_])\n",
    "    return file_list\n",
    "\n",
    "def train_generator(output_true,output_false):\n",
    "    train_nb = 21000    \n",
    "    file_list_true = get_dirfiles(output_true)\n",
    "    file_list_false = get_dirfiles(output_false)        \n",
    "    file_list_true = np.random.choice(file_list_true, train_nb)\n",
    "    file_list_false = np.random.choice(file_list_false, train_nb)    \n",
    "    nb_true = len(file_list_true) + len(file_list_false)    \n",
    "    sample = np.zeros([nb_true,32, 32, 32])\n",
    "    labels = np.zeros([nb_true,2])\n",
    "    for i in tqdm(range(len(file_list_true))):       \n",
    "        cc= np.load(file_list_true[i])\n",
    "        sample[i] = cc\n",
    "        labels[i] = [0.,1.]\n",
    "    for j in tqdm(range(len(file_list_false))):\n",
    "        bb= np.load(file_list_false[j])\n",
    "        sample[j+len(file_list_true)] = bb \n",
    "        labels[j+len(file_list_true)] = [1.,0.]\n",
    "    sample = np.expand_dims(sample, axis=1)        \n",
    "    return sample,labels\n",
    "\n",
    "\n",
    "def fenlei_fit(name, load_check = False,batch_size=2, epochs=100,check_name = None):\n",
    "    t = time.time()\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience = 8, verbose = 1),\n",
    "                 ModelCheckpoint((model_paths + '{}.h5').format(name),\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose = 0,\n",
    "                                 save_best_only = True)]\n",
    "    if load_check:\n",
    "        check_model = (model_paths + '{}.h5').format(check_name)\n",
    "        model = load_model(check_model)\n",
    "    else:\n",
    "        #model = classifier((1, 32, 32, 32),128,(3, 3, 3), (2, 2, 2))\n",
    "        model = get_net((1, 32, 32, 32))\n",
    "    x,y = train_generator(output_true,output_false)\n",
    "    model.fit(x,y, batch_size=batch_size, epochs=epochs,\n",
    "              validation_split=0.2,verbose=1, callbacks=callbacks, shuffle=True) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21000/21000 [03:42<00:00, 94.21it/s] \n",
      "100%|██████████| 21000/21000 [05:20<00:00, 65.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/200\n",
      "33600/33600 [==============================] - 669s - loss: 0.5832 - acc: 0.6899 - val_loss: 0.5168 - val_acc: 0.8102\n",
      "Epoch 2/200\n",
      "33600/33600 [==============================] - 619s - loss: 0.3499 - acc: 0.8445 - val_loss: 0.1978 - val_acc: 0.9502\n",
      "Epoch 3/200\n",
      "33600/33600 [==============================] - 615s - loss: 0.2070 - acc: 0.9167 - val_loss: 0.1518 - val_acc: 0.9615\n",
      "Epoch 4/200\n",
      "33600/33600 [==============================] - 620s - loss: 0.1390 - acc: 0.9469 - val_loss: 0.1308 - val_acc: 0.9631\n",
      "Epoch 5/200\n",
      "33600/33600 [==============================] - 694s - loss: 0.1031 - acc: 0.9626 - val_loss: 0.0913 - val_acc: 0.9786\n",
      "Epoch 6/200\n",
      "33600/33600 [==============================] - 665s - loss: 0.0777 - acc: 0.9720 - val_loss: 0.1060 - val_acc: 0.9663\n",
      "Epoch 7/200\n",
      "33600/33600 [==============================] - 664s - loss: 0.0614 - acc: 0.9781 - val_loss: 0.0848 - val_acc: 0.9789\n",
      "Epoch 8/200\n",
      "33600/33600 [==============================] - 663s - loss: 0.0469 - acc: 0.9843 - val_loss: 0.0650 - val_acc: 0.9808\n",
      "Epoch 9/200\n",
      "33600/33600 [==============================] - 645s - loss: 0.0393 - acc: 0.9865 - val_loss: 0.0443 - val_acc: 0.9858\n",
      "Epoch 10/200\n",
      "33600/33600 [==============================] - 604s - loss: 0.0339 - acc: 0.9878 - val_loss: 0.0793 - val_acc: 0.9786\n",
      "Epoch 11/200\n",
      "33600/33600 [==============================] - 589s - loss: 0.0260 - acc: 0.9912 - val_loss: 0.0504 - val_acc: 0.9869\n",
      "Epoch 12/200\n",
      "33600/33600 [==============================] - 589s - loss: 0.0227 - acc: 0.9920 - val_loss: 0.0700 - val_acc: 0.9819\n",
      "Epoch 13/200\n",
      "33600/33600 [==============================] - 581s - loss: 0.0173 - acc: 0.9938 - val_loss: 0.0771 - val_acc: 0.9812\n",
      "Epoch 14/200\n",
      "33592/33600 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9932"
     ]
    }
   ],
   "source": [
    "fenlei_fit('Fenge_32_32_32_0629_2', load_check = True, batch_size=8, epochs=200, check_name = 'Fenge_32_32_32_0629')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list_true = get_dirfiles(output_true)\n",
    "file_list_false = get_dirfiles(output_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_pred = classifier((1, 36, 36, 36), (3, 3, 3), (2, 2, 2))\n",
    "model_pred = load_model(model_paths + 'Fenge_32_32_32_0626.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = []\n",
    "for i in file_list_false[0:200]:\n",
    "    a=np.load(i)\n",
    "    a=np.expand_dims(a,0)\n",
    "    a=np.expand_dims(a,0)\n",
    "    cc.append(model_pred.predict(a))\n",
    "count = 0\n",
    "for i in cc:\n",
    "    if i[0][0] > 0.9:\n",
    "        count += 1\n",
    "print count*1.0/len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = []\n",
    "for i in file_list_true[0:200]:\n",
    "    a=np.load(i)\n",
    "    a=np.expand_dims(a,0)\n",
    "    a=np.expand_dims(a,0)\n",
    "    cc.append(model_pred.predict(a))\n",
    "count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cc:\n",
    "    if i[0][1] > 0.9:\n",
    "        count += 1\n",
    "print count*1.0/len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_list_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
