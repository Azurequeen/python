{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.imports import *\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))\n",
    "K.set_image_dim_ordering(\"tf\")\n",
    "CUBE_SIZE = 32\n",
    "MEAN_PIXEL_VALUE = MEAN_PIXEL_VALUE_NODULE\n",
    "POS_WEIGHT = 2\n",
    "NEGS_PER_POS = 20\n",
    "P_TH = 0.6\n",
    "# POS_IMG_DIR = \"luna16_train_cubes_pos\"\n",
    "LEARN_RATE = 0.001\n",
    "PREDICT_STEP = 12\n",
    "USE_DROPOUT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'settings' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-90388f0ce99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmagnification\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mpredict_cubes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/model_luna16_full__fs_best.hd5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONTINUE_JOB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_patient_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_patient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmagnification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholdout_no\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"luna16_fs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mpredict_cubes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/model_luna16_full__fs_best.hd5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONTINUE_JOB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_patient_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_patient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmagnification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholdout_no\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"luna16_fs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-90388f0ce99f>\u001b[0m in \u001b[0;36mpredict_cubes\u001b[0;34m(model_path, continue_job, only_patient_id, luna16, magnification, flip, train_data, holdout_no, ext_name, fold_count)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mdst_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLUNA_NODULE_DETECTION_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mdst_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDSB3_NODULE_DETECTION_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'settings' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def prepare_image_for_net3D(img):\n",
    "    img = img.astype(numpy.float32)\n",
    "    img -= MEAN_PIXEL_VALUE\n",
    "    img /= 255.\n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2], 1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def filter_patient_nodules_predictions(pic_path, df_nodule_predictions: pandas.DataFrame, patient_id, view_size, luna16=False):\n",
    "    src_dir = pic_path\n",
    "    patient_mask = helpers.load_patient_images(patient_id, src_dir, \"*_m.png\")\n",
    "    delete_indices = []\n",
    "    for index, row in df_nodule_predictions.iterrows():\n",
    "        z_perc = row[\"coord_z\"]\n",
    "        y_perc = row[\"coord_y\"]\n",
    "        center_x = int(round(row[\"coord_x\"] * patient_mask.shape[2]))\n",
    "        center_y = int(round(y_perc * patient_mask.shape[1]))\n",
    "        center_z = int(round(z_perc * patient_mask.shape[0]))\n",
    "\n",
    "        mal_score = row[\"diameter_mm\"]\n",
    "        start_y = center_y - view_size / 2\n",
    "        start_x = center_x - view_size / 2\n",
    "        nodule_in_mask = False\n",
    "        for z_index in [-1, 0, 1]:\n",
    "            img = patient_mask[z_index + center_z]\n",
    "            start_x = int(start_x)\n",
    "            start_y = int(start_y)\n",
    "            view_size = int(view_size)\n",
    "            img_roi = img[start_y:start_y+view_size, start_x:start_x + view_size]\n",
    "            if img_roi.sum() > 255:  # more than 1 pixel of mask.\n",
    "                nodule_in_mask = True\n",
    "\n",
    "        if not nodule_in_mask:\n",
    "            print(\"Nodule not in mask: \", (center_x, center_y, center_z))\n",
    "            if mal_score > 0:\n",
    "                mal_score *= -1\n",
    "            df_nodule_predictions.loc[index, \"diameter_mm\"] = mal_score\n",
    "        else:\n",
    "            if center_z < 30:\n",
    "                print(\"Z < 30: \", patient_id, \" center z:\", center_z, \" y_perc: \",  y_perc)\n",
    "                if mal_score > 0:\n",
    "                    mal_score *= -1\n",
    "                df_nodule_predictions.loc[index, \"diameter_mm\"] = mal_score\n",
    "\n",
    "\n",
    "            if (z_perc > 0.75 or z_perc < 0.25) and y_perc > 0.85:\n",
    "                print(\"SUSPICIOUS FALSEPOSITIVE: \", patient_id, \" center z:\", center_z, \" y_perc: \",  y_perc)\n",
    "\n",
    "            if center_z < 50 and y_perc < 0.30:\n",
    "                print(\"SUSPICIOUS FALSEPOSITIVE OUT OF RANGE: \", patient_id, \" center z:\", center_z, \" y_perc: \",  y_perc)\n",
    "\n",
    "    df_nodule_predictions.drop(df_nodule_predictions.index[delete_indices], inplace=True)\n",
    "    return df_nodule_predictions\n",
    "\n",
    "\n",
    "def filter_nodule_predictions(only_patient_id=None):\n",
    "    src_dir = settings.NDSB3_NODULE_DETECTION_DIR\n",
    "    for csv_index, csv_path in enumerate(glob.glob(src_dir + \"*.csv\")):\n",
    "        file_name = ntpath.basename(csv_path)\n",
    "        patient_id = file_name.replace(\".csv\", \"\")\n",
    "        print(csv_index, \": \", patient_id)\n",
    "        if only_patient_id is not None and patient_id != only_patient_id:\n",
    "            continue\n",
    "        df_nodule_predictions = pandas.read_csv(csv_path)\n",
    "        filter_patient_nodules_predictions(df_nodule_predictions, patient_id, CUBE_SIZE)\n",
    "        df_nodule_predictions.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "def make_negative_train_data_based_on_predicted_luna_nodules():\n",
    "    src_dir = settings.LUNA_NODULE_DETECTION_DIR\n",
    "    pos_labels_dir = settings.LUNA_NODULE_LABELS_DIR\n",
    "    keep_dist = CUBE_SIZE + CUBE_SIZE / 2\n",
    "    total_false_pos = 0\n",
    "    for csv_index, csv_path in enumerate(glob.glob(src_dir + \"*.csv\")):\n",
    "        file_name = ntpath.basename(csv_path)\n",
    "        patient_id = file_name.replace(\".csv\", \"\")\n",
    "        # if not \"273525289046256012743471155680\" in patient_id:\n",
    "        #     continue\n",
    "        df_nodule_predictions = pandas.read_csv(csv_path)\n",
    "        pos_annos_manual = None\n",
    "        manual_path = settings.MANUAL_ANNOTATIONS_LABELS_DIR + patient_id + \".csv\"\n",
    "        if os.path.exists(manual_path):\n",
    "            pos_annos_manual = pandas.read_csv(manual_path)\n",
    "\n",
    "        filter_patient_nodules_predictions(df_nodule_predictions, patient_id, CUBE_SIZE, luna16=True)\n",
    "        pos_labels = pandas.read_csv(pos_labels_dir + patient_id + \"_annos_pos_lidc.csv\")\n",
    "        print(csv_index, \": \", patient_id, \", pos\", len(pos_labels))\n",
    "        patient_imgs = helpers.load_patient_images(patient_id, settings.LUNA_16_TRAIN_DIR2D2, \"*_m.png\")\n",
    "        for nod_pred_index, nod_pred_row in df_nodule_predictions.iterrows():\n",
    "            if nod_pred_row[\"diameter_mm\"] < 0:\n",
    "                continue\n",
    "            nx, ny, nz = helpers.percentage_to_pixels(nod_pred_row[\"coord_x\"], nod_pred_row[\"coord_y\"], nod_pred_row[\"coord_z\"], patient_imgs)\n",
    "            diam_mm = nod_pred_row[\"diameter_mm\"]\n",
    "            for label_index, label_row in pos_labels.iterrows():\n",
    "                px, py, pz = helpers.percentage_to_pixels(label_row[\"coord_x\"], label_row[\"coord_y\"], label_row[\"coord_z\"], patient_imgs)\n",
    "                dist = math.sqrt(math.pow(nx - px, 2) + math.pow(ny - py, 2) + math.pow(nz- pz, 2))\n",
    "                if dist < keep_dist:\n",
    "                    if diam_mm >= 0:\n",
    "                        diam_mm *= -1\n",
    "                    df_nodule_predictions.loc[nod_pred_index, \"diameter_mm\"] = diam_mm\n",
    "                    break\n",
    "\n",
    "            if pos_annos_manual is not None:\n",
    "                for index, label_row in pos_annos_manual.iterrows():\n",
    "                    px, py, pz = helpers.percentage_to_pixels(label_row[\"x\"], label_row[\"y\"], label_row[\"z\"], patient_imgs)\n",
    "                    diameter = label_row[\"d\"] * patient_imgs[0].shape[1]\n",
    "                    # print((pos_coord_x, pos_coord_y, pos_coord_z))\n",
    "                    # print(center_float_rescaled)\n",
    "                    dist = math.sqrt(math.pow(px - nx, 2) + math.pow(py - ny, 2) + math.pow(pz - nz, 2))\n",
    "                    if dist < (diameter + 72):  #  make sure we have a big margin\n",
    "                        if diam_mm >= 0:\n",
    "                            diam_mm *= -1\n",
    "                        df_nodule_predictions.loc[nod_pred_index, \"diameter_mm\"] = diam_mm\n",
    "                        print(\"#Too close\",  (nx, ny, nz))\n",
    "                        break\n",
    "\n",
    "        df_nodule_predictions.to_csv(csv_path, index=False)\n",
    "        df_nodule_predictions = df_nodule_predictions[df_nodule_predictions[\"diameter_mm\"] >= 0]\n",
    "        df_nodule_predictions.to_csv(pos_labels_dir + patient_id + \"_candidates_falsepos.csv\", index=False)\n",
    "        total_false_pos += len(df_nodule_predictions)\n",
    "    print(\"Total false pos:\", total_false_pos)\n",
    "\n",
    "\n",
    "def predict_cubes(model_path, continue_job, only_patient_id=None, luna16=False, magnification=1, flip=False, train_data=True, holdout_no=-1, ext_name=\"\", fold_count=2):\n",
    "\n",
    "    dst_dir = settings.LUNA_NODULE_DETECTION_DIR\n",
    "\n",
    "\n",
    "\n",
    "    holdout_ext = \"\"\n",
    "    # if holdout_no is not None:\n",
    "    #     holdout_ext = \"_h\" + str(holdout_no) if holdout_no >= 0 else \"\"\n",
    "    flip_ext = \"\"\n",
    "    if flip:\n",
    "        flip_ext = \"_flip\"\n",
    "\n",
    "    dst_dir += \"predictions\" + str(int(magnification * 10)) + holdout_ext + flip_ext + \"_\" + ext_name + \"/\"\n",
    "\n",
    "    sw = helpers.Stopwatch.start_new()\n",
    "    model = step2_train_nodule_detector.get_net(input_shape=(CUBE_SIZE, CUBE_SIZE, CUBE_SIZE, 1), load_weight_path=model_path)\n",
    "    if not luna16:\n",
    "        if train_data:\n",
    "            labels_df = pandas.read_csv(\"resources/stage1_labels.csv\")\n",
    "            labels_df.set_index([\"id\"], inplace=True)\n",
    "        else:\n",
    "            labels_df = pandas.read_csv(\"resources/stage2_sample_submission.csv\")\n",
    "            labels_df.set_index([\"id\"], inplace=True)\n",
    "\n",
    "    patient_ids = []\n",
    "    for file_name in os.listdir(settings.NDSB3_EXTRACTED_IMAGE_DIR):\n",
    "        if not os.path.isdir(settings.NDSB3_EXTRACTED_IMAGE_DIR + file_name):\n",
    "            continue\n",
    "        patient_ids.append(file_name)\n",
    "\n",
    "    all_predictions_csv = []\n",
    "    for patient_index, patient_id in enumerate(reversed(patient_ids)):\n",
    "        if not luna16:\n",
    "            if patient_id not in labels_df.index:\n",
    "                continue\n",
    "        if \"metadata\" in patient_id:\n",
    "            continue\n",
    "        if only_patient_id is not None and only_patient_id != patient_id:\n",
    "            continue\n",
    "\n",
    "        if holdout_no is not None and train_data:\n",
    "            patient_fold = helpers.get_patient_fold(patient_id)\n",
    "            patient_fold %= fold_count\n",
    "            if patient_fold != holdout_no:\n",
    "                continue\n",
    "\n",
    "        print(patient_index, \": \", patient_id)\n",
    "        csv_target_path = dst_dir + patient_id + \".csv\"\n",
    "        if continue_job and only_patient_id is None:\n",
    "            if os.path.exists(csv_target_path):\n",
    "                continue\n",
    "\n",
    "        patient_img = helpers.load_patient_images(patient_id, settings.NDSB3_EXTRACTED_IMAGE_DIR, \"*_i.png\", [])\n",
    "        if magnification != 1:\n",
    "            patient_img = helpers.rescale_patient_images(patient_img, (1, 1, 1), magnification)\n",
    "\n",
    "        patient_mask = helpers.load_patient_images(patient_id, settings.NDSB3_EXTRACTED_IMAGE_DIR, \"*_m.png\", [])\n",
    "        if magnification != 1:\n",
    "            patient_mask = helpers.rescale_patient_images(patient_mask, (1, 1, 1), magnification, is_mask_image=True)\n",
    "\n",
    "            # patient_img = patient_img[:, ::-1, :]\n",
    "            # patient_mask = patient_mask[:, ::-1, :]\n",
    "\n",
    "        step = PREDICT_STEP\n",
    "        CROP_SIZE = CUBE_SIZE\n",
    "        # CROP_SIZE = 48\n",
    "\n",
    "        predict_volume_shape_list = [0, 0, 0]\n",
    "        for dim in range(3):\n",
    "            dim_indent = 0\n",
    "            while dim_indent + CROP_SIZE < patient_img.shape[dim]:\n",
    "                predict_volume_shape_list[dim] += 1\n",
    "                dim_indent += step\n",
    "\n",
    "        predict_volume_shape = (predict_volume_shape_list[0], predict_volume_shape_list[1], predict_volume_shape_list[2])\n",
    "        predict_volume = numpy.zeros(shape=predict_volume_shape, dtype=float)\n",
    "        print(\"Predict volume shape: \", predict_volume.shape)\n",
    "        done_count = 0\n",
    "        skipped_count = 0\n",
    "        batch_size = 128\n",
    "        batch_list = []\n",
    "        batch_list_coords = []\n",
    "        patient_predictions_csv = []\n",
    "        cube_img = None\n",
    "        annotation_index = 0\n",
    "\n",
    "        for z in range(0, predict_volume_shape[0]):\n",
    "            for y in range(0, predict_volume_shape[1]):\n",
    "                for x in range(0, predict_volume_shape[2]):\n",
    "                    #if cube_img is None:\n",
    "                    cube_img = patient_img[z * step:z * step+CROP_SIZE, y * step:y * step + CROP_SIZE, x * step:x * step+CROP_SIZE]\n",
    "                    cube_mask = patient_mask[z * step:z * step+CROP_SIZE, y * step:y * step + CROP_SIZE, x * step:x * step+CROP_SIZE]\n",
    "\n",
    "                    if cube_mask.sum() < 2000:\n",
    "                        skipped_count += 1\n",
    "                    else:\n",
    "                        if flip:\n",
    "                            cube_img = cube_img[:, :, ::-1]\n",
    "\n",
    "                        if CROP_SIZE != CUBE_SIZE:\n",
    "                            cube_img = helpers.rescale_patient_images2(cube_img, (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE))\n",
    "                            # helpers.save_cube_img(\"c:/tmp/cube.png\", cube_img, 8, 4)\n",
    "                            # cube_mask = helpers.rescale_patient_images2(cube_mask, (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE))\n",
    "\n",
    "                        img_prep = prepare_image_for_net3D(cube_img)\n",
    "                        batch_list.append(img_prep)\n",
    "                        batch_list_coords.append((z, y, x))\n",
    "                        if len(batch_list) % batch_size == 0:\n",
    "                            batch_data = numpy.vstack(batch_list)\n",
    "                            p = model.predict(batch_data, batch_size=batch_size)\n",
    "                            for i in range(len(p[0])):\n",
    "                                p_z = batch_list_coords[i][0]\n",
    "                                p_y = batch_list_coords[i][1]\n",
    "                                p_x = batch_list_coords[i][2]\n",
    "                                nodule_chance = p[0][i][0]\n",
    "                                predict_volume[p_z, p_y, p_x] = nodule_chance\n",
    "                                if nodule_chance > P_TH:\n",
    "                                    p_z = p_z * step + CROP_SIZE / 2\n",
    "                                    p_y = p_y * step + CROP_SIZE / 2\n",
    "                                    p_x = p_x * step + CROP_SIZE / 2\n",
    "\n",
    "                                    p_z_perc = round(p_z / patient_img.shape[0], 4)\n",
    "                                    p_y_perc = round(p_y / patient_img.shape[1], 4)\n",
    "                                    p_x_perc = round(p_x / patient_img.shape[2], 4)\n",
    "                                    diameter_mm = round(p[1][i][0], 4)\n",
    "                                    # diameter_perc = round(2 * step / patient_img.shape[2], 4)\n",
    "                                    diameter_perc = round(2 * step / patient_img.shape[2], 4)\n",
    "                                    diameter_perc = round(diameter_mm / patient_img.shape[2], 4)\n",
    "                                    nodule_chance = round(nodule_chance, 4)\n",
    "                                    patient_predictions_csv_line = [annotation_index, p_x_perc, p_y_perc, p_z_perc, diameter_perc, nodule_chance, diameter_mm]\n",
    "                                    patient_predictions_csv.append(patient_predictions_csv_line)\n",
    "                                    all_predictions_csv.append([patient_id] + patient_predictions_csv_line)\n",
    "                                    annotation_index += 1\n",
    "\n",
    "                            batch_list = []\n",
    "                            batch_list_coords = []\n",
    "                    done_count += 1\n",
    "                    if done_count % 10000 == 0:\n",
    "                        print(\"Done: \", done_count, \" skipped:\", skipped_count)\n",
    "\n",
    "        df = pandas.DataFrame(patient_predictions_csv, columns=[\"anno_index\", \"coord_x\", \"coord_y\", \"coord_z\", \"diameter\", \"nodule_chance\", \"diameter_mm\"])\n",
    "        filter_patient_nodules_predictions(df, patient_id, CROP_SIZE * magnification)\n",
    "        df.to_csv(csv_target_path, index=False)\n",
    "\n",
    "        # cols = [\"anno_index\", \"nodule_chance\", \"diamete_mm\"] + [\"f\" + str(i) for i in range(64)]\n",
    "        # df_features = pandas.DataFrame(patient_features_csv, columns=cols)\n",
    "        # for index, row in df.iterrows():\n",
    "        #     if row[\"diameter_mm\"] < 0:\n",
    "        #         print(\"Dropping\")\n",
    "        #         anno_index = row[\"anno_index\"]\n",
    "        #         df_features.drop(df_features[df_features[\"anno_index\"] == anno_index].index, inplace=True)\n",
    "        #\n",
    "        # df_features.to_csv(csv_target_path_features, index=False)\n",
    "\n",
    "        # df = pandas.DataFrame(all_predictions_csv, columns=[\"patient_id\", \"anno_index\", \"coord_x\", \"coord_y\", \"coord_z\", \"diameter\", \"nodule_chance\", \"diameter_mm\"])\n",
    "        # df.to_csv(\"c:/tmp/tmp2.csv\", index=False)\n",
    "\n",
    "        print(predict_volume.mean())\n",
    "        print(\"Done in : \", sw.get_elapsed_seconds(), \" seconds\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    CONTINUE_JOB = True\n",
    "    only_patient_id = None  # \"ebd601d40a18634b100c92e7db39f585\"\n",
    "\n",
    "    if not CONTINUE_JOB or only_patient_id is not None:\n",
    "        for file_path in glob.glob(\"c:/tmp/*.*\"):\n",
    "            if not os.path.isdir(file_path):\n",
    "                remove_file = True\n",
    "                if only_patient_id is not None:\n",
    "                    if only_patient_id not in file_path:\n",
    "                        remove_file = False\n",
    "                        remove_file = False\n",
    "\n",
    "                if remove_file:\n",
    "                    os.remove(file_path)\n",
    "\n",
    "    if True:\n",
    "        for magnification in [1, 1.5, 2]:  #\n",
    "            predict_cubes(\"models/model_luna16_full__fs_best.hd5\", CONTINUE_JOB, only_patient_id=only_patient_id, magnification=magnification, flip=False, train_data=True, holdout_no=None, ext_name=\"luna16_fs\")\n",
    "            predict_cubes(\"models/model_luna16_full__fs_best.hd5\", CONTINUE_JOB, only_patient_id=only_patient_id, magnification=magnification, flip=False, train_data=False, holdout_no=None, ext_name=\"luna16_fs\")\n",
    "\n",
    "    if True:\n",
    "        for version in [2, 1]:\n",
    "            for holdout in [0, 1]:\n",
    "                for magnification in [1, 1.5, 2]:  #\n",
    "                    predict_cubes(\"models/model_luna_posnegndsb_v\" + str(version) + \"__fs_h\" + str(holdout) + \"_end.hd5\", CONTINUE_JOB, only_patient_id=only_patient_id, magnification=magnification, flip=False, train_data=True, holdout_no=holdout, ext_name=\"luna_posnegndsb_v\" + str(version), fold_count=2)\n",
    "                    if holdout == 0:\n",
    "                        predict_cubes(\"models/model_luna_posnegndsb_v\" + str(version) + \"__fs_h\" + str(holdout) + \"_end.hd5\", CONTINUE_JOB, only_patient_id=only_patient_id, magnification=magnification, flip=False, train_data=False, holdout_no=holdout, ext_name=\"luna_posnegndsb_v\" + str(version), fold_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pic_path = PATH['pic_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path = PATH['annotations_train']\n",
    "generated_path = PATH['generated_train']\n",
    "model_paths = PATH['model_paths']\n",
    "model_paths_temp = PATH['model_paths_temp']\n",
    "pred_path = PATH['pic_test']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}