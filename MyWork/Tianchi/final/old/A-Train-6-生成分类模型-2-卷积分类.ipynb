{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_20():    \n",
    "    learning_rate = 5e-5\n",
    "    #optimizer = SGD(lr=learning_rate, momentum = 0.9, decay = 1e-3, nesterov = True)\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    inputs = Input(shape=(1, 20, 20, 6))\n",
    "    \n",
    "    conv1 = Convolution3D(64, 5, 5, 3, activation = 'relu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 1, 1, 1, activation = 'relu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 5, 5, 3, activation = 'relu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 5, 5, 1, activation = 'relu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)    \n",
    "    \n",
    "    output = Flatten(name='flatten')(conv1)\n",
    "    output = Dense(150)(output)\n",
    "    output = PReLU()(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Dense(2, activation='softmax', name = 'predictions')(output)\n",
    "    model3d = Model(inputs, output)\n",
    "    model3d.compile(loss='binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model3d\n",
    "\n",
    "def model_30():    \n",
    "    learning_rate = 5e-5\n",
    "    #optimizer = SGD(lr=learning_rate, momentum = 0.9, decay = 1e-3, nesterov = True)\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    inputs = Input(shape=(1, 30, 30, 10))\n",
    "    \n",
    "    conv1 = Convolution3D(64, 5, 5, 3, activation = 'relu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 2, 2, 1, activation = 'relu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 5, 5, 3, activation = 'relu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 5, 5, 3, activation = 'relu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)    \n",
    "    \n",
    "    output = Flatten(name='flatten')(conv1)\n",
    "    output = Dense(250)(output)\n",
    "    output = PReLU()(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Dense(2, activation='softmax', name = 'predictions')(output)\n",
    "    model3d = Model(inputs, output)\n",
    "    model3d.compile(loss='binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model3d\n",
    "\n",
    "def model_40():    \n",
    "    learning_rate = 5e-5\n",
    "    #optimizer = SGD(lr=learning_rate, momentum = 0.9, decay = 1e-3, nesterov = True)\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    \n",
    "    inputs = Input(shape=(1, 40, 40, 26))\n",
    "    \n",
    "    conv1 = Convolution3D(64, 5, 5, 3, activation = 'relu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 2, 2, 2, activation = 'relu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 5, 5, 3, activation = 'relu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 5, 5, 3, activation = 'relu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)    \n",
    "    \n",
    "    output = Flatten(name='flatten')(conv1)\n",
    "    output = Dense(250)(output)\n",
    "    output = PReLU()(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Dense(2, activation='softmax', name = 'predictions')(output)\n",
    "    model3d = Model(inputs, output)\n",
    "    model3d.compile(loss='binary_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: \n",
    "- 1) Data augmentation - translated by 1 voxel along each axis and rotated 90, 180 and 270 degrees with the transverse plane. In total, 0.65 million samples generated for training. \n",
    "- 2) Normalization - clipped the intensities into the interval (-1000,400) HU and normalized them to the range of (0,1).\n",
    "\n",
    "### 3D CNN architecture details: \n",
    "- Learning from Scratch, lr=0.3 and decayed by 5% every 5000 iterations. batchsize=200, momentum=0.9, and the dropout rate=0.2 stragety is utilized in C and FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_path = PATH['cls_train_true']\n",
    "false_path = PATH['cls_train_false']\n",
    "model_paths = PATH['model_paths']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_generator(size):\n",
    "    file_list_true = sorted(glob.glob(true_path + \"*_3d_20_6_i.npy\"))\n",
    "    file_list_false = sorted(glob.glob(false_path + \"*_3d_20_6_i.npy\"))\n",
    "    nb_true = len(file_list_true) + len(file_list_false)\n",
    "    sample = np.zeros([nb_true,size[0],size[1],size[2]])\n",
    "    labels = np.zeros([nb_true,2])\n",
    "    for i in tqdm(range(len(file_list_true))):\n",
    "        cc= np.load(file_list_true[i]).reshape([1,size[0],size[1],size[2]])\n",
    "        sample[i] = cc[0]\n",
    "        labels[i][0] = 1\n",
    "    for j in tqdm(range(len(file_list_false))):\n",
    "        bb= np.load(file_list_true[i]).reshape([1,size[0],size[1],size[2]])\n",
    "        sample[j+len(file_list_true)] = bb[0]\n",
    "        labels[j+len(file_list_true)][1] = 1    \n",
    "    sample = np.expand_dims(sample, axis=1)        \n",
    "    return sample,labels\n",
    "\n",
    "\n",
    "def fenlei_fit(name, size, check_name = None):\n",
    "    \n",
    "    t = time.time()\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience = 15, \n",
    "                                   verbose = 1),\n",
    "    ModelCheckpoint(model_paths + '{}.h5'.format(name), \n",
    "                        monitor='val_loss', \n",
    "                        verbose = 0, save_best_only = True)]\n",
    "    \n",
    "    if check_name is not None:\n",
    "        check_model = model_paths + '{}.h5'.format(check_name)\n",
    "        model = load_model(check_model, \n",
    "                           custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})\n",
    "    else:\n",
    "        model = model_20()\n",
    "\n",
    "    model.fit_generator(train_generator(size), nb_epoch = 150, verbose = 1, \n",
    "                        callbacks = callbacks,\n",
    "                        samples_per_epoch = 551, nb_val_samples = 50)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:06<00:00, 162.09it/s]\n",
      "100%|██████████| 44541/44541 [00:08<00:00, 5308.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mahui/anaconda/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/mahui/anaconda/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/Users/mahui/anaconda/lib/python2.7/site-packages/keras/engine/training.py\", line 612, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "TypeError: tuple object is not an iterator\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`. Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0f254efe5412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfenlei_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_fenlei'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-62e1688ee434>\u001b[0m in \u001b[0;36mfenlei_fit\u001b[0;34m(name, size, check_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m     model.fit_generator(train_generator(size), nb_epoch = 150, verbose = 1, \n\u001b[1;32m     36\u001b[0m                         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                         samples_per_epoch = 551, nb_val_samples = 50)\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1863\u001b[0m                                          \u001b[0;34m'a tuple `(x, y, sample_weight)` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m                                          \u001b[0;34m'or `(x, y)`. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1865\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1866\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`. Found: None"
     ]
    }
   ],
   "source": [
    "new_model = True\n",
    "\n",
    "if new_model: \n",
    "    learning_rate = 8e-6\n",
    "    fenlei_fit('final_fenlei', [20,20,6])\n",
    "else:\n",
    "    learning_rate = 1e-5\n",
    "    fenlei_fit('final_fenlei', [20,20,6], 'final_fenlei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
