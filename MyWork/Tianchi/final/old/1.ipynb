{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    folders = [x for x in os.listdir(data_path) if 'subset' in x]\n",
    "    os.chdir(data_path)\n",
    "    patients = []    \n",
    "    for i in folders:\n",
    "        os.chdir(data_path + i)\n",
    "        patient_ids = [x for x in os.listdir(data_path + i) if '.mhd' in x]\n",
    "        for id in patient_ids:\n",
    "            j = '{}/{}'.format(i, id)\n",
    "            patients.append(j)\n",
    "    return patients\n",
    "\n",
    "def get_filename(file_list, case):\n",
    "    for f in file_list:\n",
    "        if case in f:\n",
    "            return(f)\n",
    "\n",
    "def normalize(image):\n",
    "    MIN_BOUND = -1000.0\n",
    "    MAX_BOUND = 400.0\n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image[image > 1] = 1.\n",
    "    image[image < 0] = 0.\n",
    "    return image\n",
    "\n",
    "def save_cube_img(target_path, cube_img, rows, cols):\n",
    "    assert rows * cols == cube_img.shape[0]\n",
    "    img_height = cube_img.shape[1]\n",
    "    img_width = cube_img.shape[1]\n",
    "    res_img = numpy.zeros((rows * img_height, cols * img_width), dtype=numpy.uint8)\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            target_y = row * img_height\n",
    "            target_x = col * img_width\n",
    "            res_img[target_y:target_y + img_height, target_x:target_x + img_width] = cube_img[row * cols + col]\n",
    "\n",
    "    cv2.imwrite(target_path, res_img)\n",
    "\n",
    "\n",
    "def get_cube_from_img(img3d, center_x, center_y, center_z, block_size):\n",
    "    start_x = max(center_x - block_size / 2, 0)\n",
    "    if start_x + block_size > img3d.shape[2]:\n",
    "        start_x = img3d.shape[2] - block_size\n",
    "\n",
    "    start_y = max(center_y - block_size / 2, 0)\n",
    "    start_z = max(center_z - block_size / 2, 0)\n",
    "    if start_z + block_size > img3d.shape[0]:\n",
    "        start_z = img3d.shape[0] - block_size\n",
    "    start_z = int(start_z)\n",
    "    start_y = int(start_y)\n",
    "    start_x = int(start_x)\n",
    "    res = img3d[start_z:start_z + block_size, start_y:start_y + block_size, start_x:start_x + block_size]\n",
    "    return res\n",
    "\n",
    "def create_samples(img_file): \n",
    "\n",
    "    \n",
    "    #1、生成肺部及肺部掩模图片\n",
    "    patient_id = img_file.split('/')[-1][:-4]\n",
    "    dst_dir = pic_path + patient_id + \"/\"\n",
    "    itk_img = SimpleITK.ReadImage(data_path + img_file)\n",
    "    img_array = SimpleITK.GetArrayFromImage(itk_img)\n",
    "    origin = numpy.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "    direction = numpy.array(itk_img.GetDirection())      # x,y,z  Origin in world coordinates (mm)\n",
    "    spacing = numpy.array(itk_img.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "    rescale = spacing / TARGET_VOXEL_MM\n",
    "    #img_array = helpers.rescale_patient_images(img_array, spacing, TARGET_VOXEL_MM)\n",
    "    df_node = pandas.read_csv(csv_path + \"annotations.csv\")\n",
    "    df_patient = df_node[df_node[\"seriesuid\"] == patient_id]\n",
    "\n",
    "    flip_direction_x = False\n",
    "    flip_direction_y = False\n",
    "    if round(direction[0]) == -1:\n",
    "        origin[0] *= -1\n",
    "        direction[0] = 1\n",
    "        flip_direction_x = True\n",
    "    if round(direction[4]) == -1:\n",
    "        origin[1] *= -1\n",
    "        direction[4] = 1\n",
    "        flip_direction_y = True\n",
    "    assert abs(sum(direction) - 3) < 0.01\n",
    "    patient_imgs = helpers.load_patient_images(patient_id, pic_path, \"*_i.png\")\n",
    "    pos_annos = []\n",
    "    anno_index = 0\n",
    "    for index, annotation in df_patient.iterrows():\n",
    "        node_x = annotation[\"coordX\"]\n",
    "        if flip_direction_x:\n",
    "            node_x *= -1\n",
    "        node_y = annotation[\"coordY\"]\n",
    "        if flip_direction_y:\n",
    "            node_y *= -1\n",
    "        node_z = annotation[\"coordZ\"]\n",
    "        diam_mm = annotation[\"diameter_mm\"]\n",
    "        center_float = numpy.array([node_x, node_y, node_z])  #world\n",
    "        center_int = numpy.rint((center_float-origin) / spacing) #voxel\n",
    "        \n",
    "        coord_x = center_float[2]\n",
    "        coord_y = center_float[1]\n",
    "        coord_z = center_float[0]\n",
    "        radius = np.ceil(diam_mm/2)\n",
    "        noduleRange = seq(-radius, radius, 1)\n",
    "        image_mask = np.zeros(patient_imgs.shape)\n",
    "\n",
    "        for x in noduleRange:\n",
    "            for y in noduleRange:\n",
    "                for z in noduleRange:\n",
    "                    coords = numpy.rint((np.array((coord_z+z,coord_y+y,coord_x+x))-origin) / spacing)\n",
    "                    if (np.linalg.norm(voxel_center - coords)) < radius:\n",
    "                        image_mask[int(np.round(coords[0])),int(np.round(coords[1])),int(np.round(coords[2]))] = int(1)\n",
    "        #print(np.max(image_mask))            \n",
    "    \n",
    "    img_list = []\n",
    "    for i in range(img_array.shape[0]):\n",
    "        img = img_array[i]\n",
    "        seg_img, mask = helpers.get_segmented_lungs(img.copy())\n",
    "        img_list.append(seg_img)\n",
    "        img = normalize(img)\n",
    "        cv2.imwrite(dst_dir + \"img_\" + str(i).rjust(4, '0') + \"_i.png\", img * 255)\n",
    "        cv2.imwrite(dst_dir + \"img_\" + str(i).rjust(4, '0') + \"_m.png\", mask * 255)\n",
    "        cv2.imwrite(dst_dir + \"img_\" + str(i).rjust(4, '0') + \"_o.png\", image_mask[i])\n",
    "    return\n",
    "\n",
    "\n",
    "def create_tests(img_file): \n",
    "    #1、生成肺部及肺部掩模图片\n",
    "    patient_id = img_file.split('/')[-1][:-4]\n",
    "    dst_dir = pic_path + patient_id + \"/\"\n",
    "    itk_img = SimpleITK.ReadImage(data_path + img_file)\n",
    "    img_array = SimpleITK.GetArrayFromImage(itk_img)\n",
    "    origin = numpy.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n",
    "    direction = numpy.array(itk_img.GetDirection())      # x,y,z  Origin in world coordinates (mm)\n",
    "    spacing = numpy.array(itk_img.GetSpacing())    # spacing of voxels in world coor. (mm)\n",
    "    rescale = spacing / TARGET_VOXEL_MM\n",
    "    #img_array = helpers.rescale_patient_images(img_array, spacing, TARGET_VOXEL_MM)\n",
    "    \n",
    "    img_list = []\n",
    "    for i in range(img_array.shape[0]):\n",
    "        img = img_array[i]\n",
    "        seg_img, mask = helpers.get_segmented_lungs(img.copy())\n",
    "        img_list.append(seg_img)\n",
    "        img = normalize(img)\n",
    "        if not os.path.exists(dst_dir):\n",
    "            os.mkdir(dst_dir)\n",
    "        cv2.imwrite(dst_dir + \"img_\" + str(i).rjust(4, '0') + \"_i.png\", img * mask * 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = PATH['src_train']\n",
    "pic_path = PATH['pic_train']\n",
    "label_path = PATH['label_train']\n",
    "csv_path = PATH['annotations_train']\n",
    "generated_path = PATH['generated_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patients = load_train()\n",
    "df_node = pd.read_csv(csv_path+\"annotations.csv\")\n",
    "df_node[\"file\"] = df_node[\"seriesuid\"].map(lambda file_name: get_filename(patients, file_name))\n",
    "df_node = df_node.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(create_samples)(patient) for patient in tqdm(sorted(patients)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CUBE_IMGTYPE_SRC = \"_i\"\n",
    "patient_index = glob.glob(label_path + \"*_annos_pos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(make_pos_annotation_images)(patient_index, csv_file) for patient_index, csv_file in tqdm(enumerate(patient_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = PATH['src_val']\n",
    "pic_path = PATH['pic_val']\n",
    "label_path = PATH['label_val']\n",
    "generated_path = PATH['generated_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients = load_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(create_tests)(patient) for patient in tqdm(sorted(patients)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = PATH['src_test']\n",
    "pic_path = PATH['pic_test']\n",
    "label_path = PATH['label_test']\n",
    "generated_path = PATH['generated_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients = load_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=-1)(delayed(create_tests)(patient) for patient in tqdm(sorted(patients)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
