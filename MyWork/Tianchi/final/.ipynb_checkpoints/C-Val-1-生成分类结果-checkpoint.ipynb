{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path = PATH['annotations_val']\n",
    "src = PATH['model_train_pred']\n",
    "pred_csv_path = PATH['model_train_pred']\n",
    "data_path = PATH['src_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_paths = PATH['model_paths']\n",
    "model_final = PATH['model_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cube_30 = load_model(model_final + 'Fenge_36_36_36.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_0 = pd.read_csv(pred_csv_path + \"2final_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seriesuids = pd.read_csv(PATH['annotations_val'] + \"seriesuids.csv\")\n",
    "test_pred_0[\"file\"] = test_pred_0[\"seriesuid\"].map(lambda file_name:  get_filename(seriesuids['seriesuid'].values, file_name))\n",
    "test_pred_0 = test_pred_0.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patients = [x for x in os.listdir(pred_csv_path) if 'orig' in x]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_0[\"file\"] = test_pred_0[\"seriesuid\"].map(lambda file_name: get_filename(patients, file_name))\n",
    "test_pred_0 = test_pred_0.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_30_30_30_cube = []\n",
    "\n",
    "average = []\n",
    "\n",
    "for img_file in tqdm(sorted(patients)):\n",
    "    mini_df_anno = test_pred_0[test_pred_0[\"file\"]==img_file] #get all nodules associate with file\n",
    "    if mini_df_anno.shape[0]>0: # some files may not have a nodule--skipping those \n",
    "        # load the data once        \n",
    "        patient_id = img_file[:-9]\n",
    "        img_array = np.load(src + img_file)\n",
    "        pos_annos = pd.read_csv(src + img_file[:-9] + '_annos_pos.csv')\n",
    "        origin = np.array([pos_annos.loc[0]['origin_x'],pos_annos.loc[0]['origin_y'],pos_annos.loc[0]['origin_z']]) \n",
    "        spacing = np.array([pos_annos.loc[0]['spacing_x'],pos_annos.loc[0]['spacing_y'],pos_annos.loc[0]['spacing_z']])\n",
    "        img_array = normalize(img_array)                \n",
    "        for node_idx1, cur_row1 in mini_df_anno.iterrows():       \n",
    "            node_x = cur_row1[\"coordX\"]\n",
    "            node_y = cur_row1[\"coordY\"]\n",
    "            node_z = cur_row1[\"coordZ\"]\n",
    "            diam = cur_row1[\"diameter_mm\"]\n",
    "            center = np.array([node_x, node_y, node_z])   # nodule center\n",
    "            v_center = np.rint(np.absolute(center-origin)/spacing)            \n",
    "            new_x = int(v_center[0])\n",
    "            new_y = int(v_center[1])\n",
    "            new_z = int(v_center[2])\n",
    "            \n",
    "            if new_z<18 or new_x<18 or new_y<18 or new_x+18>img_array.shape[2] or new_y+18>img_array.shape[1] or new_z+18>img_array.shape[0]:\n",
    "                cls_result_cube_30 = int(0)\n",
    "            else:\n",
    "   \n",
    "                trainX_cube_30 =  img_array[new_z - 18: new_z + 18,\n",
    "                                    new_y - 18 : new_y + 18,\n",
    "                                    new_x - 18 : new_x + 18] \n",
    "            \n",
    "                trainX_cube_30=np.expand_dims(trainX_cube_30,0)\n",
    "                trainX_cube_30=np.expand_dims(trainX_cube_30,0)\n",
    "            \n",
    "                cls_result_cube_30 = model_cube_30.predict(trainX_cube_30)[0][1]\n",
    "            probability_30_30_30_cube.append(cls_result_cube_30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probability_30_30_30_cube = np.array(probability_30_30_30_cube)\n",
    "probability_30_30_30_cube = probability_30_30_30_cube.clip(0.005,0.995)\n",
    "probability_30_30_30_cube = probability_30_30_30_cube.round(3)\n",
    "test_pred_0['probability'] = probability_30_30_30_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred_0.to_csv(main_path + \"/evaluationScript/exampleFiles/val_cal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /Volumes/solo/ali/evaluationScript/noduleCADEvaluationLUNA16.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
