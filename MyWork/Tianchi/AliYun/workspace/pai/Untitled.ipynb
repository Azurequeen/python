{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run step1_preprocess_luna16.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train/holdout files.\n",
      "('Train count: ', 1129, ', holdout count: ', 135)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step2_train_mass_segmenter.py:319: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv1 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(x)\n",
      "step2_train_mass_segmenter.py:320: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv1 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv1)\n",
      "step2_train_mass_segmenter.py:325: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv2 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(pool1)\n",
      "step2_train_mass_segmenter.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv2 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv2)\n",
      "step2_train_mass_segmenter.py:331: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv3 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(pool2)\n",
      "step2_train_mass_segmenter.py:332: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv3 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv3)\n",
      "step2_train_mass_segmenter.py:337: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv4 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(pool3)\n",
      "step2_train_mass_segmenter.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv4 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv4)\n",
      "step2_train_mass_segmenter.py:342: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv5 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(pool4)\n",
      "step2_train_mass_segmenter.py:343: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv5b\")`\n",
      "  conv5 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same', name=\"conv5b\")(conv5)\n",
      "step2_train_mass_segmenter.py:347: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv6 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(pool5)\n",
      "step2_train_mass_segmenter.py:348: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", name=\"conv6b\")`\n",
      "  conv6 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same', name=\"conv6b\")(conv6)\n",
      "step2_train_mass_segmenter.py:351: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  up6 = merge([up6, conv5], mode='concat', concat_axis=3)\n",
      "/Users/mahui/anaconda/lib/python2.7/site-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "step2_train_mass_segmenter.py:356: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv66 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(up6)\n",
      "step2_train_mass_segmenter.py:357: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv66 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv66)\n",
      "step2_train_mass_segmenter.py:359: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  up7 = merge([UpSampling2D(size=(2, 2))(conv66), conv4], mode='concat', concat_axis=3)\n",
      "step2_train_mass_segmenter.py:364: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv7 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(up7)\n",
      "step2_train_mass_segmenter.py:365: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv7 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv7)\n",
      "step2_train_mass_segmenter.py:367: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv3], mode='concat', concat_axis=3)\n",
      "step2_train_mass_segmenter.py:370: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv8 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(up8)\n",
      "step2_train_mass_segmenter.py:371: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv8 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv8)\n",
      "step2_train_mass_segmenter.py:374: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv2], mode='concat', concat_axis=3)\n",
      "step2_train_mass_segmenter.py:376: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv9 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(up9)\n",
      "step2_train_mass_segmenter.py:377: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  conv9 = Convolution2D(filter_size, 3, 3, activation='relu', border_mode='same')(conv9)\n",
      "step2_train_mass_segmenter.py:381: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), activation=\"sigmoid\")`\n",
      "  conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(up10)\n",
      "step2_train_mass_segmenter.py:383: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"co..., inputs=Tensor(\"in...)`\n",
      "  model = Model(input=inputs, output=conv10)\n",
      "step2_train_mass_segmenter.py:429: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., 1129, 200, callbacks=[<keras.ca..., validation_data=<generator..., validation_steps=135)`\n",
      "  model.fit_generator(train_gen, len(train_files) / epoch_div, epoch_count, validation_data=holdout_gen, nb_val_samples=len(holdout_files) / epoch_div, callbacks=[checkpoint1, checkpoint2, dumper])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 320, 320, 1)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 320, 320, 1)   4           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 320, 320, 32)  320         batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 320, 320, 32)  9248        conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 160, 160, 32)  0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 160, 160, 32)  128         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 160, 160, 64)  18496       batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 160, 160, 64)  36928       conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 80, 80, 64)    0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 80, 80, 64)    256         max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 80, 80, 96)    55392       batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 80, 80, 96)    83040       conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 40, 40, 96)    0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 40, 40, 96)    384         max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 40, 40, 128)   110720      batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 40, 40, 128)   147584      conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 20, 20, 128)   0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 20, 20, 128)   512         max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 20, 20, 128)   147584      batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv5b (Conv2D)                  (None, 20, 20, 128)   147584      conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)             (None, 10, 10, 128)   0           conv5b[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 10, 10, 128)   512         pool5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 10, 10, 128)   147584      batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv6b (Conv2D)                  (None, 10, 10, 128)   147584      conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up6 (UpSampling2D)               (None, 20, 20, 128)   0           conv6b[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 20, 20, 256)   0           up6[0][0]                        \n",
      "                                                                   conv5b[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 20, 20, 256)   1024        merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 20, 20, 96)    221280      batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 20, 20, 96)    83040       conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)   (None, 40, 40, 96)    0           conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 40, 40, 224)   0           up_sampling2d_1[0][0]            \n",
      "                                                                   conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 40, 40, 224)   896         merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, 40, 40, 64)    129088      batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, 40, 40, 64)    36928       conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)   (None, 80, 80, 64)    0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 80, 80, 160)   0           up_sampling2d_2[0][0]            \n",
      "                                                                   conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 80, 80, 160)   640         merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, 80, 80, 32)    46112       batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, 80, 80, 32)    9248        conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)   (None, 160, 160, 32)  0           conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 160, 160, 96)  0           up_sampling2d_3[0][0]            \n",
      "                                                                   conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, 160, 160, 96)  384         merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, 160, 160, 32)  27680       batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, 160, 160, 32)  9248        conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)   (None, 320, 320, 32)  0           conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, 320, 320, 1)   33          up_sampling2d_4[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 1,619,461\n",
      "Trainable params: 1,617,091\n",
      "Non-trainable params: 2,370\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.0885 - dice_coef: 0.0885Epoch 00000: val_loss improved from inf to -0.28641, saving model to workdir/masses_model_h0_00--0.29.hd5\n",
      "Epoch 00000: val_loss improved from inf to -0.28641, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 210s - loss: -0.0886 - dice_coef: 0.0886 - val_loss: -0.2864 - val_dice_coef: 0.2864\n",
      "Epoch 2/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.5017 - dice_coef: 0.5017Epoch 00001: val_loss improved from -0.28641 to -0.51589, saving model to workdir/masses_model_h0_01--0.52.hd5\n",
      "Epoch 00001: val_loss improved from -0.28641 to -0.51589, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 206s - loss: -0.5017 - dice_coef: 0.5017 - val_loss: -0.5159 - val_dice_coef: 0.5159\n",
      "Epoch 3/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.6182 - dice_coef: 0.6182Epoch 00002: val_loss did not improve\n",
      "Epoch 00002: val_loss did not improve\n",
      "1129/1129 [==============================] - 200s - loss: -0.6184 - dice_coef: 0.6184 - val_loss: -0.3948 - val_dice_coef: 0.3948\n",
      "Epoch 4/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.6804 - dice_coef: 0.6804Epoch 00003: val_loss improved from -0.51589 to -0.59188, saving model to workdir/masses_model_h0_03--0.59.hd5\n",
      "Epoch 00003: val_loss improved from -0.51589 to -0.59188, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 199s - loss: -0.6806 - dice_coef: 0.6806 - val_loss: -0.5919 - val_dice_coef: 0.5919\n",
      "Epoch 5/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.7044 - dice_coef: 0.7044Epoch 00004: val_loss improved from -0.59188 to -0.60108, saving model to workdir/masses_model_h0_04--0.60.hd5\n",
      "Epoch 00004: val_loss improved from -0.59188 to -0.60108, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 198s - loss: -0.7043 - dice_coef: 0.7043 - val_loss: -0.6011 - val_dice_coef: 0.6011\n",
      "Epoch 6/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.7248 - dice_coef: 0.7248Epoch 00005: val_loss improved from -0.60108 to -0.64749, saving model to workdir/masses_model_h0_05--0.65.hd5\n",
      "Epoch 00005: val_loss improved from -0.60108 to -0.64749, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 198s - loss: -0.7250 - dice_coef: 0.7250 - val_loss: -0.6475 - val_dice_coef: 0.6475\n",
      "Epoch 7/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.7376 - dice_coef: 0.7376Epoch 00006: val_loss did not improve\n",
      "Epoch 00006: val_loss did not improve\n",
      "1129/1129 [==============================] - 196s - loss: -0.7375 - dice_coef: 0.7375 - val_loss: -0.6436 - val_dice_coef: 0.6436\n",
      "Epoch 8/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.7587 - dice_coef: 0.7587Epoch 00007: val_loss improved from -0.64749 to -0.71211, saving model to workdir/masses_model_h0_07--0.71.hd5\n",
      "Epoch 00007: val_loss improved from -0.64749 to -0.71211, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 197s - loss: -0.7588 - dice_coef: 0.7588 - val_loss: -0.7121 - val_dice_coef: 0.7121\n",
      "Epoch 9/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.7709 - dice_coef: 0.7709Epoch 00008: val_loss did not improve\n",
      "Epoch 00008: val_loss did not improve\n",
      "1129/1129 [==============================] - 195s - loss: -0.7710 - dice_coef: 0.7710 - val_loss: -0.6204 - val_dice_coef: 0.6204\n",
      "Epoch 10/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.7746 - dice_coef: 0.7746Epoch 00009: val_loss did not improve\n",
      "Epoch 00009: val_loss did not improve\n",
      "1129/1129 [==============================] - 196s - loss: -0.7745 - dice_coef: 0.7745 - val_loss: -0.6346 - val_dice_coef: 0.6346\n",
      "Epoch 11/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.7671 - dice_coef: 0.7671Epoch 00010: val_loss did not improve\n",
      "Epoch 00010: val_loss did not improve\n",
      "1129/1129 [==============================] - 197s - loss: -0.7672 - dice_coef: 0.7672 - val_loss: -0.6600 - val_dice_coef: 0.6600\n",
      "Epoch 12/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.7969 - dice_coef: 0.7969Epoch 00011: val_loss did not improve\n",
      "Epoch 00011: val_loss did not improve\n",
      "1129/1129 [==============================] - 196s - loss: -0.7968 - dice_coef: 0.7968 - val_loss: -0.7091 - val_dice_coef: 0.7091\n",
      "Epoch 13/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8019 - dice_coef: 0.8019Epoch 00012: val_loss improved from -0.71211 to -0.71674, saving model to workdir/masses_model_h0_12--0.72.hd5\n",
      "Epoch 00012: val_loss improved from -0.71211 to -0.71674, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 196s - loss: -0.8019 - dice_coef: 0.8019 - val_loss: -0.7167 - val_dice_coef: 0.7167\n",
      "Epoch 14/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.7933 - dice_coef: 0.7933Epoch 00013: val_loss did not improve\n",
      "Epoch 00013: val_loss did not improve\n",
      "1129/1129 [==============================] - 182s - loss: -0.7934 - dice_coef: 0.7934 - val_loss: -0.6192 - val_dice_coef: 0.6192\n",
      "Epoch 15/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.7954 - dice_coef: 0.7954Epoch 00014: val_loss did not improve\n",
      "Epoch 00014: val_loss did not improve\n",
      "1129/1129 [==============================] - 176s - loss: -0.7954 - dice_coef: 0.7954 - val_loss: -0.6772 - val_dice_coef: 0.6772\n",
      "Epoch 16/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8079 - dice_coef: 0.8079Epoch 00015: val_loss did not improve\n",
      "Epoch 00015: val_loss did not improve\n",
      "1129/1129 [==============================] - 175s - loss: -0.8080 - dice_coef: 0.8080 - val_loss: -0.6999 - val_dice_coef: 0.6999\n",
      "Epoch 17/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8128 - dice_coef: 0.8128Epoch 00016: val_loss improved from -0.71674 to -0.72012, saving model to workdir/masses_model_h0_16--0.72.hd5\n",
      "Epoch 00016: val_loss improved from -0.71674 to -0.72012, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 176s - loss: -0.8128 - dice_coef: 0.8128 - val_loss: -0.7201 - val_dice_coef: 0.7201\n",
      "Epoch 18/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8241 - dice_coef: 0.8241Epoch 00017: val_loss did not improve\n",
      "Epoch 00017: val_loss did not improve\n",
      "1129/1129 [==============================] - 176s - loss: -0.8238 - dice_coef: 0.8238 - val_loss: -0.6804 - val_dice_coef: 0.6804\n",
      "Epoch 19/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8172 - dice_coef: 0.8172Epoch 00018: val_loss did not improve\n",
      "Epoch 00018: val_loss did not improve\n",
      "1129/1129 [==============================] - 175s - loss: -0.8172 - dice_coef: 0.8172 - val_loss: -0.7110 - val_dice_coef: 0.7110\n",
      "Epoch 20/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8277 - dice_coef: 0.8277Epoch 00019: val_loss improved from -0.72012 to -0.72030, saving model to workdir/masses_model_h0_19--0.72.hd5\n",
      "Epoch 00019: val_loss improved from -0.72012 to -0.72030, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 175s - loss: -0.8277 - dice_coef: 0.8277 - val_loss: -0.7203 - val_dice_coef: 0.7203\n",
      "Epoch 21/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8262 - dice_coef: 0.8262Epoch 00020: val_loss improved from -0.72030 to -0.73314, saving model to workdir/masses_model_h0_20--0.73.hd5\n",
      "Epoch 00020: val_loss improved from -0.72030 to -0.73314, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 175s - loss: -0.8260 - dice_coef: 0.8260 - val_loss: -0.7331 - val_dice_coef: 0.7331\n",
      "Epoch 22/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8327 - dice_coef: 0.8327Epoch 00021: val_loss improved from -0.73314 to -0.73772, saving model to workdir/masses_model_h0_21--0.74.hd5\n",
      "Epoch 00021: val_loss improved from -0.73314 to -0.73772, saving model to workdir/masses_model_h0_best.hd5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1129/1129 [==============================] - 175s - loss: -0.8327 - dice_coef: 0.8327 - val_loss: -0.7377 - val_dice_coef: 0.7377\n",
      "Epoch 23/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8298 - dice_coef: 0.8298Epoch 00022: val_loss did not improve\n",
      "Epoch 00022: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8299 - dice_coef: 0.8299 - val_loss: -0.7184 - val_dice_coef: 0.7184\n",
      "Epoch 24/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8379 - dice_coef: 0.8379Epoch 00023: val_loss improved from -0.73772 to -0.76455, saving model to workdir/masses_model_h0_23--0.76.hd5\n",
      "Epoch 00023: val_loss improved from -0.73772 to -0.76455, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 172s - loss: -0.8380 - dice_coef: 0.8380 - val_loss: -0.7645 - val_dice_coef: 0.7645\n",
      "Epoch 25/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8364 - dice_coef: 0.8364Epoch 00024: val_loss did not improve\n",
      "Epoch 00024: val_loss did not improve\n",
      "1129/1129 [==============================] - 172s - loss: -0.8365 - dice_coef: 0.8365 - val_loss: -0.6938 - val_dice_coef: 0.6938\n",
      "Epoch 26/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8417 - dice_coef: 0.8417Epoch 00025: val_loss did not improve\n",
      "Epoch 00025: val_loss did not improve\n",
      "1129/1129 [==============================] - 172s - loss: -0.8417 - dice_coef: 0.8417 - val_loss: -0.7528 - val_dice_coef: 0.7528\n",
      "Epoch 27/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8386 - dice_coef: 0.8386Epoch 00026: val_loss did not improve\n",
      "Epoch 00026: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8385 - dice_coef: 0.8385 - val_loss: -0.7633 - val_dice_coef: 0.7633\n",
      "Epoch 28/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8437 - dice_coef: 0.8437Epoch 00027: val_loss did not improve\n",
      "Epoch 00027: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.7350 - val_dice_coef: 0.7350\n",
      "Epoch 29/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8432 - dice_coef: 0.8432Epoch 00028: val_loss did not improve\n",
      "Epoch 00028: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8432 - dice_coef: 0.8432 - val_loss: -0.7041 - val_dice_coef: 0.7041\n",
      "Epoch 30/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8386 - dice_coef: 0.8386Epoch 00029: val_loss did not improve\n",
      "Epoch 00029: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8386 - dice_coef: 0.8386 - val_loss: -0.7554 - val_dice_coef: 0.7554\n",
      "Epoch 31/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8437 - dice_coef: 0.8437Epoch 00030: val_loss did not improve\n",
      "Epoch 00030: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8437 - dice_coef: 0.8437 - val_loss: -0.7577 - val_dice_coef: 0.7577\n",
      "Epoch 32/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8505 - dice_coef: 0.8505Epoch 00031: val_loss improved from -0.76455 to -0.76463, saving model to workdir/masses_model_h0_31--0.76.hd5\n",
      "Epoch 00031: val_loss improved from -0.76455 to -0.76463, saving model to workdir/masses_model_h0_best.hd5\n",
      "1129/1129 [==============================] - 173s - loss: -0.8506 - dice_coef: 0.8506 - val_loss: -0.7646 - val_dice_coef: 0.7646\n",
      "Epoch 33/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8497 - dice_coef: 0.8497Epoch 00032: val_loss did not improve\n",
      "Epoch 00032: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8497 - dice_coef: 0.8497 - val_loss: -0.7363 - val_dice_coef: 0.7363\n",
      "Epoch 34/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8500 - dice_coef: 0.8500Epoch 00033: val_loss did not improve\n",
      "Epoch 00033: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8500 - dice_coef: 0.8500 - val_loss: -0.7639 - val_dice_coef: 0.7639\n",
      "Epoch 35/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8492 - dice_coef: 0.8492Epoch 00034: val_loss did not improve\n",
      "Epoch 00034: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8492 - dice_coef: 0.8492 - val_loss: -0.7610 - val_dice_coef: 0.7610\n",
      "Epoch 36/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8530 - dice_coef: 0.8530Epoch 00035: val_loss did not improve\n",
      "Epoch 00035: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8530 - dice_coef: 0.8530 - val_loss: -0.7527 - val_dice_coef: 0.7527\n",
      "Epoch 37/200\n",
      "1128/1129 [============================>.] - ETA: 0s - loss: -0.8584 - dice_coef: 0.8584Epoch 00036: val_loss did not improve\n",
      "Epoch 00036: val_loss did not improve\n",
      "1129/1129 [==============================] - 173s - loss: -0.8584 - dice_coef: 0.8584 - val_loss: -0.7276 - val_dice_coef: 0.7276\n",
      "Epoch 38/200\n",
      " 131/1129 [==>...........................] - ETA: 147s - loss: -0.8456 - dice_coef: 0.8456"
     ]
    }
   ],
   "source": [
    "%run step2_train_mass_segmenter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
