{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_net(input_shape, load_weight_path=None, features=False, mal=False):\n",
    "    width = 64\n",
    "    inputs = Input(shape=(1, 32, 32, 32), name=\"input_1\")\n",
    "    x = inputs\n",
    "    x = AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode=\"same\")(x)\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width, 3, 3, 3, activation='relu', border_mode='same', name='conv1', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1')(x)\n",
    "\n",
    "    # 2nd layer group\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width*2, 3, 3, 3, activation='relu', border_mode='same', name='conv2', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2')(x)\n",
    "    x = Dropout(p=0.3)(x)\n",
    "\n",
    "    # 3rd layer group\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width*4, 3, 3, 3, activation='relu', border_mode='same', name='conv3a', subsample=(1, 1, 1))(x)\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width*4, 3, 3, 3, activation='relu', border_mode='same', name='conv3b', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3')(x)\n",
    "    x = Dropout(p=0.4)(x)\n",
    "\n",
    "    # 4th layer group\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width*8, 3, 3, 3, activation='relu', border_mode='same', name='conv4a', subsample=(1, 1, 1))(x)\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width*8, 3, 3, 3, activation='relu', border_mode='same', name='conv4b', subsample=(1, 1, 1),)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4')(x)\n",
    "    x = Dropout(p=0.5)(x)\n",
    "       \n",
    "    last64 = Convolution3D(64, 2, 2, 2, activation=\"relu\", name=\"last_64\")(x)\n",
    "    out_class = Convolution3D(1, 1, 1, 1, activation=\"softmax\", name=\"out_class_last\")(last64)\n",
    "    out_class = Flatten(name=\"out_class\")(x)\n",
    "    \n",
    "    out_class = Dense(2)(out_class) \n",
    "    #out_class = BatchNormalization(axis = 1)(out_class)\n",
    "    out_class = Activation('softmax')(out_class)\n",
    "    \n",
    "    model = Model(input=inputs, output=out_class)\n",
    "    model.compile(optimizer=SGD(lr=1e-3, momentum=0.9, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = PATH['cls_train_cube_30']\n",
    "output_true = PATH['cls_train_cube_30_true']\n",
    "output_false = PATH['cls_train_cube_30_false']\n",
    "model_paths = PATH['model_paths']\n",
    "model_final = PATH['model_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dirfiles(dir):\n",
    "    file_list = []\n",
    "    subset_path = os.listdir(dir)\n",
    "    for _ in range(len(subset_path)):\n",
    "        if subset_path[_] != '.DS_Store':\n",
    "            file_list.append(dir + subset_path[_])\n",
    "    return file_list\n",
    "\n",
    "def train_generator(output_true,output_false):\n",
    "    train_nb = 80000    \n",
    "    file_list_true = get_dirfiles(output_true)\n",
    "    file_list_false = get_dirfiles(output_false)        \n",
    "    file_list_true = np.random.choice(file_list_true, train_nb)\n",
    "    file_list_false = np.random.choice(file_list_false, train_nb)    \n",
    "    nb_true = len(file_list_true) + len(file_list_false)    \n",
    "    sample = np.zeros([nb_true,32, 32, 32])\n",
    "    labels = np.zeros([nb_true,2])\n",
    "    for i in tqdm(range(len(file_list_true))):       \n",
    "        cc= np.load(file_list_true[i])\n",
    "        sample[i] = cc\n",
    "        labels[i] = [0.,1.]\n",
    "    for j in tqdm(range(len(file_list_false))):\n",
    "        bb= np.load(file_list_false[j])\n",
    "        sample[j+len(file_list_true)] = bb \n",
    "        labels[j+len(file_list_true)] = [1.,0.]\n",
    "    sample = np.expand_dims(sample, axis=1)        \n",
    "    return sample,labels\n",
    "\n",
    "\n",
    "def fenlei_fit(name, load_check = False,batch_size=2, epochs=20,check_name = None):\n",
    "    t = time.time()\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience = 10, verbose = 1),\n",
    "                 ModelCheckpoint((model_paths + '{}.h5').format(name),\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose = 0,\n",
    "                                 save_best_only = True)]\n",
    "    if load_check:\n",
    "        check_model = (model_paths + '{}.h5').format(check_name)\n",
    "        model = load_model(check_model)\n",
    "    else:\n",
    "        #model = classifier((1, 32, 32, 32),128,(3, 3, 3), (2, 2, 2))\n",
    "        model = get_net((1, 32, 32, 32))\n",
    "    x,y = train_generator(output_true,output_false)\n",
    "    model.fit(x,y, batch_size=batch_size, epochs=epochs,\n",
    "              validation_split=0.2,verbose=1, callbacks=callbacks, shuffle=True) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [42:26<00:00, 31.42it/s]  \n",
      "100%|██████████| 80000/80000 [55:55<00:00, 23.84it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128000 samples, validate on 32000 samples\n",
      "Epoch 1/200\n",
      " 62616/128000 [=============>................] - ETA: 1937s - loss: 0.5594 - acc: 0.6994"
     ]
    }
   ],
   "source": [
    "fenlei_fit('Fenge_32_32_32_0704', load_check = False, batch_size=8, epochs=200, check_name = 'Fenge_32_32_32_0703')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list_true = get_dirfiles(output_true)\n",
    "file_list_false = get_dirfiles(output_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_pred = classifier((1, 36, 36, 36), (3, 3, 3), (2, 2, 2))\n",
    "model_pred = load_model(model_paths + 'Fenge_32_32_32_0704.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list_true = np.random.choice(file_list_true, 1000)\n",
    "file_list_false = np.random.choice(file_list_false, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = []\n",
    "for i in file_list_false[0:200]:\n",
    "    a=np.load(i)\n",
    "    a=np.expand_dims(a,0)\n",
    "    a=np.expand_dims(a,0)\n",
    "    cc.append(model_pred.predict(a))\n",
    "count = 0\n",
    "for i in cc:\n",
    "    if i[0][0] > 0.9:\n",
    "        count += 1\n",
    "print count*1.0/len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = []\n",
    "for i in file_list_true[0:200]:\n",
    "    a=np.load(i)\n",
    "    a=np.expand_dims(a,0)\n",
    "    a=np.expand_dims(a,0)\n",
    "    cc.append(model_pred.predict(a))\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in cc:\n",
    "    if i[0][1] > 0.9:\n",
    "        count += 1\n",
    "print count*1.0/len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1503f79d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solo(input_shape, load_weight_path=None, features=False, mal=False):\n",
    "    width = 64\n",
    "    inputs = Input(shape=(1, 32, 32, 32), name=\"input_1\")\n",
    "    x = inputs\n",
    "    x = AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode=\"same\")(x)\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width, 3, 3, 3, activation='relu', border_mode='same', name='conv1', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1')(x)\n",
    "\n",
    "    # 2nd layer group\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width*2, 3, 3, 3, activation='relu', border_mode='same', name='conv2', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2')(x)\n",
    "    x = Dropout(p=0.3)(x)\n",
    "\n",
    "    # 3rd layer group\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width*4, 3, 3, 3, activation='relu', border_mode='same', name='conv3a', subsample=(1, 1, 1))(x)\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width*4, 3, 3, 3, activation='relu', border_mode='same', name='conv3b', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3')(x)\n",
    "    x = Dropout(p=0.4)(x)\n",
    "\n",
    "    # 4th layer group\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width*8, 3, 3, 3, activation='relu', border_mode='same', name='conv4a', subsample=(1, 1, 1))(x)\n",
    "    #x = BatchNormalization(axis = 1)(x)\n",
    "    x = Convolution3D(width*8, 3, 3, 3, activation='relu', border_mode='same', name='conv4b', subsample=(1, 1, 1),)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4')(x)\n",
    "    x = Dropout(p=0.5)(x)\n",
    "       \n",
    "    last64 = Convolution3D(64, 2, 2, 2, activation=\"relu\", name=\"last_64\")(x)\n",
    "    out_class = Convolution3D(1, 1, 1, 1, activation=\"softmax\", name=\"out_class_last\")(last64)\n",
    "    out_class = Flatten(name=\"out_class\")(x)\n",
    "    \n",
    "    out_class = Dense(2)(out_class) \n",
    "    #out_class = BatchNormalization(axis = 1)(out_class)\n",
    "    out_class = Activation('softmax')(out_class)\n",
    "    \n",
    "    model = Model(input=inputs, output=out_class)\n",
    "    model.compile(optimizer=SGD(lr=1e-3, momentum=0.9, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "    plot_model(model, to_file='model1.png',show_shapes=True, show_layer_names=False)\n",
    "    return model\n",
    "\n",
    "solo((1, 32, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
