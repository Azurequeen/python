{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named utils.imports",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c2b4958dcb27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named utils.imports"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = PATH['cls_train_cube_64']\n",
    "output_true = PATH['cls_train_cube_64_true']\n",
    "output_false = PATH['cls_train_cube_64_false']\n",
    "model_paths = PATH['model_paths']\n",
    "model_final = PATH['model_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_dirfiles(dir):\n",
    "    file_list = []\n",
    "    subset_path = os.listdir(dir)\n",
    "    for _ in range(len(subset_path)):\n",
    "        if subset_path[_] != '.DS_Store':\n",
    "            file_list.append(dir + subset_path[_])\n",
    "    return file_list\n",
    "\n",
    "def train_generator(output_true,output_false):\n",
    "    file_list_true = get_dirfiles(output_true)[0:20]\n",
    "    file_list_false = get_dirfiles(output_false)[0:20]\n",
    "    \n",
    "    #file_list_true = shuffle(file_list_true)\n",
    "    #file_list_false = shuffle(file_list_false)\n",
    "    \n",
    "    nb_true = len(file_list_true) + len(file_list_false)\n",
    "    sample = np.zeros([nb_true,64,64,64])\n",
    "    labels = np.zeros([nb_true,2])\n",
    "    for i in tqdm(range(len(file_list_true))):       \n",
    "        cc= np.load(file_list_true[i])\n",
    "        sample[i] = cc\n",
    "        labels[i] = [0.,1.]\n",
    "    for j in tqdm(range(len(file_list_false))):\n",
    "        bb= np.load(file_list_false[j])\n",
    "        sample[j+len(file_list_true)] = bb \n",
    "        labels[j+len(file_list_true)] = [1.,0.]\n",
    "    sample = np.expand_dims(sample, axis=1)        \n",
    "    return sample,labels\n",
    "\n",
    "def valid_generator(output_true,output_false):\n",
    "    file_list_true = get_dirfiles(output_true)[-6:]\n",
    "    file_list_false = get_dirfiles(output_false)[-6:]\n",
    "    \n",
    "    #file_list_true = shuffle(file_list_true)\n",
    "    #file_list_false = shuffle(file_list_false)\n",
    "\n",
    "    nb_true = len(file_list_true) + len(file_list_false)\n",
    "    sample = np.zeros([nb_true,64,64,64])\n",
    "    labels = np.zeros([nb_true,2])\n",
    "  \n",
    "    for i in tqdm(range(len(file_list_true))):       \n",
    "        cc= np.load(file_list_true[i])\n",
    "        sample[i] = cc\n",
    "        labels[i] = [0.,1.]\n",
    "    for j in tqdm(range(len(file_list_false))):\n",
    "        bb= np.load(file_list_false[j])\n",
    "        sample[j+len(file_list_true)] = bb \n",
    "        labels[j+len(file_list_true)] = [1.,0.]\n",
    "    sample = np.expand_dims(sample, axis=1)        \n",
    "    return sample,labels\n",
    "\n",
    "\n",
    "def fenlei_fit(name, load_check = False,batch_size=2, epochs=100,check_name = None):\n",
    "\n",
    "    t = time.time()\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience = 8, verbose = 1),\n",
    "                 ModelCheckpoint((model_paths + '{}.h5').format(name),\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose = 0,\n",
    "                                 save_best_only = True)]\n",
    "    if load_check:\n",
    "        check_model = (model_paths + '{}.h5').format(check_name)\n",
    "        model = classifier((1, 64, 64, 64), 64, (3, 3, 3), (2, 2, 2))\n",
    "    else:\n",
    "        #model = model_20()\n",
    "        #model = preds3d_dense(48)\n",
    "        model = get_net((1, 64, 64, 64))\n",
    "    x,y = train_generator(output_true,output_false)\n",
    "    model.fit(x=x, y=y, batch_size=batch_size, epochs=epochs,\n",
    "              validation_data=valid_generator(output_true,output_false),verbose=1, callbacks=callbacks, shuffle=True)\n",
    "    \n",
    " \n",
    "    return model\n",
    "\n",
    "def get_net(input_shape, load_weight_path=None, features=False, mal=False):\n",
    "    inputs = Input(shape=(1, 64, 64, 64), name=\"input_1\")\n",
    "    x = inputs\n",
    "    x = AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode=\"same\")(x)\n",
    "    x = Convolution3D(64, 3, 3, 3, activation='relu', border_mode='same', name='conv1', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), border_mode='valid', name='pool1')(x)\n",
    "\n",
    "    # 2nd layer group\n",
    "    x = Convolution3D(128, 3, 3, 3, activation='relu', border_mode='same', name='conv2', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool2')(x)\n",
    "    #x = Dropout(p=0.3)(x)\n",
    "\n",
    "    # 3rd layer group\n",
    "    x = Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(256, 3, 3, 3, activation='relu', border_mode='same', name='conv3b', subsample=(1, 1, 1))(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool3')(x)\n",
    "    #x = Dropout(p=0.4)(x)\n",
    "\n",
    "    # 4th layer group\n",
    "    x = Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4a', subsample=(1, 1, 1))(x)\n",
    "    x = Convolution3D(512, 3, 3, 3, activation='relu', border_mode='same', name='conv4b', subsample=(1, 1, 1),)(x)\n",
    "    x = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='valid', name='pool4')(x)\n",
    "    #x = Dropout(p=0.5)(x)\n",
    "\n",
    "    last64 = Convolution3D(64, 2, 2, 2, activation=\"relu\", name=\"last_64\")(x)\n",
    "    out_class = Convolution3D(1, 1, 1, 1, activation=\"softmax\", name=\"out_class_last\")(last64)\n",
    "    out_class = Flatten(name=\"out_class\")(x)\n",
    "    \n",
    "    out_class = Dense(2)(out_class) \n",
    "    #out_class = Activation('softmax')(out_class)\n",
    "    \n",
    "    model = Model(input=inputs, output=out_class)\n",
    "    model.compile(optimizer=SGD(lr=1e-5, momentum=0.9, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def classifier(input_shape, width, kernel_size, pool_size):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(AveragePooling3D(pool_size=(2, 1, 1), strides=(2, 1, 1), border_mode=\"same\", input_shape=input_shape))\n",
    "    model.add(Convolution3D(width*1, kernel_size[0], kernel_size[1], kernel_size[2],\n",
    "                            border_mode='valid'))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling3D(pool_size=pool_size))\n",
    "    model.add(Convolution3D(width*2, kernel_size[0], kernel_size[1], kernel_size[2]))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling3D(pool_size=pool_size))\n",
    "    model.add(Convolution3D(width*4, kernel_size[0], kernel_size[1], kernel_size[2]))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling3D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adadelta',\n",
    "          metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_classifier(input_shape):\n",
    "    model = classifier(input_shape, (3, 3, 3), (2, 2, 2))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=Adam(lr=1e-5),\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fenlei_fit('Fenge_64_64_64_0619', load_check = False, batch_size=1, epochs=100, check_name = 'Fenge_64_64_64_0618')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list_true = get_dirfiles(output_true)\n",
    "file_list_false = get_dirfiles(output_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_pred = classifier((1, 36, 36, 36), (3, 3, 3), (2, 2, 2))\n",
    "model_pred = load_model(model_paths + 'Fenge_64_64_64_0618.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_pred.load_weights(model_paths + 'Fenge_0613_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = []\n",
    "for i in file_list_false[0:200]:\n",
    "    a=np.load(i)\n",
    "    a=np.expand_dims(a,0)\n",
    "    a=np.expand_dims(a,0)\n",
    "    cc.append(model_pred.predict(a))\n",
    "count = 0\n",
    "for i in cc:\n",
    "    if i[0][0] > 0.9:\n",
    "        count += 1\n",
    "print count*1.0/len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = []\n",
    "for i in file_list_true[0:200]:\n",
    "    a=np.load(i)\n",
    "    a=np.expand_dims(a,0)\n",
    "    a=np.expand_dims(a,0)\n",
    "    cc.append(model_pred.predict(a))\n",
    "count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in cc:\n",
    "    if i[0][1] > 0.9:\n",
    "        count += 1\n",
    "print count*1.0/len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(file_list_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.hist(trainX[20].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb= np.load(file_list_false[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
