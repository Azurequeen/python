{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils.helpers as helpers\n",
    "from utils.paths import *\n",
    "\n",
    "\n",
    "import SimpleITK  # conda install -c https://conda.anaconda.org/simpleitk SimpleITK\n",
    "import numpy\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ntpath\n",
    "import cv2  # conda install -c https://conda.anaconda.org/menpo opencv3\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "from typing import List, Tuple\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, UpSampling2D, merge, Dropout, BatchNormalization,SpatialDropout2D,Convolution3D,MaxPooling3D, UpSampling3D, Flatten, Dense\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.metrics import binary_accuracy, binary_crossentropy, mean_squared_error, mean_absolute_error\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler,EarlyStopping\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import glorot_normal, he_uniform \n",
    "\n",
    "random.seed(1321)\n",
    "numpy.random.seed(1321)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "K.set_image_dim_ordering('th') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = PATH['model_train']\n",
    "model_paths = PATH['model_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def dice_coef_np(y_true,y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return ((2. * intersection + 1) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1))\n",
    "\n",
    "def unet_model(dropout_rate,learn_rate, width):\n",
    "    inputs = Input((1, 512, 512))\n",
    "    conv1 = Convolution2D(width, (3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    #conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution2D(width, (3, 3), padding=\"same\", activation=\"relu\")(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Convolution2D(width*2, (3, 3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "    #conv2 = BatchNormalization(axis = 1)(conv2)\n",
    "    conv2 = Convolution2D(width*2, (3, 3), padding=\"same\", activation=\"relu\")(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Convolution2D(width*4, (3, 3), padding=\"same\", activation=\"relu\")(pool2)\n",
    "    #conv3 = BatchNormalization(axis = 1)(conv3)\n",
    "    conv3 = Convolution2D(width*4, (3, 3), padding=\"same\", activation=\"relu\")(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Convolution2D(width*8, (3, 3), padding=\"same\", activation=\"relu\")(pool3)\n",
    "    #conv4 = BatchNormalization(axis = 1)(conv4)\n",
    "    conv4 = Convolution2D(width*8, (3, 3), padding=\"same\", activation=\"relu\")(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Convolution2D(width*16, (3, 3), padding=\"same\", activation=\"relu\")(pool4)\n",
    "    #conv5 = BatchNormalization(axis = 1)(conv5)\n",
    "    conv5 = Convolution2D(width*16, (3, 3), padding=\"same\", activation=\"relu\")(conv5)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = SpatialDropout2D(dropout_rate)(up6)\n",
    "    conv6 = Convolution2D(width*8, (3, 3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "    conv6 = Convolution2D(width*8, (3, 3), padding=\"same\", activation=\"relu\")(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = SpatialDropout2D(dropout_rate)(up7)\n",
    "    conv7 = Convolution2D(width*4, (3, 3), padding=\"same\", activation=\"relu\")(conv7)\n",
    "    conv7 = Convolution2D(width*4, (3, 3), padding=\"same\", activation=\"relu\")(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = SpatialDropout2D(dropout_rate)(up8)\n",
    "    conv8 = Convolution2D(width*2, (3, 3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "    conv8 = Convolution2D(width*2, (3, 3), padding=\"same\", activation=\"relu\")(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = SpatialDropout2D(dropout_rate)(up9)\n",
    "    conv9 = Convolution2D(width, (3, 3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "    conv9 = Convolution2D(width, (3, 3), padding=\"same\", activation=\"relu\")(conv9)\n",
    "    conv10 = Convolution2D(1, (1, 1), activation=\"sigmoid\")(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    #model.summary()\n",
    "    model.compile(optimizer=Adam(lr=learn_rate), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    #model.compile(optimizer=SGD(lr=0.0001, momentum=0.9, nesterov=True), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    \n",
    "    #plot_model(model, to_file='model1.png',show_shapes=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def unet_fit(name, start_t, end_t, start_v, end_v, check_name = None):\n",
    "    data_gen_args = dict(rotation_range=25.,   \n",
    "                     width_shift_range=0.3,  \n",
    "                     height_shift_range=0.3,   \n",
    "                     horizontal_flip=True,   \n",
    "                     vertical_flip=True,  \n",
    "                     )\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "    seed = 1\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        src,\n",
    "        class_mode=None,\n",
    "        classes=['lung'],\n",
    "        seed=seed,\n",
    "        target_size=(512,512),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=1)\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        src,\n",
    "        class_mode=None,\n",
    "        classes=['nodule'],\n",
    "        seed=seed,\n",
    "        target_size=(512,512),\n",
    "        color_mode=\"grayscale\",\n",
    "        batch_size=1)\n",
    "\n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "        \n",
    "    t = time.time()\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience = 20, \n",
    "                                   verbose = 1),\n",
    "    ModelCheckpoint(model_paths + '{}.h5'.format(name), \n",
    "                        monitor='val_loss', \n",
    "                        verbose = 0, save_best_only = True)]\n",
    "    \n",
    "    if check_name is not None:\n",
    "        check_model = model_paths + '{}.h5'.format(check_name)\n",
    "        model = load_model(check_model, \n",
    "                           custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})\n",
    "    else:\n",
    "        model = unet_model(dropout_rate = 0, learn_rate = 1e-5, width = 128)\n",
    "        \n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=100,\n",
    "        verbose =2, \n",
    "        callbacks = callbacks,\n",
    "        steps_per_epoch=2000,\n",
    "        validation_data = train_generator,\n",
    "        nb_val_samples = 600)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3711 images belonging to 1 classes.\n",
      "Found 3711 images belonging to 1 classes.\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "#unet_fit('final_fenge_170621_2', 0,3000,3000,3600)\n",
    "unet_fit('final_fenge_170621', 0,3000,3000,3600,'final_fenge_170619')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
