{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dirfiles(dir):\n",
    "    file_list = []\n",
    "    subset_path = os.listdir(dir)\n",
    "    for _ in range(len(subset_path)):\n",
    "        if subset_path[_] != '.DS_Store':\n",
    "            file_list.append(dir + subset_path[_])\n",
    "    return file_list\n",
    "\n",
    "def train_generator(output_true,output_false):\n",
    "    file_list_true = get_dirfiles(output_true)[0:9000]\n",
    "    file_list_false = get_dirfiles(output_false)[0:9000]\n",
    "    \n",
    "    file_list_true = shuffle(file_list_true)\n",
    "    file_list_false = shuffle(file_list_false)\n",
    "    \n",
    "    nb_true = len(file_list_true) + len(file_list_false)\n",
    "    sample = np.zeros([nb_true,6,20,20])\n",
    "    labels = np.zeros([nb_true,2])\n",
    "    for i in tqdm(range(len(file_list_true))):       \n",
    "        cc= np.load(file_list_true[i])\n",
    "        sample[i] = cc\n",
    "        labels[i] = [0.,1.]\n",
    "    for j in tqdm(range(len(file_list_false))):\n",
    "        bb= np.load(file_list_false[j])\n",
    "        sample[j+len(file_list_true)] = bb \n",
    "        labels[j+len(file_list_true)] = [1.,0.]\n",
    "    sample = np.expand_dims(sample, axis=1)        \n",
    "    return sample,labels\n",
    "\n",
    "def valid_generator(output_true,output_false):\n",
    "    file_list_true = get_dirfiles(output_true)[-1000:]\n",
    "    file_list_false = get_dirfiles(output_false)[-1000:]\n",
    "    \n",
    "    file_list_true = shuffle(file_list_true)\n",
    "    file_list_false = shuffle(file_list_false)\n",
    "\n",
    "    nb_true = len(file_list_true) + len(file_list_false)\n",
    "    sample = np.zeros([nb_true,6,20,20])\n",
    "    labels = np.zeros([nb_true,2])\n",
    "  \n",
    "    for i in tqdm(range(len(file_list_true))):       \n",
    "        cc= np.load(file_list_true[i])\n",
    "        sample[i] = cc\n",
    "        labels[i] = [0.,1.]\n",
    "    for j in tqdm(range(len(file_list_false))):\n",
    "        bb= np.load(file_list_false[j])\n",
    "        sample[j+len(file_list_true)] = bb \n",
    "        labels[j+len(file_list_true)] = [1.,0.]\n",
    "    sample = np.expand_dims(sample, axis=1)        \n",
    "    return sample,labels\n",
    "\n",
    "def model_20_2():    \n",
    "\n",
    "    inputs = Input(shape=(1, 6, 20, 20))    \n",
    "    conv1 = Convolution3D(64, 3, 5, 5, activation = 'elu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Dropout(p=0.2)(conv1)    \n",
    "    conv1 = Convolution3D(64, 1, 1, 1, activation = 'elu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Dropout(p=0.2)(conv1)   \n",
    "    conv1 = Convolution3D(64, 3, 5, 5, activation = 'elu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Dropout(p=0.2)(conv1)   \n",
    "    conv1 = Convolution3D(64, 1, 5, 5, activation = 'elu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Dropout(p=0.2)(conv1)   \n",
    "    \n",
    "    output = Flatten(name='flatten')(conv1)\n",
    "    output = Dense(150)(output)\n",
    "    output = PReLU()(output)\n",
    "    output = Dropout(p=0.2)(output)   \n",
    "    output = BatchNormalization()(output)\n",
    "    output = Dense(2, activation='softmax', name = 'predictions')(output)\n",
    "    model3d = Model(inputs, output)\n",
    "    model3d.compile(loss='categorical_crossentropy', optimizer = SGD(lr=0.3, momentum=0.9), metrics = ['accuracy'])\n",
    "    return model3d\n",
    "\n",
    "def model_20():    \n",
    "\n",
    "    inputs = Input(shape=(1, 6, 20, 20))    \n",
    "    conv1 = Convolution3D(64, 3, 5, 5, activation = 'elu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 1, 1, 1, activation = 'elu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 3, 5, 5, activation = 'elu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(64, 1, 5, 5, activation = 'elu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)    \n",
    "    \n",
    "    output = Flatten(name='flatten')(conv1)\n",
    "    output = Dense(150)(output)\n",
    "    output = PReLU()(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Dense(2, activation='softmax', name = 'predictions')(output)\n",
    "    model3d = Model(inputs, output)\n",
    "    model3d.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-5), metrics = ['accuracy'])\n",
    "    return model3d\n",
    "\n",
    "def fenlei_fit(name, load_check = False,batch_size=2, epochs=20,check_name = None):\n",
    "\n",
    "    t = time.time()\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience = 200, verbose = 1),\n",
    "                 ModelCheckpoint((model_paths + '{}.h5').format(name),\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose = 0,\n",
    "                                 save_best_only = True)]\n",
    "    if load_check:\n",
    "        check_model = (model_paths + '{}.h5').format(check_name)\n",
    "        model = load_model(check_model)\n",
    "    else:\n",
    "        model = model_20_2()\n",
    "    x,y = train_generator(output_true,output_false)\n",
    "    model.fit(x=x, y=y, batch_size=batch_size, epochs=epochs,\n",
    "              validation_data=valid_generator(output_true,output_false),verbose=1, callbacks=callbacks, shuffle=True) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = PATH['cls_train_20']\n",
    "output_true = PATH['cls_train_20_true']\n",
    "output_false = PATH['cls_train_20_false']\n",
    "model_paths = PATH['model_paths']\n",
    "model_final = PATH['model_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [00:01<00:00, 5250.64it/s]\n",
      "100%|██████████| 9000/9000 [00:01<00:00, 5223.38it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5184.82it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5127.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "18000/18000 [==============================] - 89s - loss: 0.2169 - acc: 0.9130 - val_loss: 0.2141 - val_acc: 0.9210\n",
      "Epoch 2/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.2206 - acc: 0.9148 - val_loss: 0.2445 - val_acc: 0.9055\n",
      "Epoch 3/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.2052 - acc: 0.9211 - val_loss: 0.2194 - val_acc: 0.9170\n",
      "Epoch 4/200\n",
      "18000/18000 [==============================] - 88s - loss: 0.2061 - acc: 0.9210 - val_loss: 0.1968 - val_acc: 0.9305\n",
      "Epoch 5/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1939 - acc: 0.9252 - val_loss: 0.2153 - val_acc: 0.9175\n",
      "Epoch 6/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1882 - acc: 0.9274 - val_loss: 0.2003 - val_acc: 0.9285\n",
      "Epoch 7/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1893 - acc: 0.9261 - val_loss: 0.2073 - val_acc: 0.9260\n",
      "Epoch 8/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1811 - acc: 0.9294 - val_loss: 0.2004 - val_acc: 0.9295\n",
      "Epoch 9/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1773 - acc: 0.9296 - val_loss: 0.2088 - val_acc: 0.9210\n",
      "Epoch 10/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1725 - acc: 0.9344 - val_loss: 0.2257 - val_acc: 0.9230\n",
      "Epoch 11/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1643 - acc: 0.9367 - val_loss: 0.2059 - val_acc: 0.9300\n",
      "Epoch 12/200\n",
      "18000/18000 [==============================] - 88s - loss: 0.1546 - acc: 0.9410 - val_loss: 0.1957 - val_acc: 0.9325\n",
      "Epoch 13/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1603 - acc: 0.9386 - val_loss: 0.2187 - val_acc: 0.9200\n",
      "Epoch 14/200\n",
      "18000/18000 [==============================] - 88s - loss: 0.1487 - acc: 0.9434 - val_loss: 0.1935 - val_acc: 0.9340\n",
      "Epoch 15/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1388 - acc: 0.9497 - val_loss: 0.1939 - val_acc: 0.9340\n",
      "Epoch 16/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1370 - acc: 0.9474 - val_loss: 0.2062 - val_acc: 0.9370\n",
      "Epoch 17/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1356 - acc: 0.9478 - val_loss: 0.2627 - val_acc: 0.9200\n",
      "Epoch 18/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1254 - acc: 0.9545 - val_loss: 0.2143 - val_acc: 0.9345\n",
      "Epoch 19/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1141 - acc: 0.9583 - val_loss: 0.2260 - val_acc: 0.9280\n",
      "Epoch 20/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1152 - acc: 0.9575 - val_loss: 0.2264 - val_acc: 0.9310\n",
      "Epoch 21/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1078 - acc: 0.9605 - val_loss: 0.2844 - val_acc: 0.9155\n",
      "Epoch 22/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1008 - acc: 0.9629 - val_loss: 0.2217 - val_acc: 0.9290\n",
      "Epoch 23/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0999 - acc: 0.9643 - val_loss: 0.2249 - val_acc: 0.9260\n",
      "Epoch 24/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.1072 - acc: 0.9609 - val_loss: 0.2398 - val_acc: 0.9255\n",
      "Epoch 25/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0878 - acc: 0.9686 - val_loss: 0.2215 - val_acc: 0.9280\n",
      "Epoch 26/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0851 - acc: 0.9698 - val_loss: 0.2456 - val_acc: 0.9315\n",
      "Epoch 27/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0882 - acc: 0.9687 - val_loss: 0.2652 - val_acc: 0.9200\n",
      "Epoch 28/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0830 - acc: 0.9713 - val_loss: 0.2847 - val_acc: 0.9225\n",
      "Epoch 29/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0750 - acc: 0.9738 - val_loss: 0.2368 - val_acc: 0.9310\n",
      "Epoch 30/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0751 - acc: 0.9726 - val_loss: 0.2710 - val_acc: 0.9310\n",
      "Epoch 31/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0742 - acc: 0.9746 - val_loss: 0.3095 - val_acc: 0.9215\n",
      "Epoch 32/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0623 - acc: 0.9777 - val_loss: 0.2681 - val_acc: 0.9260\n",
      "Epoch 33/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0711 - acc: 0.9753 - val_loss: 0.2669 - val_acc: 0.9305\n",
      "Epoch 34/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0615 - acc: 0.9797 - val_loss: 0.2719 - val_acc: 0.9250\n",
      "Epoch 35/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0617 - acc: 0.9794 - val_loss: 0.2963 - val_acc: 0.9280\n",
      "Epoch 36/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0603 - acc: 0.9802 - val_loss: 0.2807 - val_acc: 0.9295\n",
      "Epoch 37/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0607 - acc: 0.9797 - val_loss: 0.3515 - val_acc: 0.9250\n",
      "Epoch 38/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0607 - acc: 0.9802 - val_loss: 0.3672 - val_acc: 0.9185\n",
      "Epoch 39/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0553 - acc: 0.9812 - val_loss: 0.3141 - val_acc: 0.9300\n",
      "Epoch 40/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0481 - acc: 0.9836 - val_loss: 0.2872 - val_acc: 0.9305\n",
      "Epoch 41/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0608 - acc: 0.9796 - val_loss: 0.2773 - val_acc: 0.9330\n",
      "Epoch 42/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0514 - acc: 0.9832 - val_loss: 0.3118 - val_acc: 0.9345\n",
      "Epoch 43/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0476 - acc: 0.9842 - val_loss: 0.3008 - val_acc: 0.9220\n",
      "Epoch 44/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0487 - acc: 0.9837 - val_loss: 0.2653 - val_acc: 0.9315\n",
      "Epoch 45/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0495 - acc: 0.9832 - val_loss: 0.3248 - val_acc: 0.9240\n",
      "Epoch 46/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0459 - acc: 0.9846 - val_loss: 0.2716 - val_acc: 0.9330\n",
      "Epoch 47/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0341 - acc: 0.9887 - val_loss: 0.3393 - val_acc: 0.9300\n",
      "Epoch 48/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0439 - acc: 0.9858 - val_loss: 0.3322 - val_acc: 0.9245\n",
      "Epoch 49/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0354 - acc: 0.9873 - val_loss: 0.3171 - val_acc: 0.9325\n",
      "Epoch 50/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0397 - acc: 0.9864 - val_loss: 0.3149 - val_acc: 0.9335\n",
      "Epoch 51/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0369 - acc: 0.9878 - val_loss: 0.3705 - val_acc: 0.9175\n",
      "Epoch 52/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0465 - acc: 0.9849 - val_loss: 0.4079 - val_acc: 0.9135\n",
      "Epoch 53/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0383 - acc: 0.9866 - val_loss: 0.3223 - val_acc: 0.9300\n",
      "Epoch 54/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0343 - acc: 0.9890 - val_loss: 0.3115 - val_acc: 0.9325\n",
      "Epoch 55/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0336 - acc: 0.9887 - val_loss: 0.3296 - val_acc: 0.9315\n",
      "Epoch 56/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0349 - acc: 0.9888 - val_loss: 0.3522 - val_acc: 0.9160\n",
      "Epoch 57/200\n",
      "18000/18000 [==============================] - 87s - loss: 0.0328 - acc: 0.9897 - val_loss: 0.3803 - val_acc: 0.9195\n",
      "Epoch 58/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0255 - acc: 0.9912 - val_loss: 0.3658 - val_acc: 0.9220\n",
      "Epoch 59/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0345 - acc: 0.9892 - val_loss: 0.3075 - val_acc: 0.9345\n",
      "Epoch 60/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0316 - acc: 0.9907 - val_loss: 0.3687 - val_acc: 0.9300\n",
      "Epoch 61/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0286 - acc: 0.9908 - val_loss: 0.3816 - val_acc: 0.9270\n",
      "Epoch 62/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0266 - acc: 0.9905 - val_loss: 0.3583 - val_acc: 0.9295\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 86s - loss: 0.0263 - acc: 0.9920 - val_loss: 0.3749 - val_acc: 0.9190\n",
      "Epoch 64/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0313 - acc: 0.9899 - val_loss: 0.3376 - val_acc: 0.9285\n",
      "Epoch 65/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0289 - acc: 0.9909 - val_loss: 0.3909 - val_acc: 0.9165\n",
      "Epoch 66/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0330 - acc: 0.9887 - val_loss: 0.3466 - val_acc: 0.9350\n",
      "Epoch 67/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0285 - acc: 0.9908 - val_loss: 0.3461 - val_acc: 0.9285\n",
      "Epoch 68/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0254 - acc: 0.9912 - val_loss: 0.3973 - val_acc: 0.9250\n",
      "Epoch 69/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0285 - acc: 0.9908 - val_loss: 0.3875 - val_acc: 0.9195\n",
      "Epoch 70/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0275 - acc: 0.9907 - val_loss: 0.4180 - val_acc: 0.9250\n",
      "Epoch 71/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0248 - acc: 0.9919 - val_loss: 0.3373 - val_acc: 0.9300\n",
      "Epoch 72/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0257 - acc: 0.9927 - val_loss: 0.3427 - val_acc: 0.9385\n",
      "Epoch 73/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0243 - acc: 0.9929 - val_loss: 0.3544 - val_acc: 0.9300\n",
      "Epoch 74/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0219 - acc: 0.9929 - val_loss: 0.3780 - val_acc: 0.9200\n",
      "Epoch 75/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0197 - acc: 0.9939 - val_loss: 0.4604 - val_acc: 0.9170\n",
      "Epoch 76/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0229 - acc: 0.9931 - val_loss: 0.3536 - val_acc: 0.9290\n",
      "Epoch 77/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0235 - acc: 0.9922 - val_loss: 0.3913 - val_acc: 0.9245\n",
      "Epoch 78/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0208 - acc: 0.9939 - val_loss: 0.3967 - val_acc: 0.9225\n",
      "Epoch 79/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0222 - acc: 0.9931 - val_loss: 0.3943 - val_acc: 0.9305\n",
      "Epoch 80/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0259 - acc: 0.9917 - val_loss: 0.3599 - val_acc: 0.9190\n",
      "Epoch 81/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0223 - acc: 0.9932 - val_loss: 0.4013 - val_acc: 0.9185\n",
      "Epoch 82/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0250 - acc: 0.9919 - val_loss: 0.3656 - val_acc: 0.9295\n",
      "Epoch 83/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0273 - acc: 0.9912 - val_loss: 0.3647 - val_acc: 0.9295\n",
      "Epoch 84/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0182 - acc: 0.9943 - val_loss: 0.4048 - val_acc: 0.9285\n",
      "Epoch 85/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0261 - acc: 0.9916 - val_loss: 0.4357 - val_acc: 0.9270\n",
      "Epoch 86/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0251 - acc: 0.9924 - val_loss: 0.4241 - val_acc: 0.9255\n",
      "Epoch 87/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0254 - acc: 0.9916 - val_loss: 0.3548 - val_acc: 0.9310\n",
      "Epoch 88/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0196 - acc: 0.9946 - val_loss: 0.3766 - val_acc: 0.9290\n",
      "Epoch 89/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0179 - acc: 0.9949 - val_loss: 0.4265 - val_acc: 0.9225\n",
      "Epoch 90/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0192 - acc: 0.9936 - val_loss: 0.4292 - val_acc: 0.9245\n",
      "Epoch 91/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0191 - acc: 0.9943 - val_loss: 0.3713 - val_acc: 0.9275\n",
      "Epoch 92/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0168 - acc: 0.9948 - val_loss: 0.3587 - val_acc: 0.9300\n",
      "Epoch 93/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0181 - acc: 0.9943 - val_loss: 0.3980 - val_acc: 0.9260\n",
      "Epoch 94/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0181 - acc: 0.9946 - val_loss: 0.3830 - val_acc: 0.9305\n",
      "Epoch 95/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0195 - acc: 0.9944 - val_loss: 0.4571 - val_acc: 0.9225\n",
      "Epoch 96/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0168 - acc: 0.9948 - val_loss: 0.4328 - val_acc: 0.9320\n",
      "Epoch 97/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0150 - acc: 0.9951 - val_loss: 0.4264 - val_acc: 0.9225\n",
      "Epoch 98/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0205 - acc: 0.9934 - val_loss: 0.4071 - val_acc: 0.9325\n",
      "Epoch 99/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0192 - acc: 0.9948 - val_loss: 0.4220 - val_acc: 0.9290\n",
      "Epoch 100/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0166 - acc: 0.9947 - val_loss: 0.4099 - val_acc: 0.9290\n",
      "Epoch 101/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0206 - acc: 0.9933 - val_loss: 0.4459 - val_acc: 0.9215\n",
      "Epoch 102/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0156 - acc: 0.9954 - val_loss: 0.4204 - val_acc: 0.9315\n",
      "Epoch 103/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0136 - acc: 0.9959 - val_loss: 0.4561 - val_acc: 0.9255\n",
      "Epoch 104/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0166 - acc: 0.9945 - val_loss: 0.4815 - val_acc: 0.9180\n",
      "Epoch 105/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0160 - acc: 0.9952 - val_loss: 0.4472 - val_acc: 0.9210\n",
      "Epoch 106/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0178 - acc: 0.9947 - val_loss: 0.4073 - val_acc: 0.9260\n",
      "Epoch 107/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0158 - acc: 0.9953 - val_loss: 0.3982 - val_acc: 0.9305\n",
      "Epoch 108/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0188 - acc: 0.9947 - val_loss: 0.4352 - val_acc: 0.9310\n",
      "Epoch 109/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0158 - acc: 0.9950 - val_loss: 0.4139 - val_acc: 0.9290\n",
      "Epoch 110/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0157 - acc: 0.9952 - val_loss: 0.4436 - val_acc: 0.9160\n",
      "Epoch 111/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0145 - acc: 0.9962 - val_loss: 0.3888 - val_acc: 0.9265\n",
      "Epoch 112/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0135 - acc: 0.9957 - val_loss: 0.4677 - val_acc: 0.9175\n",
      "Epoch 113/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0194 - acc: 0.9939 - val_loss: 0.4479 - val_acc: 0.9245\n",
      "Epoch 114/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0149 - acc: 0.9951 - val_loss: 0.4254 - val_acc: 0.9260\n",
      "Epoch 115/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0185 - acc: 0.9939 - val_loss: 0.4093 - val_acc: 0.9280\n",
      "Epoch 116/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0142 - acc: 0.9959 - val_loss: 0.4934 - val_acc: 0.9225\n",
      "Epoch 117/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0167 - acc: 0.9945 - val_loss: 0.3793 - val_acc: 0.9280\n",
      "Epoch 118/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0129 - acc: 0.9964 - val_loss: 0.4552 - val_acc: 0.9165\n",
      "Epoch 119/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0172 - acc: 0.9949 - val_loss: 0.3884 - val_acc: 0.9245\n",
      "Epoch 120/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0131 - acc: 0.9963 - val_loss: 0.4228 - val_acc: 0.9330\n",
      "Epoch 121/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0158 - acc: 0.9951 - val_loss: 0.4442 - val_acc: 0.9265\n",
      "Epoch 122/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0155 - acc: 0.9956 - val_loss: 0.4656 - val_acc: 0.9270\n",
      "Epoch 123/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0178 - acc: 0.9946 - val_loss: 0.4567 - val_acc: 0.9265\n",
      "Epoch 124/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0170 - acc: 0.9951 - val_loss: 0.4282 - val_acc: 0.9250\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 86s - loss: 0.0152 - acc: 0.9952 - val_loss: 0.3791 - val_acc: 0.9250\n",
      "Epoch 126/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0150 - acc: 0.9956 - val_loss: 0.3876 - val_acc: 0.9315\n",
      "Epoch 127/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0144 - acc: 0.9955 - val_loss: 0.3962 - val_acc: 0.9270\n",
      "Epoch 128/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0193 - acc: 0.9947 - val_loss: 0.4505 - val_acc: 0.9275\n",
      "Epoch 129/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0165 - acc: 0.9952 - val_loss: 0.4233 - val_acc: 0.9250\n",
      "Epoch 130/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0124 - acc: 0.9968 - val_loss: 0.4314 - val_acc: 0.9215\n",
      "Epoch 131/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0139 - acc: 0.9956 - val_loss: 0.4695 - val_acc: 0.9200\n",
      "Epoch 132/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0137 - acc: 0.9962 - val_loss: 0.4006 - val_acc: 0.9310\n",
      "Epoch 133/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0122 - acc: 0.9968 - val_loss: 0.4276 - val_acc: 0.9280\n",
      "Epoch 134/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0146 - acc: 0.9962 - val_loss: 0.4436 - val_acc: 0.9300\n",
      "Epoch 135/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0148 - acc: 0.9957 - val_loss: 0.5091 - val_acc: 0.9115\n",
      "Epoch 136/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0126 - acc: 0.9963 - val_loss: 0.4260 - val_acc: 0.9285\n",
      "Epoch 137/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0126 - acc: 0.9962 - val_loss: 0.4533 - val_acc: 0.9255\n",
      "Epoch 138/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0122 - acc: 0.9965 - val_loss: 0.4586 - val_acc: 0.9220\n",
      "Epoch 139/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0155 - acc: 0.9957 - val_loss: 0.4280 - val_acc: 0.9275\n",
      "Epoch 140/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0150 - acc: 0.9953 - val_loss: 0.4655 - val_acc: 0.9240\n",
      "Epoch 141/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0137 - acc: 0.9963 - val_loss: 0.4419 - val_acc: 0.9270\n",
      "Epoch 142/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0112 - acc: 0.9967 - val_loss: 0.4719 - val_acc: 0.9335\n",
      "Epoch 143/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0106 - acc: 0.9970 - val_loss: 0.4743 - val_acc: 0.9265\n",
      "Epoch 144/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0100 - acc: 0.9965 - val_loss: 0.4409 - val_acc: 0.9280\n",
      "Epoch 145/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0105 - acc: 0.9973 - val_loss: 0.4505 - val_acc: 0.9315\n",
      "Epoch 146/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0138 - acc: 0.9958 - val_loss: 0.4635 - val_acc: 0.9270\n",
      "Epoch 147/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0165 - acc: 0.9953 - val_loss: 0.4322 - val_acc: 0.9245\n",
      "Epoch 148/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0126 - acc: 0.9961 - val_loss: 0.4434 - val_acc: 0.9295\n",
      "Epoch 149/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0118 - acc: 0.9967 - val_loss: 0.4517 - val_acc: 0.9245\n",
      "Epoch 150/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0121 - acc: 0.9968 - val_loss: 0.4777 - val_acc: 0.9270\n",
      "Epoch 151/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0113 - acc: 0.9968 - val_loss: 0.4713 - val_acc: 0.9245\n",
      "Epoch 152/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0105 - acc: 0.9968 - val_loss: 0.4615 - val_acc: 0.9285\n",
      "Epoch 153/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0111 - acc: 0.9968 - val_loss: 0.4615 - val_acc: 0.9210\n",
      "Epoch 154/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0108 - acc: 0.9971 - val_loss: 0.5611 - val_acc: 0.9150\n",
      "Epoch 155/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0155 - acc: 0.9954 - val_loss: 0.4148 - val_acc: 0.9260\n",
      "Epoch 156/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0128 - acc: 0.9957 - val_loss: 0.4790 - val_acc: 0.9260\n",
      "Epoch 157/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0139 - acc: 0.9958 - val_loss: 0.4366 - val_acc: 0.9255\n",
      "Epoch 158/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0141 - acc: 0.9956 - val_loss: 0.4547 - val_acc: 0.9210\n",
      "Epoch 159/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0115 - acc: 0.9966 - val_loss: 0.4407 - val_acc: 0.9255\n",
      "Epoch 160/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0083 - acc: 0.9976 - val_loss: 0.4600 - val_acc: 0.9325\n",
      "Epoch 161/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0104 - acc: 0.9976 - val_loss: 0.4878 - val_acc: 0.9135\n",
      "Epoch 162/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0122 - acc: 0.9959 - val_loss: 0.4684 - val_acc: 0.9235\n",
      "Epoch 163/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0107 - acc: 0.9969 - val_loss: 0.4518 - val_acc: 0.9250\n",
      "Epoch 164/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0128 - acc: 0.9971 - val_loss: 0.4747 - val_acc: 0.9205\n",
      "Epoch 165/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0117 - acc: 0.9966 - val_loss: 0.4943 - val_acc: 0.9310\n",
      "Epoch 166/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0117 - acc: 0.9967 - val_loss: 0.4817 - val_acc: 0.9125\n",
      "Epoch 167/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0143 - acc: 0.9962 - val_loss: 0.4854 - val_acc: 0.9105\n",
      "Epoch 168/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0142 - acc: 0.9958 - val_loss: 0.4712 - val_acc: 0.9325\n",
      "Epoch 169/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0119 - acc: 0.9964 - val_loss: 0.4435 - val_acc: 0.9295\n",
      "Epoch 170/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0111 - acc: 0.9971 - val_loss: 0.4476 - val_acc: 0.9260\n",
      "Epoch 171/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0091 - acc: 0.9976 - val_loss: 0.5336 - val_acc: 0.9135\n",
      "Epoch 172/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0118 - acc: 0.9965 - val_loss: 0.4574 - val_acc: 0.9265\n",
      "Epoch 173/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0086 - acc: 0.9977 - val_loss: 0.4963 - val_acc: 0.9270\n",
      "Epoch 174/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0118 - acc: 0.9970 - val_loss: 0.4388 - val_acc: 0.9320\n",
      "Epoch 175/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0097 - acc: 0.9976 - val_loss: 0.4375 - val_acc: 0.9335\n",
      "Epoch 176/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0106 - acc: 0.9969 - val_loss: 0.4367 - val_acc: 0.9295\n",
      "Epoch 177/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0087 - acc: 0.9977 - val_loss: 0.4379 - val_acc: 0.9310\n",
      "Epoch 178/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0099 - acc: 0.9970 - val_loss: 0.5368 - val_acc: 0.9205\n",
      "Epoch 179/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0116 - acc: 0.9967 - val_loss: 0.4502 - val_acc: 0.9240\n",
      "Epoch 180/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0090 - acc: 0.9973 - val_loss: 0.4810 - val_acc: 0.9255\n",
      "Epoch 181/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0108 - acc: 0.9971 - val_loss: 0.4250 - val_acc: 0.9250\n",
      "Epoch 182/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0131 - acc: 0.9957 - val_loss: 0.4787 - val_acc: 0.9265\n",
      "Epoch 183/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0114 - acc: 0.9973 - val_loss: 0.4922 - val_acc: 0.9205\n",
      "Epoch 184/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0095 - acc: 0.9976 - val_loss: 0.4503 - val_acc: 0.9305\n",
      "Epoch 185/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0118 - acc: 0.9963 - val_loss: 0.4770 - val_acc: 0.9210\n",
      "Epoch 186/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0095 - acc: 0.9972 - val_loss: 0.4754 - val_acc: 0.9190\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 86s - loss: 0.0107 - acc: 0.9969 - val_loss: 0.4540 - val_acc: 0.9280\n",
      "Epoch 188/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0101 - acc: 0.9976 - val_loss: 0.4614 - val_acc: 0.9290\n",
      "Epoch 189/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.4852 - val_acc: 0.9270\n",
      "Epoch 190/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0094 - acc: 0.9973 - val_loss: 0.4703 - val_acc: 0.9255\n",
      "Epoch 191/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0132 - acc: 0.9962 - val_loss: 0.4539 - val_acc: 0.9300\n",
      "Epoch 192/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0103 - acc: 0.9971 - val_loss: 0.4514 - val_acc: 0.9240\n",
      "Epoch 193/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0108 - acc: 0.9968 - val_loss: 0.4782 - val_acc: 0.9270\n",
      "Epoch 194/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0101 - acc: 0.9977 - val_loss: 0.4919 - val_acc: 0.9215\n",
      "Epoch 195/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0081 - acc: 0.9979 - val_loss: 0.4372 - val_acc: 0.9245\n",
      "Epoch 196/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0080 - acc: 0.9983 - val_loss: 0.4230 - val_acc: 0.9255\n",
      "Epoch 197/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0081 - acc: 0.9979 - val_loss: 0.4817 - val_acc: 0.9305\n",
      "Epoch 198/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0094 - acc: 0.9969 - val_loss: 0.5136 - val_acc: 0.9270\n",
      "Epoch 199/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0107 - acc: 0.9964 - val_loss: 0.5530 - val_acc: 0.9170\n",
      "Epoch 200/200\n",
      "18000/18000 [==============================] - 86s - loss: 0.0098 - acc: 0.9974 - val_loss: 0.4524 - val_acc: 0.9305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x14aa93510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fenlei_fit('Fenge_6_20_20_0618', load_check = True, batch_size=200, epochs=30, check_name = 'Fenge_6_20_20_0618')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list_true = get_dirfiles(output_true)\n",
    "file_list_false = get_dirfiles(output_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_pred = classifier((1, 36, 36, 36), (3, 3, 3), (2, 2, 2))\n",
    "model_pred = load_model(model_paths + 'Fenge_6_20_20_0618.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n"
     ]
    }
   ],
   "source": [
    "cc = []\n",
    "for i in file_list_false[0:200]:\n",
    "    a=np.load(i)\n",
    "    a=np.expand_dims(a,0)\n",
    "    a=np.expand_dims(a,0)\n",
    "    cc.append(model_pred.predict(a))\n",
    "count = 0\n",
    "for i in cc:\n",
    "    if i[0][0] > 0.9:\n",
    "        count += 1\n",
    "print count*1.0/len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.97026348,  0.02973649]], dtype=float32),\n",
       " array([[ 0.96584773,  0.03415221]], dtype=float32),\n",
       " array([[ 0.92281783,  0.07718219]], dtype=float32),\n",
       " array([[  9.99274313e-01,   7.25683407e-04]], dtype=float32),\n",
       " array([[ 0.26466003,  0.73534   ]], dtype=float32),\n",
       " array([[ 0.99575138,  0.00424865]], dtype=float32),\n",
       " array([[ 0.89408034,  0.10591961]], dtype=float32),\n",
       " array([[ 0.98376369,  0.01623633]], dtype=float32),\n",
       " array([[ 0.98421222,  0.01578782]], dtype=float32),\n",
       " array([[ 0.01634328,  0.98365676]], dtype=float32),\n",
       " array([[ 0.99277037,  0.00722961]], dtype=float32),\n",
       " array([[ 0.95145828,  0.04854175]], dtype=float32),\n",
       " array([[ 0.15287569,  0.84712434]], dtype=float32),\n",
       " array([[ 0.99786711,  0.00213282]], dtype=float32),\n",
       " array([[ 0.96023434,  0.03976573]], dtype=float32),\n",
       " array([[ 0.99698669,  0.0030133 ]], dtype=float32),\n",
       " array([[ 0.99776328,  0.00223668]], dtype=float32),\n",
       " array([[ 0.9646855 ,  0.03531453]], dtype=float32),\n",
       " array([[ 0.97167128,  0.02832871]], dtype=float32),\n",
       " array([[ 0.99633992,  0.00366011]], dtype=float32),\n",
       " array([[ 0.9955669 ,  0.00443313]], dtype=float32),\n",
       " array([[ 0.991418  ,  0.00858199]], dtype=float32),\n",
       " array([[ 0.9956696 ,  0.00433038]], dtype=float32),\n",
       " array([[ 0.99644691,  0.00355308]], dtype=float32),\n",
       " array([[ 0.99359387,  0.00640609]], dtype=float32),\n",
       " array([[ 0.99344712,  0.00655288]], dtype=float32),\n",
       " array([[ 0.80112368,  0.19887631]], dtype=float32),\n",
       " array([[  9.99548972e-01,   4.50960739e-04]], dtype=float32),\n",
       " array([[ 0.99231088,  0.00768912]], dtype=float32),\n",
       " array([[ 0.99796069,  0.00203928]], dtype=float32),\n",
       " array([[ 0.97765326,  0.02234681]], dtype=float32),\n",
       " array([[ 0.97542894,  0.02457099]], dtype=float32),\n",
       " array([[  9.99208152e-01,   7.91917089e-04]], dtype=float32),\n",
       " array([[ 0.99804115,  0.00195883]], dtype=float32),\n",
       " array([[ 0.81722844,  0.18277153]], dtype=float32),\n",
       " array([[ 0.9988668 ,  0.00113323]], dtype=float32),\n",
       " array([[ 0.63491559,  0.36508438]], dtype=float32),\n",
       " array([[ 0.99427754,  0.00572255]], dtype=float32),\n",
       " array([[ 0.99562573,  0.00437428]], dtype=float32),\n",
       " array([[ 0.99418676,  0.00581325]], dtype=float32),\n",
       " array([[ 0.98633713,  0.0136629 ]], dtype=float32),\n",
       " array([[ 0.99774432,  0.00225574]], dtype=float32),\n",
       " array([[ 0.98008567,  0.01991436]], dtype=float32),\n",
       " array([[ 0.98822325,  0.01177677]], dtype=float32),\n",
       " array([[ 0.99792117,  0.0020789 ]], dtype=float32),\n",
       " array([[ 0.978374  ,  0.02162605]], dtype=float32),\n",
       " array([[ 0.9974578 ,  0.00254227]], dtype=float32),\n",
       " array([[ 0.99808335,  0.00191669]], dtype=float32),\n",
       " array([[ 0.99257374,  0.00742625]], dtype=float32),\n",
       " array([[ 0.99891651,  0.00108348]], dtype=float32),\n",
       " array([[ 0.52027571,  0.47972426]], dtype=float32),\n",
       " array([[ 0.99624592,  0.00375408]], dtype=float32),\n",
       " array([[ 0.99306655,  0.00693349]], dtype=float32),\n",
       " array([[ 0.99299157,  0.00700846]], dtype=float32),\n",
       " array([[ 0.99896002,  0.00103995]], dtype=float32),\n",
       " array([[ 0.99067336,  0.00932668]], dtype=float32),\n",
       " array([[ 0.99798846,  0.00201157]], dtype=float32),\n",
       " array([[ 0.99520725,  0.00479268]], dtype=float32),\n",
       " array([[ 0.96231437,  0.03768567]], dtype=float32),\n",
       " array([[  9.99511480e-01,   4.88510937e-04]], dtype=float32),\n",
       " array([[ 0.99894553,  0.00105444]], dtype=float32),\n",
       " array([[ 0.98038805,  0.0196119 ]], dtype=float32),\n",
       " array([[ 0.99878007,  0.00121993]], dtype=float32),\n",
       " array([[ 0.99078953,  0.00921044]], dtype=float32),\n",
       " array([[  9.99904871e-01,   9.50891044e-05]], dtype=float32),\n",
       " array([[ 0.99505448,  0.00494547]], dtype=float32),\n",
       " array([[ 0.99838984,  0.00161019]], dtype=float32),\n",
       " array([[ 0.96266609,  0.03733388]], dtype=float32),\n",
       " array([[ 0.98345506,  0.016545  ]], dtype=float32),\n",
       " array([[ 0.98987645,  0.01012349]], dtype=float32),\n",
       " array([[ 0.94011021,  0.05988975]], dtype=float32),\n",
       " array([[ 0.91324764,  0.08675233]], dtype=float32),\n",
       " array([[ 0.99809963,  0.00190044]], dtype=float32),\n",
       " array([[ 0.69467044,  0.30532956]], dtype=float32),\n",
       " array([[ 0.78444898,  0.21555103]], dtype=float32),\n",
       " array([[ 0.9905991 ,  0.00940086]], dtype=float32),\n",
       " array([[  9.99091029e-01,   9.09028342e-04]], dtype=float32),\n",
       " array([[ 0.98599213,  0.01400785]], dtype=float32),\n",
       " array([[ 0.90037584,  0.09962415]], dtype=float32),\n",
       " array([[ 0.99826825,  0.00173174]], dtype=float32),\n",
       " array([[ 0.98075533,  0.01924471]], dtype=float32),\n",
       " array([[ 0.99513716,  0.00486283]], dtype=float32),\n",
       " array([[ 0.99651647,  0.0034835 ]], dtype=float32),\n",
       " array([[ 0.95079517,  0.04920487]], dtype=float32),\n",
       " array([[ 0.94935489,  0.05064512]], dtype=float32),\n",
       " array([[ 0.90426826,  0.0957318 ]], dtype=float32),\n",
       " array([[ 0.81928492,  0.18071514]], dtype=float32),\n",
       " array([[  9.99181449e-01,   8.18502682e-04]], dtype=float32),\n",
       " array([[ 0.6989575 ,  0.30104247]], dtype=float32),\n",
       " array([[ 0.94539416,  0.0546059 ]], dtype=float32),\n",
       " array([[ 0.97888333,  0.02111669]], dtype=float32),\n",
       " array([[ 0.99224174,  0.00775825]], dtype=float32),\n",
       " array([[ 0.99178094,  0.00821904]], dtype=float32),\n",
       " array([[ 0.99352807,  0.00647188]], dtype=float32),\n",
       " array([[ 0.98882663,  0.01117334]], dtype=float32),\n",
       " array([[ 0.72201145,  0.27798852]], dtype=float32),\n",
       " array([[ 0.99244386,  0.0075561 ]], dtype=float32),\n",
       " array([[ 0.22944313,  0.77055687]], dtype=float32),\n",
       " array([[ 0.9752627 ,  0.02473734]], dtype=float32),\n",
       " array([[ 0.99730116,  0.0026989 ]], dtype=float32),\n",
       " array([[ 0.99756795,  0.00243197]], dtype=float32),\n",
       " array([[ 0.98406547,  0.0159345 ]], dtype=float32),\n",
       " array([[  9.99488950e-01,   5.11076185e-04]], dtype=float32),\n",
       " array([[ 0.99709272,  0.00290726]], dtype=float32),\n",
       " array([[ 0.99447733,  0.00552271]], dtype=float32),\n",
       " array([[ 0.7987783 ,  0.20122179]], dtype=float32),\n",
       " array([[  9.99219298e-01,   7.80670904e-04]], dtype=float32),\n",
       " array([[ 0.98854792,  0.01145208]], dtype=float32),\n",
       " array([[ 0.91897321,  0.08102676]], dtype=float32),\n",
       " array([[  9.99468148e-01,   5.31879137e-04]], dtype=float32),\n",
       " array([[ 0.95376343,  0.0462366 ]], dtype=float32),\n",
       " array([[ 0.9910897 ,  0.00891025]], dtype=float32),\n",
       " array([[ 0.9986456 ,  0.00135444]], dtype=float32),\n",
       " array([[ 0.97697383,  0.02302622]], dtype=float32),\n",
       " array([[ 0.36569533,  0.63430464]], dtype=float32),\n",
       " array([[  9.99214649e-01,   7.85273267e-04]], dtype=float32),\n",
       " array([[ 0.95427263,  0.04572741]], dtype=float32),\n",
       " array([[ 0.99423814,  0.00576185]], dtype=float32),\n",
       " array([[ 0.9978531,  0.0021469]], dtype=float32),\n",
       " array([[ 0.97213393,  0.02786606]], dtype=float32),\n",
       " array([[ 0.99155432,  0.00844564]], dtype=float32),\n",
       " array([[ 0.83905548,  0.16094458]], dtype=float32),\n",
       " array([[ 0.76998955,  0.23001049]], dtype=float32),\n",
       " array([[ 0.98907745,  0.01092261]], dtype=float32),\n",
       " array([[ 0.98653352,  0.01346646]], dtype=float32),\n",
       " array([[ 0.95210105,  0.04789899]], dtype=float32),\n",
       " array([[ 0.97934616,  0.02065391]], dtype=float32),\n",
       " array([[ 0.81290787,  0.18709214]], dtype=float32),\n",
       " array([[ 0.98527598,  0.01472399]], dtype=float32),\n",
       " array([[ 0.97888833,  0.02111165]], dtype=float32),\n",
       " array([[ 0.98548359,  0.01451637]], dtype=float32),\n",
       " array([[ 0.88180411,  0.11819586]], dtype=float32),\n",
       " array([[  9.99123633e-01,   8.76386999e-04]], dtype=float32),\n",
       " array([[ 0.9986307 ,  0.00136921]], dtype=float32),\n",
       " array([[  9.99523044e-01,   4.77005815e-04]], dtype=float32),\n",
       " array([[ 0.91838747,  0.08161259]], dtype=float32),\n",
       " array([[ 0.97430068,  0.02569927]], dtype=float32),\n",
       " array([[ 0.99793029,  0.00206967]], dtype=float32),\n",
       " array([[ 0.99718755,  0.0028125 ]], dtype=float32),\n",
       " array([[ 0.99880552,  0.00119454]], dtype=float32),\n",
       " array([[ 0.94610137,  0.05389856]], dtype=float32),\n",
       " array([[ 0.99529415,  0.00470586]], dtype=float32),\n",
       " array([[ 0.94453216,  0.05546789]], dtype=float32),\n",
       " array([[ 0.89476061,  0.1052394 ]], dtype=float32),\n",
       " array([[ 0.15212506,  0.84787488]], dtype=float32),\n",
       " array([[ 0.99875295,  0.00124702]], dtype=float32),\n",
       " array([[ 0.9546991 ,  0.04530085]], dtype=float32),\n",
       " array([[ 0.95636189,  0.04363811]], dtype=float32),\n",
       " array([[ 0.99783844,  0.0021616 ]], dtype=float32),\n",
       " array([[ 0.99475831,  0.00524168]], dtype=float32),\n",
       " array([[  9.99522448e-01,   4.77557187e-04]], dtype=float32),\n",
       " array([[ 0.99819142,  0.00180854]], dtype=float32),\n",
       " array([[ 0.96899563,  0.03100436]], dtype=float32),\n",
       " array([[ 0.99491453,  0.00508552]], dtype=float32),\n",
       " array([[ 0.99348456,  0.00651547]], dtype=float32),\n",
       " array([[ 0.99508023,  0.00491978]], dtype=float32),\n",
       " array([[ 0.9986608 ,  0.00133918]], dtype=float32),\n",
       " array([[ 0.88286883,  0.11713115]], dtype=float32),\n",
       " array([[ 0.99398094,  0.00601897]], dtype=float32),\n",
       " array([[ 0.99414462,  0.00585545]], dtype=float32),\n",
       " array([[ 0.99765801,  0.00234196]], dtype=float32),\n",
       " array([[ 0.98533624,  0.01466369]], dtype=float32),\n",
       " array([[ 0.98946255,  0.01053747]], dtype=float32),\n",
       " array([[ 0.9988656 ,  0.00113437]], dtype=float32),\n",
       " array([[ 0.99750924,  0.0024907 ]], dtype=float32),\n",
       " array([[ 0.99854326,  0.00145681]], dtype=float32),\n",
       " array([[ 0.99483669,  0.00516338]], dtype=float32),\n",
       " array([[  9.99162078e-01,   8.37875123e-04]], dtype=float32),\n",
       " array([[ 0.98374593,  0.01625404]], dtype=float32),\n",
       " array([[ 0.99750179,  0.00249817]], dtype=float32),\n",
       " array([[ 0.99513358,  0.00486641]], dtype=float32),\n",
       " array([[ 0.99813902,  0.00186091]], dtype=float32),\n",
       " array([[ 0.99623662,  0.00376345]], dtype=float32),\n",
       " array([[ 0.99764168,  0.00235833]], dtype=float32),\n",
       " array([[ 0.9942562 ,  0.00574376]], dtype=float32),\n",
       " array([[  9.99821484e-01,   1.78600196e-04]], dtype=float32),\n",
       " array([[ 0.99739909,  0.00260088]], dtype=float32),\n",
       " array([[ 0.99621177,  0.00378826]], dtype=float32),\n",
       " array([[ 0.98782271,  0.01217734]], dtype=float32),\n",
       " array([[ 0.68217903,  0.31782097]], dtype=float32),\n",
       " array([[ 0.99417937,  0.00582066]], dtype=float32),\n",
       " array([[ 0.99304706,  0.006953  ]], dtype=float32),\n",
       " array([[ 0.99672711,  0.00327292]], dtype=float32),\n",
       " array([[ 0.99549758,  0.00450248]], dtype=float32),\n",
       " array([[ 0.76335657,  0.23664343]], dtype=float32),\n",
       " array([[  9.99203503e-01,   7.96522363e-04]], dtype=float32),\n",
       " array([[ 0.98704588,  0.01295412]], dtype=float32),\n",
       " array([[ 0.99564528,  0.00435473]], dtype=float32),\n",
       " array([[ 0.99114734,  0.00885274]], dtype=float32),\n",
       " array([[  9.99080300e-01,   9.19718877e-04]], dtype=float32),\n",
       " array([[ 0.95310134,  0.04689868]], dtype=float32),\n",
       " array([[ 0.78573984,  0.21426016]], dtype=float32),\n",
       " array([[ 0.99098361,  0.00901637]], dtype=float32),\n",
       " array([[  9.99454200e-01,   5.45783609e-04]], dtype=float32),\n",
       " array([[ 0.98438525,  0.01561478]], dtype=float32),\n",
       " array([[ 0.99632543,  0.00367457]], dtype=float32),\n",
       " array([[ 0.98617262,  0.01382742]], dtype=float32),\n",
       " array([[ 0.99402678,  0.00597315]], dtype=float32),\n",
       " array([[ 0.96469861,  0.03530138]], dtype=float32),\n",
       " array([[ 0.98834062,  0.0116594 ]], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = []\n",
    "for i in file_list_true[0:200]:\n",
    "    a=np.load(i)\n",
    "    a=np.expand_dims(a,0)\n",
    "    a=np.expand_dims(a,0)\n",
    "    cc.append(model_pred.predict(a))\n",
    "count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755\n"
     ]
    }
   ],
   "source": [
    "for i in cc:\n",
    "    if i[0][1] > 0.9:\n",
    "        count += 1\n",
    "print count*1.0/len(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.35381708,  0.64618289]], dtype=float32),\n",
       " array([[ 0.3929517 ,  0.60704833]], dtype=float32),\n",
       " array([[ 0.0397889 ,  0.96021116]], dtype=float32),\n",
       " array([[ 0.0441843 ,  0.95581573]], dtype=float32),\n",
       " array([[ 0.04035529,  0.95964473]], dtype=float32),\n",
       " array([[ 0.10420643,  0.89579362]], dtype=float32),\n",
       " array([[ 0.03444644,  0.96555358]], dtype=float32),\n",
       " array([[ 0.01089699,  0.98910296]], dtype=float32),\n",
       " array([[  1.18041926e-05,   9.99988198e-01]], dtype=float32),\n",
       " array([[ 0.42278352,  0.57721645]], dtype=float32),\n",
       " array([[ 0.04140922,  0.95859081]], dtype=float32),\n",
       " array([[ 0.3540034 ,  0.64599657]], dtype=float32),\n",
       " array([[  3.08432733e-04,   9.99691606e-01]], dtype=float32),\n",
       " array([[  1.57752118e-04,   9.99842167e-01]], dtype=float32),\n",
       " array([[ 0.00519567,  0.99480432]], dtype=float32),\n",
       " array([[ 0.34400567,  0.65599436]], dtype=float32),\n",
       " array([[ 0.01286149,  0.98713845]], dtype=float32),\n",
       " array([[ 0.71489102,  0.28510895]], dtype=float32),\n",
       " array([[ 0.00100233,  0.99899763]], dtype=float32),\n",
       " array([[ 0.00113618,  0.99886382]], dtype=float32),\n",
       " array([[ 0.8792212 ,  0.12077878]], dtype=float32),\n",
       " array([[ 0.00580264,  0.99419737]], dtype=float32),\n",
       " array([[ 0.3583127 ,  0.64168727]], dtype=float32),\n",
       " array([[ 0.00117209,  0.99882787]], dtype=float32),\n",
       " array([[  1.34614666e-05,   9.99986529e-01]], dtype=float32),\n",
       " array([[  9.49302921e-05,   9.99905109e-01]], dtype=float32),\n",
       " array([[  4.01106343e-04,   9.99598920e-01]], dtype=float32),\n",
       " array([[ 0.51916307,  0.48083693]], dtype=float32),\n",
       " array([[ 0.15817916,  0.84182084]], dtype=float32),\n",
       " array([[ 0.00468739,  0.99531257]], dtype=float32),\n",
       " array([[  6.01077659e-07,   9.99999404e-01]], dtype=float32),\n",
       " array([[  1.54512290e-05,   9.99984503e-01]], dtype=float32),\n",
       " array([[  7.41070471e-05,   9.99925852e-01]], dtype=float32),\n",
       " array([[ 0.28161404,  0.71838599]], dtype=float32),\n",
       " array([[ 0.36625496,  0.63374501]], dtype=float32),\n",
       " array([[ 0.4688468,  0.5311532]], dtype=float32),\n",
       " array([[ 0.17078346,  0.82921654]], dtype=float32),\n",
       " array([[ 0.16224648,  0.83775353]], dtype=float32),\n",
       " array([[ 0.17381789,  0.82618213]], dtype=float32),\n",
       " array([[ 0.00256734,  0.99743265]], dtype=float32),\n",
       " array([[  9.84215643e-04,   9.99015808e-01]], dtype=float32),\n",
       " array([[ 0.01563251,  0.98436755]], dtype=float32),\n",
       " array([[ 0.00312463,  0.99687541]], dtype=float32),\n",
       " array([[ 0.00339614,  0.99660385]], dtype=float32),\n",
       " array([[ 0.27254671,  0.72745329]], dtype=float32),\n",
       " array([[ 0.03466511,  0.96533495]], dtype=float32),\n",
       " array([[ 0.0012174 ,  0.99878258]], dtype=float32),\n",
       " array([[ 0.0186103,  0.9813897]], dtype=float32),\n",
       " array([[  2.52161826e-05,   9.99974728e-01]], dtype=float32),\n",
       " array([[  3.93578957e-05,   9.99960661e-01]], dtype=float32),\n",
       " array([[  1.76167523e-04,   9.99823868e-01]], dtype=float32),\n",
       " array([[ 0.72907001,  0.27092999]], dtype=float32),\n",
       " array([[ 0.76191765,  0.23808239]], dtype=float32),\n",
       " array([[  4.01594152e-04,   9.99598444e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[ 0.00111331,  0.99888676]], dtype=float32),\n",
       " array([[ 0.00156378,  0.99843615]], dtype=float32),\n",
       " array([[  7.91108527e-04,   9.99208868e-01]], dtype=float32),\n",
       " array([[  3.02963999e-05,   9.99969721e-01]], dtype=float32),\n",
       " array([[  3.49378242e-05,   9.99965072e-01]], dtype=float32),\n",
       " array([[  6.52756935e-05,   9.99934673e-01]], dtype=float32),\n",
       " array([[ 0.03559033,  0.96440965]], dtype=float32),\n",
       " array([[ 0.00409897,  0.99590105]], dtype=float32),\n",
       " array([[ 0.51016206,  0.48983791]], dtype=float32),\n",
       " array([[ 0.08309805,  0.91690201]], dtype=float32),\n",
       " array([[ 0.00154924,  0.99845076]], dtype=float32),\n",
       " array([[ 0.66585177,  0.3341482 ]], dtype=float32),\n",
       " array([[  4.39308642e-04,   9.99560654e-01]], dtype=float32),\n",
       " array([[ 0.00666066,  0.99333936]], dtype=float32),\n",
       " array([[ 0.01128719,  0.98871279]], dtype=float32),\n",
       " array([[ 0.1466929 ,  0.85330713]], dtype=float32),\n",
       " array([[  3.00685730e-04,   9.99699354e-01]], dtype=float32),\n",
       " array([[ 0.02302566,  0.97697443]], dtype=float32),\n",
       " array([[ 0.51022214,  0.48977789]], dtype=float32),\n",
       " array([[ 0.10739172,  0.89260834]], dtype=float32),\n",
       " array([[ 0.05286187,  0.94713813]], dtype=float32),\n",
       " array([[ 0.0084503 ,  0.99154973]], dtype=float32),\n",
       " array([[  3.13695666e-04,   9.99686360e-01]], dtype=float32),\n",
       " array([[ 0.0644346 ,  0.93556541]], dtype=float32),\n",
       " array([[ 0.00749999,  0.99250001]], dtype=float32),\n",
       " array([[ 0.04971428,  0.95028567]], dtype=float32),\n",
       " array([[ 0.00199776,  0.99800223]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[  3.85451358e-06,   9.99996185e-01]], dtype=float32),\n",
       " array([[ 0.60272592,  0.39727405]], dtype=float32),\n",
       " array([[ 0.29059997,  0.70940006]], dtype=float32),\n",
       " array([[ 0.0021218 ,  0.99787819]], dtype=float32),\n",
       " array([[  3.32743657e-05,   9.99966741e-01]], dtype=float32),\n",
       " array([[  5.33509810e-05,   9.99946594e-01]], dtype=float32),\n",
       " array([[  1.04783110e-04,   9.99895215e-01]], dtype=float32),\n",
       " array([[  2.97853956e-04,   9.99702156e-01]], dtype=float32),\n",
       " array([[  3.53546580e-04,   9.99646425e-01]], dtype=float32),\n",
       " array([[  1.25743332e-04,   9.99874234e-01]], dtype=float32),\n",
       " array([[ 0.02166355,  0.97833645]], dtype=float32),\n",
       " array([[ 0.02325323,  0.9767468 ]], dtype=float32),\n",
       " array([[ 0.02940571,  0.97059435]], dtype=float32),\n",
       " array([[ 0.04844042,  0.9515596 ]], dtype=float32),\n",
       " array([[ 0.04996922,  0.95003074]], dtype=float32),\n",
       " array([[ 0.01899224,  0.98100775]], dtype=float32),\n",
       " array([[ 0.03645546,  0.96354455]], dtype=float32),\n",
       " array([[ 0.06119795,  0.938802  ]], dtype=float32),\n",
       " array([[ 0.05496366,  0.94503629]], dtype=float32),\n",
       " array([[ 0.00646374,  0.99353623]], dtype=float32),\n",
       " array([[  1.97404748e-04,   9.99802649e-01]], dtype=float32),\n",
       " array([[  5.86254137e-05,   9.99941349e-01]], dtype=float32),\n",
       " array([[ 0.0347667 ,  0.96523327]], dtype=float32),\n",
       " array([[ 0.08007529,  0.91992474]], dtype=float32),\n",
       " array([[ 0.02978193,  0.97021806]], dtype=float32),\n",
       " array([[ 0.07349191,  0.92650807]], dtype=float32),\n",
       " array([[ 0.00381301,  0.99618703]], dtype=float32),\n",
       " array([[  7.28139130e-04,   9.99271810e-01]], dtype=float32),\n",
       " array([[ 0.58870411,  0.41129589]], dtype=float32),\n",
       " array([[ 0.11232588,  0.88767409]], dtype=float32),\n",
       " array([[ 0.30864045,  0.69135952]], dtype=float32),\n",
       " array([[ 0.00702148,  0.99297851]], dtype=float32),\n",
       " array([[ 0.0110521 ,  0.98894787]], dtype=float32),\n",
       " array([[  8.14565283e-04,   9.99185383e-01]], dtype=float32),\n",
       " array([[ 0.00219183,  0.99780816]], dtype=float32),\n",
       " array([[  9.35694610e-04,   9.99064267e-01]], dtype=float32),\n",
       " array([[  5.69516669e-05,   9.99943018e-01]], dtype=float32),\n",
       " array([[ 0.69182557,  0.3081744 ]], dtype=float32),\n",
       " array([[ 0.60873139,  0.39126864]], dtype=float32),\n",
       " array([[ 0.83542812,  0.16457185]], dtype=float32),\n",
       " array([[  8.19040695e-04,   9.99180973e-01]], dtype=float32),\n",
       " array([[ 0.00111514,  0.99888486]], dtype=float32),\n",
       " array([[  1.21718302e-04,   9.99878287e-01]], dtype=float32),\n",
       " array([[ 0.11589549,  0.88410449]], dtype=float32),\n",
       " array([[ 0.25108698,  0.74891305]], dtype=float32),\n",
       " array([[ 0.0314208 ,  0.96857923]], dtype=float32),\n",
       " array([[ 0.1686843,  0.8313157]], dtype=float32),\n",
       " array([[ 0.42971525,  0.57028472]], dtype=float32),\n",
       " array([[ 0.02697514,  0.9730249 ]], dtype=float32),\n",
       " array([[  4.98116751e-05,   9.99950171e-01]], dtype=float32),\n",
       " array([[  5.37637334e-07,   9.99999404e-01]], dtype=float32),\n",
       " array([[ 0.00686703,  0.99313301]], dtype=float32),\n",
       " array([[ 0.07582171,  0.92417824]], dtype=float32),\n",
       " array([[ 0.05708651,  0.94291347]], dtype=float32),\n",
       " array([[  1.60308227e-05,   9.99984026e-01]], dtype=float32),\n",
       " array([[ 0.37665197,  0.623348  ]], dtype=float32),\n",
       " array([[ 0.04472722,  0.95527285]], dtype=float32),\n",
       " array([[ 0.18307172,  0.81692833]], dtype=float32),\n",
       " array([[  6.07760558e-05,   9.99939203e-01]], dtype=float32),\n",
       " array([[  1.09923221e-05,   9.99989033e-01]], dtype=float32),\n",
       " array([[  4.44852503e-07,   9.99999523e-01]], dtype=float32),\n",
       " array([[  6.12567703e-04,   9.99387383e-01]], dtype=float32),\n",
       " array([[  8.01690840e-06,   9.99992013e-01]], dtype=float32),\n",
       " array([[ 0.00304781,  0.99695218]], dtype=float32),\n",
       " array([[ 0.01471323,  0.98528671]], dtype=float32),\n",
       " array([[ 0.01471323,  0.98528671]], dtype=float32),\n",
       " array([[ 0.01471323,  0.98528671]], dtype=float32),\n",
       " array([[ 0.02163037,  0.97836965]], dtype=float32),\n",
       " array([[ 0.01830521,  0.98169476]], dtype=float32),\n",
       " array([[ 0.01791678,  0.9820832 ]], dtype=float32),\n",
       " array([[ 0.01471323,  0.98528671]], dtype=float32),\n",
       " array([[ 0.01471323,  0.98528671]], dtype=float32),\n",
       " array([[ 0.01471323,  0.98528671]], dtype=float32),\n",
       " array([[ 0.11965239,  0.88034761]], dtype=float32),\n",
       " array([[ 0.00519777,  0.99480224]], dtype=float32),\n",
       " array([[ 0.00580151,  0.99419844]], dtype=float32),\n",
       " array([[ 0.40024945,  0.59975058]], dtype=float32),\n",
       " array([[ 0.34283906,  0.65716094]], dtype=float32),\n",
       " array([[ 0.95497781,  0.04502217]], dtype=float32),\n",
       " array([[ 0.19692342,  0.80307657]], dtype=float32),\n",
       " array([[ 0.63673848,  0.36326146]], dtype=float32),\n",
       " array([[ 0.00230676,  0.99769324]], dtype=float32),\n",
       " array([[ 0.3650437,  0.6349563]], dtype=float32),\n",
       " array([[ 0.87090087,  0.12909912]], dtype=float32),\n",
       " array([[  6.96851857e-05,   9.99930263e-01]], dtype=float32),\n",
       " array([[  2.59711469e-05,   9.99974012e-01]], dtype=float32),\n",
       " array([[  1.21434969e-05,   9.99987841e-01]], dtype=float32),\n",
       " array([[  3.19327155e-05,   9.99968052e-01]], dtype=float32),\n",
       " array([[  8.90624942e-05,   9.99910951e-01]], dtype=float32),\n",
       " array([[  2.49184200e-06,   9.99997497e-01]], dtype=float32),\n",
       " array([[ 0.49091649,  0.50908351]], dtype=float32),\n",
       " array([[ 0.44286641,  0.55713356]], dtype=float32),\n",
       " array([[ 0.00527248,  0.99472755]], dtype=float32),\n",
       " array([[ 0.00263479,  0.99736518]], dtype=float32),\n",
       " array([[  4.13315320e-07,   9.99999642e-01]], dtype=float32),\n",
       " array([[  8.08794994e-07,   9.99999166e-01]], dtype=float32),\n",
       " array([[  3.08276758e-05,   9.99969125e-01]], dtype=float32),\n",
       " array([[  1.38444250e-07,   9.99999881e-01]], dtype=float32),\n",
       " array([[  4.02722799e-06,   9.99995947e-01]], dtype=float32),\n",
       " array([[  2.27587207e-05,   9.99977231e-01]], dtype=float32),\n",
       " array([[ 0.08459692,  0.91540307]], dtype=float32),\n",
       " array([[ 0.00372947,  0.99627054]], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
