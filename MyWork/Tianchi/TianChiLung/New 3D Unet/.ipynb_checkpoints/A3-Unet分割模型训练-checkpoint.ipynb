{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import skimage, os\n",
    "import SimpleITK as sitk\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import zarr\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th') \n",
    "\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Input, merge, UpSampling2D\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D, UpSampling3D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.core import SpatialDropout3D\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils_3d import *\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unet_model():\n",
    "    \n",
    "    inputs = Input(shape=(1, max_slices, img_size, img_size))\n",
    "    conv1 = Convolution3D(width, 3, 3, 3, activation = 'relu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(width*2, 3, 3, 3, activation = 'relu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2), strides = (2, 2, 2), border_mode='same')(conv1)\n",
    "    \n",
    "    conv2 = Convolution3D(width*2, 3, 3, 3, activation = 'relu', border_mode='same')(pool1)\n",
    "    conv2 = BatchNormalization(axis = 1)(conv2)\n",
    "    conv2 = Convolution3D(width*4, 3, 3, 3, activation = 'relu', border_mode='same')(conv2)\n",
    "    conv2 = BatchNormalization(axis = 1)(conv2)\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2), strides = (2, 2, 2), border_mode='same')(conv2)\n",
    "\n",
    "    conv3 = Convolution3D(width*4, 3, 3, 3, activation = 'relu', border_mode='same')(pool2)\n",
    "    conv3 = BatchNormalization(axis = 1)(conv3)\n",
    "    conv3 = Convolution3D(width*8, 3, 3, 3, activation = 'relu', border_mode='same')(conv3)\n",
    "    conv3 = BatchNormalization(axis = 1)(conv3)\n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2), strides = (2, 2, 2), border_mode='same')(conv3)\n",
    "    \n",
    "    conv4 = Convolution3D(width*8, 3, 3, 3, activation = 'relu', border_mode='same')(pool3)\n",
    "    conv4 = BatchNormalization(axis = 1)(conv4)\n",
    "    conv4 = Convolution3D(width*8, 3, 3, 3, activation = 'relu', border_mode='same')(conv4)\n",
    "    conv4 = BatchNormalization(axis = 1)(conv4)\n",
    "    conv4 = Convolution3D(width*16, 3, 3, 3, activation = 'relu', border_mode='same')(conv4)\n",
    "    conv4 = BatchNormalization(axis = 1)(conv4)\n",
    "\n",
    "    up5 = merge([UpSampling3D(size=(2, 2, 2))(conv4), conv3], mode='concat', concat_axis=1)\n",
    "    conv5 = SpatialDropout3D(dropout_rate)(up5)\n",
    "    conv5 = Convolution3D(width*8, 3, 3, 3, activation = 'relu', border_mode='same')(conv5)\n",
    "    conv5 = Convolution3D(width*8, 3, 3, 3, activation = 'relu', border_mode='same')(conv5)\n",
    "    \n",
    "    up6 = merge([UpSampling3D(size=(2, 2, 2))(conv5), conv2], mode='concat', concat_axis=1)\n",
    "    conv6 = SpatialDropout3D(dropout_rate)(up6)\n",
    "    conv6 = Convolution3D(width*4, 3, 3, 3, activation = 'relu', border_mode='same')(conv6)\n",
    "    conv6 = Convolution3D(width*4, 3, 3, 3, activation = 'relu', border_mode='same')(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling3D(size=(2, 2, 2))(conv6), conv1], mode='concat', concat_axis=1)\n",
    "    conv7 = SpatialDropout3D(dropout_rate)(up7)\n",
    "    conv7 = Convolution3D(width*2, 3, 3, 3, activation = 'relu', border_mode='same')(conv7)\n",
    "    conv7 = Convolution3D(width*2, 3, 3, 3, activation = 'relu', border_mode='same')(conv7)\n",
    "    conv8 = Convolution3D(1, 1, 1, 1, activation='sigmoid')(conv7)\n",
    "\n",
    "    model = Model(input=inputs, output=conv8)\n",
    "    model.compile(optimizer=Adam(lr=1e-5), \n",
    "                  loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_train(start, end, seed = None):\n",
    "    lung = sorted(glob.glob(src + 'lung_mask_rand/*.npy'))[start:end]\n",
    "    nod = sorted(glob.glob(src + 'nodule_mask_rand/*.npy'))[start:end]    \n",
    "    while True:\n",
    "        print('Shuffling data')\n",
    "        lung, nod = shuffle(lung, nod)\n",
    "        for i in range(len(lung)):            \n",
    "            lungs = np.load(lung[i]).astype('float32')\n",
    "            nods = np.load(nod[i]).astype('float32')\n",
    "            lungs = np.expand_dims(lungs,0)\n",
    "            nods = np.expand_dims(nods,0)  \n",
    "            lungs = np.expand_dims(lungs,0)\n",
    "            nods = np.expand_dims(nods,0)\n",
    "            yield(lungs, nods)\n",
    "\n",
    "            \n",
    "def generate_val(start, end, seed = None):\n",
    "\n",
    "    lung = sorted(glob.glob(src + 'lung_mask_rand/*.npy'))[start:end]\n",
    "    nod = sorted(glob.glob(src + 'nodule_mask_rand/*.npy'))[start:end]\n",
    "    while True:\n",
    "        for i in range(len(lung)):            \n",
    "            lungs = np.load(lung[i]).astype('float32')\n",
    "            nods = np.load(nod[i]).astype('float32')  \n",
    "            lungs = np.expand_dims(lungs,0)\n",
    "            nods = np.expand_dims(nods,0)\n",
    "            lungs = np.expand_dims(lungs,0)\n",
    "            nods = np.expand_dims(nods,0)\n",
    "            yield(lungs, nods)\n",
    "\n",
    "\n",
    "\n",
    "def unet_fit(name, start_t, end_t, start_v, end_v, check_name = None):\n",
    "    \n",
    "    t = time.time()\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience = 15, \n",
    "                                   verbose = 1),\n",
    "    ModelCheckpoint('/Volumes/solo/ali/Data/model/{}.h5'.format(name), \n",
    "                        monitor='val_loss', \n",
    "                        verbose = 0, save_best_only = True)]\n",
    "    \n",
    "    if check_name is not None:\n",
    "        check_model = '/Volumes/solo/ali/Data/model/{}.h5'.format(check_name)\n",
    "        model = load_model(check_model, \n",
    "                           custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})\n",
    "    else:\n",
    "        model = unet_model()\n",
    "\n",
    "    model.fit_generator(generate_train(start_t, end_t), nb_epoch = 200, verbose = 1, \n",
    "                        validation_data = generate_val(start_v, end_v), \n",
    "                        callbacks = callbacks,\n",
    "                        samples_per_epoch = 2000, nb_val_samples = 300)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Shuffling data\n",
      "490/500 [============================>.] - ETA: 14s - loss: -0.5744 - dice_coef: 0.5744Shuffling data\n",
      "500/500 [==============================] - 974s - loss: -0.5747 - dice_coef: 0.5747 - val_loss: -0.7290 - val_dice_coef: 0.7290\n",
      "Epoch 2/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -0.7195 - dice_coef: 0.7195Shuffling data\n",
      "500/500 [==============================] - 957s - loss: -0.7156 - dice_coef: 0.7156 - val_loss: -0.8001 - val_dice_coef: 0.8001\n",
      "Epoch 3/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -0.8088 - dice_coef: 0.8088Shuffling data\n",
      "500/500 [==============================] - 959s - loss: -0.8065 - dice_coef: 0.8065 - val_loss: -0.8215 - val_dice_coef: 0.8215\n",
      "Epoch 4/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -0.8538 - dice_coef: 0.8538Shuffling data\n",
      "500/500 [==============================] - 963s - loss: -0.8515 - dice_coef: 0.8515 - val_loss: -0.8331 - val_dice_coef: 0.8331\n",
      "Epoch 5/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -0.9046 - dice_coef: 0.9046Shuffling data\n",
      "500/500 [==============================] - 961s - loss: -0.9051 - dice_coef: 0.9051 - val_loss: -0.8406 - val_dice_coef: 0.8406\n",
      "Epoch 6/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -0.9469 - dice_coef: 0.9469Shuffling data\n",
      "500/500 [==============================] - 957s - loss: -0.9536 - dice_coef: 0.9536 - val_loss: -0.8314 - val_dice_coef: 0.8314\n",
      "Epoch 7/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.0048 - dice_coef: 1.0048Shuffling data\n",
      "500/500 [==============================] - 960s - loss: -1.0024 - dice_coef: 1.0024 - val_loss: -0.8545 - val_dice_coef: 0.8545\n",
      "Epoch 8/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.0162 - dice_coef: 1.0162Shuffling data\n",
      "500/500 [==============================] - 965s - loss: -1.0165 - dice_coef: 1.0165 - val_loss: -0.8458 - val_dice_coef: 0.8458\n",
      "Epoch 9/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -1.0387 - dice_coef: 1.0387Shuffling data\n",
      "500/500 [==============================] - 972s - loss: -1.0414 - dice_coef: 1.0414 - val_loss: -0.8303 - val_dice_coef: 0.8303\n",
      "Epoch 10/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -1.0867 - dice_coef: 1.0867Shuffling data\n",
      "500/500 [==============================] - 961s - loss: -1.0899 - dice_coef: 1.0899 - val_loss: -0.8497 - val_dice_coef: 0.8497\n",
      "Epoch 11/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.1183 - dice_coef: 1.1183Shuffling data\n",
      "500/500 [==============================] - 967s - loss: -1.1202 - dice_coef: 1.1202 - val_loss: -0.8706 - val_dice_coef: 0.8706\n",
      "Epoch 12/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.1625 - dice_coef: 1.1625Shuffling data\n",
      "500/500 [==============================] - 966s - loss: -1.1583 - dice_coef: 1.1583 - val_loss: -0.8889 - val_dice_coef: 0.8889\n",
      "Epoch 13/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -1.1755 - dice_coef: 1.1755Shuffling data\n",
      "500/500 [==============================] - 959s - loss: -1.1748 - dice_coef: 1.1748 - val_loss: -0.9107 - val_dice_coef: 0.9107\n",
      "Epoch 14/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.2449 - dice_coef: 1.2449Shuffling data\n",
      "500/500 [==============================] - 967s - loss: -1.2366 - dice_coef: 1.2366 - val_loss: -0.9011 - val_dice_coef: 0.9011\n",
      "Epoch 15/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -1.2553 - dice_coef: 1.2553Shuffling data\n",
      "500/500 [==============================] - 960s - loss: -1.2556 - dice_coef: 1.2556 - val_loss: -0.9045 - val_dice_coef: 0.9045\n",
      "Epoch 16/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -1.2750 - dice_coef: 1.2750Shuffling data\n",
      "500/500 [==============================] - 961s - loss: -1.2794 - dice_coef: 1.2794 - val_loss: -0.7505 - val_dice_coef: 0.7505\n",
      "Epoch 17/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -1.2957 - dice_coef: 1.2957Shuffling data\n",
      "500/500 [==============================] - 963s - loss: -1.2978 - dice_coef: 1.2978 - val_loss: -0.9420 - val_dice_coef: 0.9420\n",
      "Epoch 18/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.3441 - dice_coef: 1.3441Shuffling data\n",
      "500/500 [==============================] - 961s - loss: -1.3397 - dice_coef: 1.3397 - val_loss: -0.9287 - val_dice_coef: 0.9287\n",
      "Epoch 19/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -1.3527 - dice_coef: 1.3527Shuffling data\n",
      "500/500 [==============================] - 957s - loss: -1.3518 - dice_coef: 1.3518 - val_loss: -0.8994 - val_dice_coef: 0.8994\n",
      "Epoch 20/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -1.3687 - dice_coef: 1.3687Shuffling data\n",
      "500/500 [==============================] - 959s - loss: -1.3643 - dice_coef: 1.3643 - val_loss: -0.8707 - val_dice_coef: 0.8707\n",
      "Epoch 21/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -1.4013 - dice_coef: 1.4013Shuffling data\n",
      "500/500 [==============================] - 961s - loss: -1.4078 - dice_coef: 1.4078 - val_loss: -0.9208 - val_dice_coef: 0.9208\n",
      "Epoch 22/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.4237 - dice_coef: 1.4237Shuffling data\n",
      "500/500 [==============================] - 965s - loss: -1.4196 - dice_coef: 1.4196 - val_loss: -0.8350 - val_dice_coef: 0.8350\n",
      "Epoch 23/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.4399 - dice_coef: 1.4399Shuffling data\n",
      "500/500 [==============================] - 962s - loss: -1.4386 - dice_coef: 1.4386 - val_loss: -0.9543 - val_dice_coef: 0.9543\n",
      "Epoch 24/30\n",
      "490/500 [============================>.] - ETA: 14s - loss: -1.4796 - dice_coef: 1.4796Shuffling data\n",
      "500/500 [==============================] - 969s - loss: -1.4750 - dice_coef: 1.4750 - val_loss: -0.9007 - val_dice_coef: 0.9007\n",
      "Epoch 25/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.4927 - dice_coef: 1.4927Shuffling data\n",
      "500/500 [==============================] - 966s - loss: -1.4940 - dice_coef: 1.4940 - val_loss: -0.9188 - val_dice_coef: 0.9188\n",
      "Epoch 26/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.5321 - dice_coef: 1.5321Shuffling data\n",
      "500/500 [==============================] - 966s - loss: -1.5348 - dice_coef: 1.5348 - val_loss: -1.0049 - val_dice_coef: 1.0049\n",
      "Epoch 27/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.5141 - dice_coef: 1.5141Shuffling data\n",
      "500/500 [==============================] - 971s - loss: -1.5118 - dice_coef: 1.5118 - val_loss: -0.9379 - val_dice_coef: 0.9379\n",
      "Epoch 28/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.5415 - dice_coef: 1.5415Shuffling data\n",
      "500/500 [==============================] - 948s - loss: -1.5368 - dice_coef: 1.5368 - val_loss: -0.9661 - val_dice_coef: 0.9661\n",
      "Epoch 29/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.5545 - dice_coef: 1.5545Shuffling data\n",
      "500/500 [==============================] - 941s - loss: -1.5568 - dice_coef: 1.5568 - val_loss: -0.8839 - val_dice_coef: 0.8839\n",
      "Epoch 30/30\n",
      "490/500 [============================>.] - ETA: 13s - loss: -1.5734 - dice_coef: 1.5734Shuffling data\n",
      "500/500 [==============================] - 943s - loss: -1.5768 - dice_coef: 1.5768 - val_loss: -0.9489 - val_dice_coef: 0.9489\n"
     ]
    }
   ],
   "source": [
    "src = mask_val\n",
    "max_slices = 64\n",
    "img_size = 64\n",
    "dropout_rate = 0.5\n",
    "width = 8\n",
    "\n",
    "img_rows = img_size\n",
    "img_cols = img_size\n",
    "\n",
    "\n",
    "#unet_fit('3DUNet_genfulldata_patients_merged', 0, 551, 551, 601)\n",
    "unet_fit('final_fenge', 0, 2000,2000,2300,'final_fenge')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
