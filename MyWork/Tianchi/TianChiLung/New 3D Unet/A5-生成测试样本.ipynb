{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahui/anaconda/lib/python2.7/site-packages/dicom/__init__.py:53: UserWarning: \n",
      "This code is using an older version of pydicom, which is no longer \n",
      "maintained as of Jan 2017.  You can access the new pydicom features and API \n",
      "by installing `pydicom` from PyPI.\n",
      "See 'Transitioning to pydicom 1.x' section at pydicom.readthedocs.org \n",
      "for more information.\n",
      "\n",
      "  warnings.warn(msg)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import skimage, os\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from scipy import ndimage\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import dicom\n",
    "import scipy.misc\n",
    "\n",
    "from skimage import measure, morphology, segmentation\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from numba import autojit\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th') \n",
    "\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Input, merge, UpSampling2D\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D, UpSampling3D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.core import SpatialDropout3D\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils_3d import *\n",
    "from paths import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unet_model():\n",
    "    \n",
    "    inputs = Input(shape=(1, max_slices, img_size, img_size))\n",
    "    conv1 = Convolution3D(width, 3, 3, 3, activation = 'relu', border_mode='same')(inputs)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    conv1 = Convolution3D(width*2, 3, 3, 3, activation = 'relu', border_mode='same')(conv1)\n",
    "    conv1 = BatchNormalization(axis = 1)(conv1)\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2), strides = (2, 2, 2), border_mode='same')(conv1)\n",
    "    \n",
    "    conv2 = Convolution3D(width*2, 3, 3, 3, activation = 'relu', border_mode='same')(pool1)\n",
    "    conv2 = BatchNormalization(axis = 1)(conv2)\n",
    "    conv2 = Convolution3D(width*4, 3, 3, 3, activation = 'relu', border_mode='same')(conv2)\n",
    "    conv2 = BatchNormalization(axis = 1)(conv2)\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2), strides = (2, 2, 2), border_mode='same')(conv2)\n",
    "\n",
    "    conv3 = Convolution3D(width*4, 3, 3, 3, activation = 'relu', border_mode='same')(pool2)\n",
    "    conv3 = BatchNormalization(axis = 1)(conv3)\n",
    "    conv3 = Convolution3D(width*8, 3, 3, 3, activation = 'relu', border_mode='same')(conv3)\n",
    "    conv3 = BatchNormalization(axis = 1)(conv3)\n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2), strides = (2, 2, 2), border_mode='same')(conv3)\n",
    "    \n",
    "    conv4 = Convolution3D(width*8, 3, 3, 3, activation = 'relu', border_mode='same')(pool3)\n",
    "    conv4 = BatchNormalization(axis = 1)(conv4)\n",
    "    conv4 = Convolution3D(width*8, 3, 3, 3, activation = 'relu', border_mode='same')(conv4)\n",
    "    conv4 = BatchNormalization(axis = 1)(conv4)\n",
    "    conv4 = Convolution3D(width*16, 3, 3, 3, activation = 'relu', border_mode='same')(conv4)\n",
    "    conv4 = BatchNormalization(axis = 1)(conv4)\n",
    "\n",
    "    up5 = merge([UpSampling3D(size=(2, 2, 2))(conv4), conv3], mode='concat', concat_axis=1)\n",
    "    conv5 = SpatialDropout3D(dropout_rate)(up5)\n",
    "    conv5 = Convolution3D(width*8, 3, 3, 3, activation = 'relu', border_mode='same')(conv5)\n",
    "    conv5 = Convolution3D(width*8, 3, 3, 3, activation = 'relu', border_mode='same')(conv5)\n",
    "    \n",
    "    up6 = merge([UpSampling3D(size=(2, 2, 2))(conv5), conv2], mode='concat', concat_axis=1)\n",
    "    conv6 = SpatialDropout3D(dropout_rate)(up6)\n",
    "    conv6 = Convolution3D(width*4, 3, 3, 3, activation = 'relu', border_mode='same')(conv6)\n",
    "    conv6 = Convolution3D(width*4, 3, 3, 3, activation = 'relu', border_mode='same')(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling3D(size=(2, 2, 2))(conv6), conv1], mode='concat', concat_axis=1)\n",
    "    conv7 = SpatialDropout3D(dropout_rate)(up7)\n",
    "    conv7 = Convolution3D(width*2, 3, 3, 3, activation = 'relu', border_mode='same')(conv7)\n",
    "    conv7 = Convolution3D(width*2, 3, 3, 3, activation = 'relu', border_mode='same')(conv7)\n",
    "    conv8 = Convolution3D(1, 1, 1, 1, activation='sigmoid')(conv7)\n",
    "\n",
    "    model = Model(input=inputs, output=conv8)\n",
    "    model.compile(optimizer=Adam(lr=1e-5), \n",
    "                  loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    return model\n",
    "\n",
    "\n",
    "def segment_HU_scan_ira(x, threshold=-350, min_area=300):\n",
    "    mask = np.asarray(x < threshold, dtype='int8')\n",
    "\n",
    "    for zi in xrange(mask.shape[0]):\n",
    "        skimage.segmentation.clear_border(mask[zi, :, :], in_place=True)\n",
    "\n",
    "    # noise reduction\n",
    "    mask = skimage.morphology.binary_opening(mask, skimage.morphology.cube(2))\n",
    "    mask = np.asarray(mask, dtype='int8')\n",
    "\n",
    "    # label regions\n",
    "    label_image = skimage.measure.label(mask)\n",
    "    region_props = skimage.measure.regionprops(label_image)\n",
    "    sorted_regions = sorted(region_props, key=lambda x: x.area, reverse=True)\n",
    "    lung_label = sorted_regions[0].label\n",
    "    lung_mask = np.asarray((label_image == lung_label), dtype='int8')\n",
    "\n",
    "    # convex hull mask\n",
    "    lung_mask_convex = np.zeros_like(lung_mask)\n",
    "    for i in range(lung_mask.shape[2]):\n",
    "        if np.any(lung_mask[:, :, i]):\n",
    "            lung_mask_convex[:, :, i] = skimage.morphology.convex_hull_image(lung_mask[:, :, i])\n",
    "\n",
    "    # old mask inside the convex hull\n",
    "    mask *= lung_mask_convex\n",
    "    label_image = skimage.measure.label(mask)\n",
    "    region_props = skimage.measure.regionprops(label_image)\n",
    "    sorted_regions = sorted(region_props, key=lambda x: x.area, reverse=True)\n",
    "\n",
    "    for r in sorted_regions[1:]:\n",
    "        if r.area > min_area:\n",
    "            # make an image only containing that region\n",
    "            label_image_r = label_image == r.label\n",
    "            # grow the mask\n",
    "            label_image_r = scipy.ndimage.binary_dilation(label_image_r,\n",
    "                                                          structure=scipy.ndimage.generate_binary_structure(3, 2))\n",
    "            # compute the overlap with true lungs\n",
    "            overlap = label_image_r * lung_mask\n",
    "            if not np.any(overlap):\n",
    "                for i in range(label_image_r.shape[0]):\n",
    "                    if np.any(label_image_r[i]):\n",
    "                        label_image_r[i] = skimage.morphology.convex_hull_image(label_image_r[i])\n",
    "                lung_mask_convex *= 1 - label_image_r\n",
    "\n",
    "    return lung_mask_convex\n",
    "\n",
    "def img_edge(i,shape):\n",
    "    if i == (shape//128):\n",
    "        x_max = shape - (shape//128)*128\n",
    "    else:\n",
    "        x_max = i*128+128\n",
    "    return x_max\n",
    "\n",
    "def load_train():\n",
    "    data_path = src\n",
    "    folders = [x for x in os.listdir(data_path) if 'subset' in x]\n",
    "    os.chdir(data_path)\n",
    "    patients = []\n",
    "    \n",
    "    for i in folders:\n",
    "        os.chdir(data_path + i)\n",
    "        #print('Changing folder to: {}'.format(data_path + i))\n",
    "        patient_ids = [x for x in os.listdir(data_path + i) if '.mhd' in x]\n",
    "        for id in patient_ids:\n",
    "            j = '{}/{}'.format(i, id)\n",
    "            patients.append(j)\n",
    "    return patients\n",
    "                       \n",
    "def load_itk(filename):\n",
    "    itkimage = sitk.ReadImage(filename)\n",
    "    numpyImage = sitk.GetArrayFromImage(itkimage)\n",
    "    numpyOrigin = np.array(list(reversed(itkimage.GetOrigin())))\n",
    "    numpySpacing = np.array(list(reversed(itkimage.GetSpacing())))\n",
    "    return numpyImage, numpyOrigin, numpySpacing\n",
    "\n",
    "def world_2_voxel(world_coordinates, origin, spacing):\n",
    "    stretched_voxel_coordinates = np.absolute(world_coordinates - origin)\n",
    "    voxel_coordinates = stretched_voxel_coordinates / spacing\n",
    "    return voxel_coordinates\n",
    "\n",
    "def voxel_2_world(voxel_coordinates, origin, spacing):\n",
    "    stretched_voxel_coordinates = voxel_coordinates * spacing\n",
    "    world_coordinates = stretched_voxel_coordinates + origin\n",
    "    return world_coordinates\n",
    "\n",
    "def get_pixels_hu(image):\n",
    "    image = image.astype(np.int16)\n",
    "    image[image == threshold_min] = 0\n",
    "    return np.array(image, dtype=np.int16)\n",
    "\n",
    "\n",
    "def pred_for_test_watershed(img_file, save = True):         \n",
    "\n",
    "    def save_result(temp):\n",
    "        var = []\n",
    "        temp = skimage.morphology.binary_opening(np.squeeze(temp),np.ones([5,5,5]))\n",
    "        labels = measure.label(np.squeeze(temp))\n",
    "        props = regionprops(labels)\n",
    "        for point_ in range(len(props)):\n",
    "            if props[point_]['EquivDiameter'] < 30 and props[point_]['EquivDiameter'] >5 :\n",
    "                \n",
    "    \n",
    "                z = props[point_]['Centroid'][2]\n",
    "                y = props[point_]['Centroid'][1]\n",
    "                x = props[point_]['Centroid'][0]\n",
    "                \n",
    "                var_z_world,var_y_world,var_x_world= voxel_2_world((z,y,x), origin, new_spacing)\n",
    "                var.append([patient_id,var_x_world,var_y_world,var_z_world,props[point_]['EquivDiameter']])\n",
    "        return var\n",
    "    \n",
    "    patient_id = img_file.split('/')[-1][:-4]\n",
    "    img, origin, spacing = load_itk(src + img_file)\n",
    "    lung_mask = segment_HU_scan_ira(img)\n",
    "\n",
    "    height, width = img.shape[1], img.shape[2]\n",
    "    resize_factor = spacing / RESIZE_SPACING\n",
    "    new_real_shape = img.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize = new_shape / img.shape\n",
    "    new_spacing = spacing / real_resize\n",
    "\n",
    "    lung_img = scipy.ndimage.interpolation.zoom(img, real_resize)\n",
    "    lung_mask = scipy.ndimage.interpolation.zoom(lung_mask, real_resize)\n",
    "    lung_final = np.zeros_like(lung_img)\n",
    "    lung_mask[lung_mask<0.8] = 0\n",
    "    lung_mask[lung_mask>=0.8] = 1\n",
    "    \n",
    "    \n",
    "    lung_img = get_pixels_hu(lung_img)\n",
    "    lung_img[lung_img >= threshold_max] = threshold_max\n",
    "    lung_img[lung_img <= threshold_min] = threshold_min\n",
    "    lung_img = np.expand_dims(lung_img,1)    \n",
    "    lung_img = my_PreProc(lung_img)\n",
    "    lung_img = lung_img.astype(np.float32)\n",
    "    lung_img = np.squeeze(lung_img)    \n",
    "    \n",
    "    lung_img = lung_mask*lung_img\n",
    "    \n",
    "    shape_x,shape_y,shape_z = lung_img.shape\n",
    "\n",
    "\n",
    "    final_cube = np.zeros_like(lung_img)\n",
    "    for i in range(shape_x//128+1):\n",
    "        for j in range(shape_y//128+1):\n",
    "            for k in range(shape_z//128+1):\n",
    "                \n",
    "                edge_x = img_edge(i,shape_x)\n",
    "                edge_y = img_edge(j,shape_y)\n",
    "                edge_z = img_edge(k,shape_z)\n",
    "                \n",
    "                sample = np.zeros([128, 128, 128])\n",
    "                sample[0:(edge_x - i*128), 0:(edge_y - j*128), 0:(edge_z - k*128)] = lung_img[i*128:edge_x, j*128:edge_y, k*128:edge_z]\n",
    "                sample = np.expand_dims(sample,0)\n",
    "                sample = np.expand_dims(sample,0)\n",
    "                result = model.predict(sample) \n",
    "                result = np.squeeze(result)\n",
    "                final_cube[i*128:edge_x, j*128:edge_y, k*128:edge_z] = result[0:(edge_x - i*128), 0:(edge_y - j*128), 0:(edge_z - k*128)] \n",
    "    lung_final = lung_mask*final_cube\n",
    "    #lung_final[:,:,:] = final_cube[0:shape_x,0:shape_y,0:shape_z]\n",
    "    final_cube_result = save_result(final_cube)\n",
    "    #var = save_result(result)\n",
    "\n",
    "                        \n",
    "    \n",
    "    return final_cube_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#annotations_path = annotations_train_path\n",
    "#src = src_train\n",
    "#dst_nodules = mask_train\n",
    "annotations_path = '/Users/mahui/Downloads/csv/train/'\n",
    "src = '/Users/mahui/Downloads/Data/train/'\n",
    "dst_nodules = '/Users/mahui/Downloads/Data/train_mask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patients = load_train()\n",
    "RESIZE_SPACING = [1, 1, 1]\n",
    "threshold_min = -1200\n",
    "threshold_max = 400\n",
    "\n",
    "height_mask = 512\n",
    "width_mask = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subset00/LKDS-00001.mhd',\n",
       " 'subset00/LKDS-00003.mhd',\n",
       " 'subset00/LKDS-00004.mhd',\n",
       " 'subset00/LKDS-00005.mhd',\n",
       " 'subset00/LKDS-00635.mhd',\n",
       " 'subset00/LKDS-00642.mhd',\n",
       " 'subset00/LKDS-00655.mhd',\n",
       " 'subset00/LKDS-00659.mhd']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_slices = 128\n",
    "img_size = 128\n",
    "dropout_rate = 0.5\n",
    "width = 8\n",
    "\n",
    "img_rows = img_size\n",
    "img_cols = img_size\n",
    "model = unet_model()\n",
    "#model.load_weights(model_path + '3DUNet_FenGe519.h5')\n",
    "model.load_weights('/Users/mahui/Downloads/3DUNet_FenGe519.h5')\n",
    "final_result = pd.DataFrame(columns=('seriesuid', 'coordX', 'coordY', 'coordZ','diameter_mm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for patient in tqdm(sorted(patients[0:1])):\n",
    "    final = pred_for_test_watershed(patient)\n",
    "    for idx in range(len(final)):\n",
    "        row = pd.DataFrame([dict(seriesuid=final[idx][0], coordX=final[idx][1], coordY=final[idx][2],coordZ=final[idx][3],diameter_mm=final[idx][4]), ])\n",
    "        final_result = final_result.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_result = final_result[['seriesuid', 'coordX', 'coordY', 'coordZ','diameter_mm']]\n",
    "final_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_result"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
