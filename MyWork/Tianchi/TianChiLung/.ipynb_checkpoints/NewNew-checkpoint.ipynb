{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.paths import *\n",
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scan(path):\n",
    "    slices = [sitk.ReadImage(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n",
    "    if slices[0].ImagePositionPatient[2] == slices[1].ImagePositionPatient[2]:\n",
    "        sec_num = 2;\n",
    "        while slices[0].ImagePositionPatient[2] == slices[sec_num].ImagePositionPatient[2]:\n",
    "            sec_num = sec_num+1;\n",
    "        slice_num = int(len(slices) / sec_num)\n",
    "        slices.sort(key = lambda x:float(x.InstanceNumber))\n",
    "        slices = slices[0:slice_num]\n",
    "        slices.sort(key = lambda x:float(x.ImagePositionPatient[2]))\n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices\n",
    "\n",
    "def get_pixels_hu(slices):\n",
    "    image = np.stack([s.pixel_array for s in slices])\n",
    "    # Convert to int16 (from sometimes int16), \n",
    "    # should be possible as values should always be low enough (<32k)\n",
    "    image = image.astype(np.int16)\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    for slice_number in range(len(slices)):        \n",
    "        intercept = slices[slice_number].RescaleIntercept\n",
    "        slope = slices[slice_number].RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image[slice_number] = slope * image[slice_number].astype(np.float64)\n",
    "            image[slice_number] = image[slice_number].astype(np.int16)\n",
    "            \n",
    "        image[slice_number] += np.int16(intercept)\n",
    "    \n",
    "    return np.array(image, dtype=np.int16), np.array([slices[0].SliceThickness] + slices[0].PixelSpacing, dtype=np.float32)\n",
    "\n",
    "def binarize_per_slice(image, spacing, intensity_th=-600, sigma=1, area_th=30, eccen_th=0.99, bg_patch_size=10):\n",
    "    bw = np.zeros(image.shape, dtype=bool)\n",
    "    \n",
    "    # prepare a mask, with all corner values set to nan\n",
    "    image_size = image.shape[1]\n",
    "    grid_axis = np.linspace(-image_size/2+0.5, image_size/2-0.5, image_size)\n",
    "    x, y = np.meshgrid(grid_axis, grid_axis)\n",
    "    d = (x**2+y**2)**0.5\n",
    "    nan_mask = (d<image_size/2).astype(float)\n",
    "    nan_mask[nan_mask == 0] = np.nan\n",
    "    for i in range(image.shape[0]):\n",
    "        # Check if corner pixels are identical, if so the slice  before Gaussian filtering\n",
    "        if len(np.unique(image[i, 0:bg_patch_size, 0:bg_patch_size])) == 1:\n",
    "            current_bw = scipy.ndimage.filters.gaussian_filter(np.multiply(image[i].astype('float32'), nan_mask), sigma, truncate=2.0) < intensity_th\n",
    "        else:\n",
    "            current_bw = scipy.ndimage.filters.gaussian_filter(image[i].astype('float32'), sigma, truncate=2.0) < intensity_th\n",
    "        \n",
    "        # select proper components\n",
    "        label = measure.label(current_bw)\n",
    "        properties = measure.regionprops(label)\n",
    "        valid_label = set()\n",
    "        for prop in properties:\n",
    "            if prop.area * spacing[1] * spacing[2] > area_th and prop.eccentricity < eccen_th:\n",
    "                valid_label.add(prop.label)\n",
    "        current_bw = np.in1d(label, list(valid_label)).reshape(label.shape)\n",
    "        bw[i] = current_bw\n",
    "        \n",
    "    return bw\n",
    "\n",
    "def all_slice_analysis(bw, spacing, cut_num=0, vol_limit=[0.68, 8.2], area_th=6e3, dist_th=62):\n",
    "    # in some cases, several top layers need to be removed first\n",
    "    if cut_num > 0:\n",
    "        bw0 = np.copy(bw)\n",
    "        bw[-cut_num:] = False\n",
    "    label = measure.label(bw, connectivity=1)\n",
    "    # remove components access to corners\n",
    "    mid = int(label.shape[2] / 2)\n",
    "    bg_label = set([label[0, 0, 0], label[0, 0, -1], label[0, -1, 0], label[0, -1, -1], \\\n",
    "                    label[-1-cut_num, 0, 0], label[-1-cut_num, 0, -1], label[-1-cut_num, -1, 0], label[-1-cut_num, -1, -1], \\\n",
    "                    label[0, 0, mid], label[0, -1, mid], label[-1-cut_num, 0, mid], label[-1-cut_num, -1, mid]])\n",
    "    for l in bg_label:\n",
    "        label[label == l] = 0\n",
    "        \n",
    "    # select components based on volume\n",
    "    properties = measure.regionprops(label)\n",
    "    for prop in properties:\n",
    "        if prop.area * spacing.prod() < vol_limit[0] * 1e6 or prop.area * spacing.prod() > vol_limit[1] * 1e6:\n",
    "            label[label == prop.label] = 0\n",
    "            \n",
    "    # prepare a distance map for further analysis\n",
    "    x_axis = np.linspace(-label.shape[1]/2+0.5, label.shape[1]/2-0.5, label.shape[1]) * spacing[1]\n",
    "    y_axis = np.linspace(-label.shape[2]/2+0.5, label.shape[2]/2-0.5, label.shape[2]) * spacing[2]\n",
    "    x, y = np.meshgrid(x_axis, y_axis)\n",
    "    d = (x**2+y**2)**0.5\n",
    "    vols = measure.regionprops(label)\n",
    "    valid_label = set()\n",
    "    # select components based on their area and distance to center axis on all slices\n",
    "    for vol in vols:\n",
    "        single_vol = label == vol.label\n",
    "        slice_area = np.zeros(label.shape[0])\n",
    "        min_distance = np.zeros(label.shape[0])\n",
    "        for i in range(label.shape[0]):\n",
    "            slice_area[i] = np.sum(single_vol[i]) * np.prod(spacing[1:3])\n",
    "            min_distance[i] = np.min(single_vol[i] * d + (1 - single_vol[i]) * np.max(d))\n",
    "        \n",
    "        if np.average([min_distance[i] for i in range(label.shape[0]) if slice_area[i] > area_th]) < dist_th:\n",
    "            valid_label.add(vol.label)\n",
    "            \n",
    "    bw = np.in1d(label, list(valid_label)).reshape(label.shape)\n",
    "    \n",
    "    # fill back the parts removed earlier\n",
    "    if cut_num > 0:\n",
    "        # bw1 is bw with removed slices, bw2 is a dilated version of bw, part of their intersection is returned as final mask\n",
    "        bw1 = np.copy(bw)\n",
    "        bw1[-cut_num:] = bw0[-cut_num:]\n",
    "        bw2 = np.copy(bw)\n",
    "        bw2 = scipy.ndimage.binary_dilation(bw2, iterations=cut_num)\n",
    "        bw3 = bw1 & bw2\n",
    "        label = measure.label(bw, connectivity=1)\n",
    "        label3 = measure.label(bw3, connectivity=1)\n",
    "        l_list = list(set(np.unique(label)) - {0})\n",
    "        valid_l3 = set()\n",
    "        for l in l_list:\n",
    "            indices = np.nonzero(label==l)\n",
    "            l3 = label3[indices[0][0], indices[1][0], indices[2][0]]\n",
    "            if l3 > 0:\n",
    "                valid_l3.add(l3)\n",
    "        bw = np.in1d(label3, list(valid_l3)).reshape(label3.shape)\n",
    "    \n",
    "    return bw, len(valid_label)\n",
    "\n",
    "def fill_hole(bw):\n",
    "    # fill 3d holes\n",
    "    label = measure.label(~bw)\n",
    "    # idendify corner components\n",
    "    bg_label = set([label[0, 0, 0], label[0, 0, -1], label[0, -1, 0], label[0, -1, -1], \\\n",
    "                    label[-1, 0, 0], label[-1, 0, -1], label[-1, -1, 0], label[-1, -1, -1]])\n",
    "    bw = ~np.in1d(label, list(bg_label)).reshape(label.shape)\n",
    "    \n",
    "    return bw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def two_lung_only(bw, spacing, max_iter=22, max_ratio=4.8):    \n",
    "    def extract_main(bw, cover=0.95):\n",
    "        for i in range(bw.shape[0]):\n",
    "            current_slice = bw[i]\n",
    "            label = measure.label(current_slice)\n",
    "            properties = measure.regionprops(label)\n",
    "            properties.sort(key=lambda x: x.area, reverse=True)\n",
    "            area = [prop.area for prop in properties]\n",
    "            count = 0\n",
    "            sum = 0\n",
    "            while sum < np.sum(area)*cover:\n",
    "                sum = sum+area[count]\n",
    "                count = count+1\n",
    "            filter = np.zeros(current_slice.shape, dtype=bool)\n",
    "            for j in range(count):\n",
    "                bb = properties[j].bbox\n",
    "                filter[bb[0]:bb[2], bb[1]:bb[3]] = filter[bb[0]:bb[2], bb[1]:bb[3]] | properties[j].convex_image\n",
    "            bw[i] = bw[i] & filter\n",
    "           \n",
    "        label = measure.label(bw)\n",
    "        properties = measure.regionprops(label)\n",
    "        properties.sort(key=lambda x: x.area, reverse=True)\n",
    "        bw = label==properties[0].label\n",
    "\n",
    "        return bw\n",
    "    \n",
    "    def fill_2d_hole(bw):\n",
    "        for i in range(bw.shape[0]):\n",
    "            current_slice = bw[i]\n",
    "            label = measure.label(current_slice)\n",
    "            properties = measure.regionprops(label)\n",
    "            for prop in properties:\n",
    "                bb = prop.bbox\n",
    "                current_slice[bb[0]:bb[2], bb[1]:bb[3]] = current_slice[bb[0]:bb[2], bb[1]:bb[3]] | prop.filled_image\n",
    "            bw[i] = current_slice\n",
    "\n",
    "        return bw\n",
    "    \n",
    "    found_flag = False\n",
    "    iter_count = 0\n",
    "    bw0 = np.copy(bw)\n",
    "    while not found_flag and iter_count < max_iter:\n",
    "        label = measure.label(bw, connectivity=2)\n",
    "        properties = measure.regionprops(label)\n",
    "        properties.sort(key=lambda x: x.area, reverse=True)\n",
    "        if len(properties) > 1 and properties[0].area/properties[1].area < max_ratio:\n",
    "            found_flag = True\n",
    "            bw1 = label == properties[0].label\n",
    "            bw2 = label == properties[1].label\n",
    "        else:\n",
    "            bw = scipy.ndimage.binary_erosion(bw)\n",
    "            iter_count = iter_count + 1\n",
    "    \n",
    "    if found_flag:\n",
    "        d1 = scipy.ndimage.morphology.distance_transform_edt(bw1 == False, sampling=spacing)\n",
    "        d2 = scipy.ndimage.morphology.distance_transform_edt(bw2 == False, sampling=spacing)\n",
    "        bw1 = bw0 & (d1 < d2)\n",
    "        bw2 = bw0 & (d1 > d2)\n",
    "                \n",
    "        bw1 = extract_main(bw1)\n",
    "        bw2 = extract_main(bw2)\n",
    "        \n",
    "    else:\n",
    "        bw1 = bw0\n",
    "        bw2 = np.zeros(bw.shape).astype('bool')\n",
    "        \n",
    "    bw1 = fill_2d_hole(bw1)\n",
    "    bw2 = fill_2d_hole(bw2)\n",
    "    bw = bw1 | bw2\n",
    "\n",
    "    return bw1, bw2, bw\n",
    "\n",
    "def step1_python(case_path):\n",
    "    case = load_scan(case_path)\n",
    "    case_pixels, spacing = get_pixels_hu(case)\n",
    "    bw = binarize_per_slice(case_pixels, spacing)\n",
    "    flag = 0\n",
    "    cut_num = 0\n",
    "    cut_step = 2\n",
    "    bw0 = np.copy(bw)\n",
    "    while flag == 0 and cut_num < bw.shape[0]:\n",
    "        bw = np.copy(bw0)\n",
    "        bw, flag = all_slice_analysis(bw, spacing, cut_num=cut_num, vol_limit=[0.68,7.5])\n",
    "        cut_num = cut_num + cut_step\n",
    "\n",
    "    bw = fill_hole(bw)\n",
    "    bw1, bw2, bw = two_lung_only(bw, spacing)\n",
    "    return case_pixels, bw1, bw2, spacing\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exception thrown in SimpleITK ReadImage: /scratch/dashboards/SimpleITK-OSX10.6-x86_64-pkg/SimpleITK/Code/IO/src/sitkImageReaderBase.cxx:84:\nsitk::ERROR: Unable to determine ImageIO reader for \"/Volumes/solo/ali/Data/train/train_subset00//LKDS-00001.zraw\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-e628c59ad5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcase_pixels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep1_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-1a75f649c25e>\u001b[0m in \u001b[0;36mstep1_python\u001b[0;34m(case_path)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstep1_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mcase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mcase_pixels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pixels_hu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mbw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinarize_per_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase_pixels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-1a75f649c25e>\u001b[0m in \u001b[0;36mload_scan\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mslices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePositionPatient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePositionPatient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePositionPatient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msec_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/SimpleITK/SimpleITK.pyc\u001b[0m in \u001b[0;36mReadImage\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   8254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8255\u001b[0m     \"\"\"\n\u001b[0;32m-> 8256\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8257\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHashImageFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcessObject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8258\u001b[0m     \"\"\"\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception thrown in SimpleITK ReadImage: /scratch/dashboards/SimpleITK-OSX10.6-x86_64-pkg/SimpleITK/Code/IO/src/sitkImageReaderBase.cxx:84:\nsitk::ERROR: Unable to determine ImageIO reader for \"/Volumes/solo/ali/Data/train/train_subset00//LKDS-00001.zraw\""
     ]
    }
   ],
   "source": [
    "INPUT_FOLDER = '/Volumes/solo/ali/Data/train/train_subset00/'\n",
    "patients = [x for x in os.listdir(INPUT_FOLDER) if '.mhd' in x]\n",
    "patients.sort()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "case_pixels, m1, m2, spacing = step1_python(os.path.join(INPUT_FOLDER,patients[20]))\n",
    "plt.imshow(m1[60])\n",
    "plt.figure()\n",
    "plt.imshow(m2[60])\n",
    "#     first_patient = load_scan(INPUT_FOLDER + patients[25])\n",
    "#     first_patient_pixels, spacing = get_pixels_hu(first_patient)\n",
    "#     plt.hist(first_patient_pixels.flatten(), bins=80, color='c')\n",
    "#     plt.xlabel(\"Hounsfield Units (HU)\")\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Show some slice in the middle\n",
    "#     h = 80\n",
    "#     plt.imshow(first_patient_pixels[h], cmap=plt.cm.gray)\n",
    "#     plt.show()\n",
    "    \n",
    "#     bw = binarize_per_slice(first_patient_pixels, spacing)\n",
    "#     plt.imshow(bw[h], cmap=plt.cm.gray)\n",
    "#     plt.show()\n",
    "    \n",
    "#     flag = 0\n",
    "#     cut_num = 0\n",
    "#     while flag == 0:\n",
    "#         bw, flag = all_slice_analysis(bw, spacing, cut_num=cut_num)\n",
    "#         cut_num = cut_num + 1\n",
    "#     plt.imshow(bw[h], cmap=plt.cm.gray)\n",
    "#     plt.show()\n",
    "    \n",
    "#     bw = fill_hole(bw)\n",
    "#     plt.imshow(bw[h], cmap=plt.cm.gray)\n",
    "#     plt.show()\n",
    "    \n",
    "#     bw1, bw2, bw = two_lung_only(bw, spacing)\n",
    "#     plt.imshow(bw[h], cmap=plt.cm.gray)\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/solo/ali/Data/train/train_subset00/LKDS-00001.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00003.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00004.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00005.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00007.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00011.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00013.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00015.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00016.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00019.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00020.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00021.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00023.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00025.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00026.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00028.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00029.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00030.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00034.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00035.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00036.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00038.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00039.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00040.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00041.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00042.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00043.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00044.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00047.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00050.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00051.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00052.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00053.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00054.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00058.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00061.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00062.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00064.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00065.mhd',\n",
       " '/Volumes/solo/ali/Data/train/train_subset00/LKDS-00066.mhd']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-824a50f67c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "os.path.join(PATH['src'],patients[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidDicomError",
     "evalue": "File is missing 'DICM' marker. Use force=True to force reading",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidDicomError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-dc6998c33133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/solo/ali/Data/train/train_subset00/LKDS-00036.mhd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/dicom/filereader.pyc\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(fp, defer_size, stop_before_pixels, force)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         dataset = read_partial(fp, stop_when, defer_size=defer_size,\n\u001b[0;32m--> 614\u001b[0;31m                                force=force)\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcaller_owns_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/dicom/filereader.pyc\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(fileobj, stop_when, defer_size, force)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \"\"\"\n\u001b[1;32m    514\u001b[0m     \u001b[0;31m# Read preamble -- raise an exception if missing and force=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     \u001b[0mpreamble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_preamble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m     \u001b[0mfile_meta_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Assume a transfer syntax, correct it as necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mahui/anaconda/lib/python2.7/site-packages/dicom/filereader.pyc\u001b[0m in \u001b[0;36mread_preamble\u001b[0;34m(fp, force)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             raise InvalidDicomError(\"File is missing 'DICM' marker. \"\n\u001b[0m\u001b[1;32m    490\u001b[0m                                     \"Use force=True to force reading\")\n\u001b[1;32m    491\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidDicomError\u001b[0m: File is missing 'DICM' marker. Use force=True to force reading"
     ]
    }
   ],
   "source": [
    "cc = dicom.read_file('/Volumes/solo/ali/Data/train/train_subset00/LKDS-00036.mhd')\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from skimage import measure\n",
    "import warnings\n",
    "from scipy.ndimage.morphology import binary_dilation,generate_binary_structure\n",
    "from skimage.morphology import convex_hull_image\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from step1 import step1_python\n",
    "import warnings\n",
    "\n",
    "def process_mask(mask):\n",
    "    convex_mask = np.copy(mask)\n",
    "    for i_layer in range(convex_mask.shape[0]):\n",
    "        mask1  = np.ascontiguousarray(mask[i_layer])\n",
    "        if np.sum(mask1)>0:\n",
    "            mask2 = convex_hull_image(mask1)\n",
    "            if np.sum(mask2)>2*np.sum(mask1):\n",
    "                mask2 = mask1\n",
    "        else:\n",
    "            mask2 = mask1\n",
    "        convex_mask[i_layer] = mask2\n",
    "    struct = generate_binary_structure(3,1)  \n",
    "    dilatedMask = binary_dilation(convex_mask,structure=struct,iterations=10) \n",
    "    return dilatedMask\n",
    "\n",
    "# def savenpy(id):\n",
    "id = 1\n",
    "\n",
    "def lumTrans(img):\n",
    "    lungwin = np.array([-1200.,600.])\n",
    "    newimg = (img-lungwin[0])/(lungwin[1]-lungwin[0])\n",
    "    newimg[newimg<0]=0\n",
    "    newimg[newimg>1]=1\n",
    "    newimg = (newimg*255).astype('uint8')\n",
    "    return newimg\n",
    "\n",
    "def resample(imgs, spacing, new_spacing,order = 2):\n",
    "    if len(imgs.shape)==3:\n",
    "        new_shape = np.round(imgs.shape * spacing / new_spacing)\n",
    "        true_spacing = spacing * imgs.shape / new_shape\n",
    "        resize_factor = new_shape / imgs.shape\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            imgs = zoom(imgs, resize_factor, mode = 'nearest',order=order)\n",
    "        return imgs, true_spacing\n",
    "    elif len(imgs.shape)==4:\n",
    "        n = imgs.shape[-1]\n",
    "        newimg = []\n",
    "        for i in range(n):\n",
    "            slice = imgs[:,:,:,i]\n",
    "            newslice,true_spacing = resample(slice,spacing,new_spacing)\n",
    "            newimg.append(newslice)\n",
    "        newimg=np.transpose(np.array(newimg),[1,2,3,0])\n",
    "        return newimg,true_spacing\n",
    "    else:\n",
    "        raise ValueError('wrong shape')\n",
    "\n",
    "def savenpy(id,filelist,prep_folder,data_path,use_existing=True):      \n",
    "    resolution = np.array([1,1,1])\n",
    "    name = filelist[id]\n",
    "    if use_existing:\n",
    "        if os.path.exists(os.path.join(prep_folder,name+'_label.npy')) and os.path.exists(os.path.join(prep_folder,name+'_clean.npy')):\n",
    "            print(name+' had been done')\n",
    "            return\n",
    "    try:\n",
    "        im, m1, m2, spacing = step1_python(os.path.join(data_path,name))\n",
    "        Mask = m1+m2\n",
    "        \n",
    "        newshape = np.round(np.array(Mask.shape)*spacing/resolution)\n",
    "        xx,yy,zz= np.where(Mask)\n",
    "        box = np.array([[np.min(xx),np.max(xx)],[np.min(yy),np.max(yy)],[np.min(zz),np.max(zz)]])\n",
    "        box = box*np.expand_dims(spacing,1)/np.expand_dims(resolution,1)\n",
    "        box = np.floor(box).astype('int')\n",
    "        margin = 5\n",
    "        extendbox = np.vstack([np.max([[0,0,0],box[:,0]-margin],0),np.min([newshape,box[:,1]+2*margin],axis=0).T]).T\n",
    "        extendbox = extendbox.astype('int')\n",
    "\n",
    "\n",
    "\n",
    "        convex_mask = m1\n",
    "        dm1 = process_mask(m1)\n",
    "        dm2 = process_mask(m2)\n",
    "        dilatedMask = dm1+dm2\n",
    "        Mask = m1+m2\n",
    "        extramask = dilatedMask ^ Mask\n",
    "        bone_thresh = 210\n",
    "        pad_value = 170\n",
    "\n",
    "        im[np.isnan(im)]=-2000\n",
    "        sliceim = lumTrans(im)\n",
    "        sliceim = sliceim*dilatedMask+pad_value*(1-dilatedMask).astype('uint8')\n",
    "        bones = sliceim*extramask>bone_thresh\n",
    "        sliceim[bones] = pad_value\n",
    "        sliceim1,_ = resample(sliceim,spacing,resolution,order=1)\n",
    "        sliceim2 = sliceim1[extendbox[0,0]:extendbox[0,1],\n",
    "                    extendbox[1,0]:extendbox[1,1],\n",
    "                    extendbox[2,0]:extendbox[2,1]]\n",
    "        sliceim = sliceim2[np.newaxis,...]\n",
    "        np.save(os.path.join(prep_folder,name+'_clean'),sliceim)\n",
    "        np.save(os.path.join(prep_folder,name+'_label'),np.array([[0,0,0,0]]))\n",
    "    except:\n",
    "        print('bug in '+name)\n",
    "        raise\n",
    "    print(name+' done')\n",
    "\n",
    "    \n",
    "def full_prep(data_path,prep_folder,n_worker = None,use_existing=True):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    if not os.path.exists(prep_folder):\n",
    "        os.mkdir(prep_folder)\n",
    "\n",
    "            \n",
    "    print('starting preprocessing')\n",
    "    pool = Pool(n_worker)\n",
    "    filelist = [f for f in os.listdir(data_path)]\n",
    "    partial_savenpy = partial(savenpy,filelist=filelist,prep_folder=prep_folder,\n",
    "                              data_path=data_path,use_existing=use_existing)\n",
    "\n",
    "    N = len(filelist)\n",
    "    _=pool.map(partial_savenpy,range(N))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('end preprocessing')\n",
    "    return filelist\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
